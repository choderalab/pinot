{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground for Biophysical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pinot\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\miniconda3\\envs\\pinot\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "ds = pinot.data.moonshot_multi()\n",
    "\n",
    "# send data to cuda\n",
    "ds = ds.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 6 values, three for each assay.\n",
    "\n",
    "They are as follows:\n",
    "\n",
    "```\n",
    "    KEY\n",
    "        r is rapidfire\n",
    "        f is fluorescence\n",
    "\n",
    "    DESCRIPTIONS\n",
    "    \n",
    "        'r_inhibition_at_20_uM',\n",
    "        'r_inhibition_at_50_uM',\n",
    "        'r_avg_IC50',\n",
    "        \n",
    "        'f_inhibition_at_20_uM',\n",
    "        'f_inhibition_at_50_uM',\n",
    "        'f_avg_IC50'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0361, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g, y = ds.ds[9]\n",
    "y[3] # `f_inhibition_at_20_uM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up net and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_and_optimizer(architecture, regressor_type='vgp',\n",
    "                          n_inducing_points=50, optimizer='Adam',\n",
    "                          lr=1e-4, weight_decay=0.01, device='cuda'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    representation = pinot.representation.sequential.SequentialMix(\n",
    "        architecture,\n",
    "    )\n",
    "\n",
    "    if regressor_type == \"gp\":\n",
    "        output_regressor = pinot.regressors.ExactGaussianProcessRegressor\n",
    "    elif regressor_type == \"nn\":\n",
    "        output_regressor = pinot.regressors.NeuralNetworkRegressor \n",
    "    else:\n",
    "        output_regressor = pinot.regressors.VariationalGaussianProcessRegressor\n",
    "\n",
    "    # First train a fully supervised Net to use as Baseline\n",
    "    net = pinot.Net(\n",
    "        representation=representation,\n",
    "        output_regressor_class=output_regressor,\n",
    "        n_inducing_points=n_inducing_points\n",
    "    )\n",
    "    optimizer = pinot.app.utils.optimizer_translation(\n",
    "        opt_string=optimizer, lr=lr, weight_decay=weight_decay,\n",
    "    )\n",
    "    net.to(device)\n",
    "    \n",
    "    return net, optimizer(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design architecture, instantiate net, optimizer, and set batch size accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = [\n",
    "    32, 'GraphSAGE' 'activation', 'tanh',\n",
    "    32, 'GraphSAGE' 'activation', 'tanh',\n",
    "    32, 'GraphSAGE' 'activation', 'tanh',\n",
    "]\n",
    "\n",
    "net, optimizer = get_net_and_optimizer(\n",
    "    architecture, regressor_type='vgp',\n",
    "    n_inducing_points=50, optimizer='Adam',\n",
    "    lr=1e-4, weight_decay=0.01, device='cuda'\n",
    ")\n",
    "\n",
    "if net.has_exact_gp:\n",
    "    batch_size = len(data)\n",
    "else:\n",
    "    batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_once(net, data, optimizer, annealing):\n",
    "    \"\"\"\n",
    "    Train the model for one batch.\n",
    "    \"\"\"\n",
    "    total_loss = 0.\n",
    "    for d in data:\n",
    "\n",
    "        batch_ratio = len(d[1]) / len(data)\n",
    "        \n",
    "        def l():\n",
    "            \"\"\" \"\"\"\n",
    "            optimizer.zero_grad()\n",
    "            loss = torch.sum(\n",
    "                net.loss(\n",
    "                    *d,\n",
    "                    kl_loss_scaling=batch_ratio,\n",
    "                    annealing=annealing\n",
    "                )\n",
    "            )\n",
    "            loss.backward()\n",
    "\n",
    "            return loss\n",
    "\n",
    "        optimizer.step(l)\n",
    "        \n",
    "def compute_conditional(net, data, batch_size):\n",
    "    \"\"\"\n",
    "    Get conditional distribution for net on dataset for testing.\n",
    "    \"\"\"\n",
    "    # compute conditional distribution in batched fashion\n",
    "    locs, scales = [], []\n",
    "    for idx, d in enumerate(data.batch(batch_size,\n",
    "#                                        partial_batch=True\n",
    "                                      )):\n",
    "\n",
    "        g_batch, _ = d\n",
    "        distribution_batch = net.condition(g_batch)\n",
    "        loc_batch = distribution_batch.mean.flatten().cpu()\n",
    "        scale_batch = distribution_batch.variance.pow(0.5).flatten().cpu()\n",
    "        locs.append(loc_batch)\n",
    "        scales.append(scale_batch)\n",
    "\n",
    "    distribution = torch.distributions.normal.Normal(\n",
    "        loc=torch.cat(locs),\n",
    "        scale=torch.cat(scales)\n",
    "    )\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get toy data that contains only `f_inhibition_at_20_uM` for `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "ds_f = deepcopy(ds)\n",
    "gs, ys = zip(*ds)\n",
    "y_stacked = torch.stack(ys)\n",
    "\n",
    "# filter for only at 20uM\n",
    "has_f_at_20uM = ~torch.isnan(y_stacked[:,3])\n",
    "gs_f = [g for idx, g in enumerate(gs) if has_f_at_20uM[idx]]\n",
    "ys_f = [y[3].unsqueeze(-1)\n",
    "        for idx, y in enumerate(ys)\n",
    "        if has_f_at_20uM[idx]]\n",
    "ds_f.ds = list(zip(gs_f, ys_f))\n",
    "data = ds_f\n",
    "\n",
    "# split train/test\n",
    "seed = 0\n",
    "train_data, test_data = data.split([4, 1], seed=seed)\n",
    "\n",
    "# mini-batch if we're using variational GP\n",
    "train_data = train_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1200 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Normal' object has no attribute 'ndata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-813eef5a5f7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# loop through the metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             score = metric(\n\u001b[0m\u001b[0;32m     34\u001b[0m                 \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mdistribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\dev\\choderalab\\pinot\\pinot\\metrics.py\u001b[0m in \u001b[0;36mrmse\u001b[1;34m(net, g, y, n_samples, *args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         y_hat = _independent(\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m             ).sample().detach().cpu()\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\dev\\choderalab\\pinot\\pinot\\net.py\u001b[0m in \u001b[0;36mcondition\u001b[1;34m(self, g, *args, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# g -> h\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[1;31m# kwargs = {}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pinot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\dev\\choderalab\\pinot\\pinot\\representation\\sequential.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, h, pool)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"h\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"h\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"f_in\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_in\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Normal' object has no attribute 'ndata'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 1200\n",
    "annealing = 1.0 # weighting on variational loss\n",
    "metrics = [pinot.rmse, pinot.r2, pinot.avg_nll]\n",
    "data = ds_f\n",
    "\n",
    "results = []\n",
    "for epoch_idx in tqdm(range(n_epochs)):\n",
    "    \n",
    "    # train\n",
    "    net.train()\n",
    "    train_once(net, train_data, optimizer, annealing)\n",
    "    \n",
    "    # test\n",
    "    net.eval()\n",
    "    \n",
    "    # compute conditional distribution in batched fashion\n",
    "    epoch_results = {}\n",
    "    \n",
    "    for phase in ['test']:\n",
    "        \n",
    "        if phase == 'test':\n",
    "            _, y = zip(*test_data)\n",
    "            y = torch.stack(y)\n",
    "#         else:\n",
    "#             gs, ys = \n",
    "            \n",
    "        distribution = compute_conditional(net, data, batch_size)\n",
    "\n",
    "        y = y.detach().cpu().reshape(-1, 1)\n",
    "        for metric in metrics:  # loop through the metrics\n",
    "            score = metric(\n",
    "                net,\n",
    "                distribution,\n",
    "                y,\n",
    "                batch_size=batch_size\n",
    "            ).detach().cpu().numpy()\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    'epoch': epoch_idx,\n",
    "                    'metric': metric.__name__,\n",
    "                    'score': score,\n",
    "                    'phase': phase,\n",
    "                }\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
