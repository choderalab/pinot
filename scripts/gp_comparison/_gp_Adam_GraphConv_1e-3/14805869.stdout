Sender: LSF System <lsfadmin@ls10>
Subject: Job 14805869: <_gp_Adam_GraphConv_1e-3> in cluster <lila> Done

Job <_gp_Adam_GraphConv_1e-3> was submitted from host <lx12> by user <wangy1> in cluster <lila> at Mon Jun  8 15:48:09 2020
Job was executed on host(s) <12*ls10>, in queue <gpuqueue>, as user <wangy1> in cluster <lila> at Mon Jun  8 15:48:09 2020
</home/wangy1> was used as the home directory.
</data/chodera/wangyq/pinot/scripts/gp_comparison> was used as the working directory.
Started at Mon Jun  8 15:48:09 2020
Terminated at Mon Jun  8 15:50:47 2020
Results reported at Mon Jun  8 15:50:47 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../../pinot/app/gp_train.py --layer GraphConv --optimizer Adam --lr 1e-3 --out _gp_Adam_GraphConv_1e-3 --n_epochs 10
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   32.53 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.58 GB
    Total Requested Memory :                     48.00 GB
    Delta Memory :                               46.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   157 sec.
    Turnaround time :                            158 sec.

The output (if any) follows:

Parameter containing:
tensor(1., device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9990, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9980, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9970, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9960, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9950, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9940, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9930, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9920, device='cuda:0', requires_grad=True)
Parameter containing:
tensor(0.9909, device='cuda:0', requires_grad=True)
tensor([[-2.0233, -2.2500],
        [-0.1806,  1.5800],
        [-3.5697, -3.4000],
        ...,
        [-0.6889, -0.6000],
        [-4.4141, -5.1150],
        [-0.5899,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31629.5430, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.9661, -2.2500],
        [-0.1393,  1.5800],
        [-3.6523, -3.4000],
        ...,
        [-0.7144, -0.6000],
        [-4.5801, -5.1150],
        [-0.5072,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-30662.0645, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.8891, -2.2500],
        [-0.0867,  1.5800],
        [-3.6885, -3.4000],
        ...,
        [-0.7296, -0.6000],
        [-4.7709, -5.1150],
        [-0.3909,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31717.1875, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.8047, -2.2500],
        [-0.0352,  1.5800],
        [-3.7125, -3.4000],
        ...,
        [-0.7394, -0.6000],
        [-4.9952, -5.1150],
        [-0.2655,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31866.1895, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.7420, -2.2500],
        [ 0.0178,  1.5800],
        [-3.7491, -3.4000],
        ...,
        [-0.7500, -0.6000],
        [-5.1991, -5.1150],
        [-0.1577,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31470.0586, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.7131, -2.2500],
        [ 0.0669,  1.5800],
        [-3.8010, -3.4000],
        ...,
        [-0.7612, -0.6000],
        [-5.3052, -5.1150],
        [-0.0579,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31460.8672, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.6831, -2.2500],
        [ 0.1005,  1.5800],
        [-3.8095, -3.4000],
        ...,
        [-0.7703, -0.6000],
        [-5.3580, -5.1150],
        [ 0.0572,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31356.0840, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.6436, -2.2500],
        [ 0.1118,  1.5800],
        [-3.7666, -3.4000],
        ...,
        [-0.7804, -0.6000],
        [-5.4175, -5.1150],
        [ 0.1723,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31302.2910, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.6173, -2.2500],
        [ 0.1032,  1.5800],
        [-3.7214, -3.4000],
        ...,
        [-0.7910, -0.6000],
        [-5.4749, -5.1150],
        [ 0.2633,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31150.1875, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.5987, -2.2500],
        [ 0.1004,  1.5800],
        [-3.7024, -3.4000],
        ...,
        [-0.7924, -0.6000],
        [-5.5345, -5.1150],
        [ 0.3235,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31074.3887, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-1.5987, -2.2500],
        [ 0.1004,  1.5800],
        [-3.7024, -3.4000],
        ...,
        [-0.7924, -0.6000],
        [-5.5345, -5.1150],
        [ 0.3235,  0.4800]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-31290.0098, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1292, -5.3600],
        [-3.5180, -4.0900],
        [-3.6770, -3.4300],
        ...,
        [-1.2196, -0.6600],
        [-1.2976, -1.5200],
        [-1.6273, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29654.6309, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1581, -5.3600],
        [-3.7129, -4.0900],
        [-3.8882, -3.4300],
        ...,
        [-1.2018, -0.6600],
        [-1.2406, -1.5200],
        [-1.7475, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29643.2422, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1804, -5.3600],
        [-3.8927, -4.0900],
        [-4.0084, -3.4300],
        ...,
        [-1.1522, -0.6600],
        [-1.1530, -1.5200],
        [-1.8959, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29671.6289, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1849, -5.3600],
        [-4.0405, -4.0900],
        [-4.0836, -3.4300],
        ...,
        [-1.0920, -0.6600],
        [-1.0381, -1.5200],
        [-2.0677, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29893.9863, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1612, -5.3600],
        [-4.1628, -4.0900],
        [-4.1452, -3.4300],
        ...,
        [-1.0430, -0.6600],
        [-0.9228, -1.5200],
        [-2.2041, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29340.9199, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1254, -5.3600],
        [-4.2678, -4.0900],
        [-4.1876, -3.4300],
        ...,
        [-1.0003, -0.6600],
        [-0.8474, -1.5200],
        [-2.2246, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-28959.0977, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1081, -5.3600],
        [-4.3643, -4.0900],
        [-4.1920, -3.4300],
        ...,
        [-0.9290, -0.6600],
        [-0.8048, -1.5200],
        [-2.2332, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29291.9570, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1121, -5.3600],
        [-4.4562, -4.0900],
        [-4.1430, -3.4300],
        ...,
        [-0.8303, -0.6600],
        [-0.7809, -1.5200],
        [-2.2900, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-28806.3691, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1256, -5.3600],
        [-4.5259, -4.0900],
        [-4.0729, -3.4300],
        ...,
        [-0.7325, -0.6600],
        [-0.7840, -1.5200],
        [-2.3774, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29026.9453, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1437, -5.3600],
        [-4.5743, -4.0900],
        [-4.0292, -3.4300],
        ...,
        [-0.6524, -0.6600],
        [-0.7975, -1.5200],
        [-2.4597, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29632.2969, device='cuda:0', grad_fn=<SubBackward0>)
tensor([[-4.1437, -5.3600],
        [-4.5743, -4.0900],
        [-4.0292, -3.4300],
        ...,
        [-0.6524, -0.6600],
        [-0.7975, -1.5200],
        [-2.4597, -2.8000]], device='cuda:0', grad_fn=<StackBackward>)
tensor(-29458.9258, device='cuda:0', grad_fn=<SubBackward0>)


PS:

Read file <14805869.stderr> for stderr output of this job.

