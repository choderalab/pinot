{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pinot\n",
    "import torch\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinot.data.datasets.Dataset at 0x7fdefafb0a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pinot.data.moonshot_pic50()\n",
    "all_data = [(g, y) for g, y in data]\n",
    "all_ys = np.array([y for (g, y) in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [(g, y) for g, y in data]\n",
    "train_data, test_data = pinot.data.utils.split(all_data, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ys = np.array([y for (g, y) in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of data points')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAJNCAYAAACfsmlCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgo0lEQVR4nO3dfbBtd13f8c+XJCAiFCiXGJNAIhNog9ZAb1OVGeRBBUEIUKlhFCNDG2qDQuuMJo4KlMlIq+BDK9AI1GiVNIJI5EHFyEOdKiHB8JCElCtEuCYmV5QnH4JJvv3jrOs93J577sZk7d+5d71eM2fO3muvffK9a9Zk3rPW2mtXdwcAgHHuNnoAAIClE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAw2LGjB7gzHvCAB/Qpp5wyegwAgMO66qqr/ry7d2312hEdZKecckquvPLK0WMAABxWVf3JoV5zyhIAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgx44egEM75fy3rrTeDS978syTAABzcoQMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYLMFWVV9WVVdUVUfqKprquol0/IXV9WfVtXV08+TNr3ngqraU1XXV9UT5poNAGAnOXbGv31rksd19+er6rgkv19Vb59e++nu/qnNK1fV6UnOTvLwJF+V5Her6qHdffuMMwIADDfbEbLe8Pnp6XHTT2/zlrOSXNLdt3b3x5PsSXLmXPMBAOwUs15DVlXHVNXVSW5J8o7ufu/00vOr6oNV9bqqut+07MQkn9z09r3TMgCAo9qsQdbdt3f3GUlOSnJmVX1NklcleUiSM5LclOTl0+q11Z84eEFVnVtVV1bVlfv27ZtlbgCAdVrLpyy7+9NJ3pXkid198xRqdyT5hRw4Lbk3ycmb3nZSkhu3+FsXdffu7t69a9eueQcHAFiDOT9luauq7js9vmeSb07ykao6YdNqT0/y4enxZUnOrqp7VNWpSU5LcsVc8wEA7BRzfsryhCQXV9Ux2Qi/S7v7LVX1y1V1RjZOR96Q5HlJ0t3XVNWlSa5NcluS83zCEgBYgtmCrLs/mOQRWyx/9jbvuTDJhXPNBACwE7lTPwDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYbLYgq6ovq6orquoDVXVNVb1kWn7/qnpHVX10+n2/Te+5oKr2VNX1VfWEuWYDANhJ5jxCdmuSx3X31yU5I8kTq+rrk5yf5PLuPi3J5dPzVNXpSc5O8vAkT0zyyqo6Zsb5AAB2hNmCrDd8fnp63PTTSc5KcvG0/OIkT5sen5Xkku6+tbs/nmRPkjPnmg8AYKeY9Rqyqjqmqq5OckuSd3T3e5Mc3903Jcn0+4HT6icm+eSmt++dlgEAHNVmDbLuvr27z0hyUpIzq+prtlm9tvoT/99KVedW1ZVVdeW+ffvuokkBAMZZy6csu/vTSd6VjWvDbq6qE5Jk+n3LtNreJCdvettJSW7c4m9d1N27u3v3rl275hwbAGAt5vyU5a6quu/0+J5JvjnJR5JcluScabVzkrx5enxZkrOr6h5VdWqS05JcMdd8AAA7xbEz/u0Tklw8fVLybkku7e63VNUfJLm0qp6b5BNJnpkk3X1NVV2a5NoktyU5r7tvn3E+AIAdYbYg6+4PJnnEFss/leTxh3jPhUkunGsmAICdyJ36AQAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwWYLsqo6uareWVXXVdU1VfWCafmLq+pPq+rq6edJm95zQVXtqarrq+oJc80GALCTHDvj374tyQ929/ur6t5Jrqqqd0yv/XR3/9Tmlavq9CRnJ3l4kq9K8rtV9dDuvn3GGQEAhpvtCFl339Td758efy7JdUlO3OYtZyW5pLtv7e6PJ9mT5My55gMA2CnWcg1ZVZ2S5BFJ3jsten5VfbCqXldV95uWnZjkk5vetjfbBxwAwFFh9iCrqq9I8sYkL+zuzyZ5VZKHJDkjyU1JXr5/1S3e3lv8vXOr6sqqunLfvn3zDA0AsEazBllVHZeNGPuV7v71JOnum7v79u6+I8kv5MBpyb1JTt709pOS3Hjw3+zui7p7d3fv3rVr15zjAwCsxZyfsqwkr01yXXe/YtPyEzat9vQkH54eX5bk7Kq6R1WdmuS0JFfMNR8AwE4x56csH5Xk2Uk+VFVXT8t+JMmzquqMbJyOvCHJ85Kku6+pqkuTXJuNT2ie5xOWAMASzBZk3f372fq6sLdt854Lk1w410wAADuRO/UDAAwmyAAABhNkAACDCTIAgMEEGQDAYIIMAGAwQQYAMJggAwAYTJABAAwmyAAABhNkAACDCTIAgMEOG2RV9aiqutf0+Lur6hVV9eD5RwMAWIZVjpC9KslfV9XXJfmhJH+S5JdmnQoAYEFWCbLburuTnJXkZ7v7Z5Pce96xAACW49gV1vlcVV2Q5LuTPLqqjkly3LxjAQAsxypHyL4zya1Jntvdf5bkxCQ/OetUAAALssoRsv/Q3T+8/0l3f6KqHj7jTAAAi7LKEbJv2WLZt93VgwAALNUhj5BV1fcl+fdJvrqqPrjppXsn+T9zDwYAsBTbnbL81SRvT/ITSc7ftPxz3f0Xs04FALAghwyy7v5Mks8kedb0ycrjp/W/oqq+ors/saYZAQCOaoe9qL+qnp/kxUluTnLHtLiT/LP5xgIAWI5VPmX5wiQP6+5PzTwLAMAirfIpy09m49QlAAAzWOUI2ceSvKuq3pqNG8QmSbr7FbNNBQCwIKsE2Semn7tPPwAA3IUOG2Td/ZJ1DAIAsFTb3Rj2Z7r7hVX1m9n4VOUX6e6nzjoZAMBCbHeE7Jen3z+1jkEAAJZquxvDXjX9fndV3T3JQ6eXru/uv1vHcAAAS7DKjWEfk+TiJDckqSQnV9U53f2eWScDAFiIVT5l+fIk39rd1ydJVT00yeuT/PM5BwMAWIpVbgx73P4YS5Lu/r9JjptvJACAZVnlCNmVVfXaHLjI/7uSXDXfSAAAy7JKkH1fkvOS/EA2riF7T5JXzjkUAMCSrHJj2Fur6r8luTzJHdn4lOUXZp8MAGAhVvmU5ZOTvDrJH2fjCNmpVfW87n773MMBACzBqp+yfGx370mSqnpIkrcmEWQAAHeBVT5lecv+GJt8LMktM80DALA4qxwhu6aq3pbk0mx8p+Uzk7yvqp6RJN396zPOBwBw1FslyL4syc1Jvml6vi/J/ZM8JRuBJsgAAO6EVT5l+Zx1DAIAsFSrXEMGAMCMBBkAwGCCDABgsFUu6t9/c9iHZ+MC/yRJd/+nuYYCAFiSwx4hq6pXJ/nOJN+fjTv1PzPJg2eeCwBgMVY5ZfmN3f09Sf6yu1+S5BuSnDzvWAAAy7FKkP3N9Puvq+qrkvxdklPnGwkAYFlWuYbsLVV13yQ/meT92bgZ7GvmHAoAYElWCbL/0t23JnljVb0lGxf2/+28YwEALMcqpyz/YP+D7r61uz+zeRkAAHfOIY+QVdVXJjkxyT2r6hHZ+IRlktwnyZevYTYAgEXY7pTlE5J8b5KTkrxi0/LPJfmRGWcCAFiUQwZZd1+c5OKq+lfd/cY1zgQAsCiHvai/u9/oTv0AAPNxp34AgMHcqR8AYDB36gcAGGyVIDv4Tv03JLnkcG+qqpOr6p1VdV1VXVNVL5iW37+q3lFVH51+32/Tey6oqj1VdX1VPeEf9C8CADjCHDbIuvul3f3p6ZOWD07yT7r7x1b427cl+cHu/qdJvj7JeVV1epLzk1ze3acluXx6num1s7Px4YEnJnllVR3zD/lHAQAcSba7Mewztnkt3f3r2/3h7r4pyU3T489V1XXZuNHsWUkeM612cZJ3Jfnhafkl09c0fbyq9iQ5M74VAAA4ym1324unTL8fmOQbk/ze9Pyx2YiobYNss6o6Jckjkrw3yfFTrKW7b6qqB06rnZjkDze9be+0DADgqLbdjWGfkyTTF4qfvj+iquqEJD+/6n+gqr4iyRuTvLC7P1tVh1x1qzG2+HvnJjk3SR70oAetOgYAwI61ykX9p+yPscnNSR66yh+vquOyEWO/sukU581T1O2Pu1um5XvzxbfTOCnJjQf/ze6+qLt3d/fuXbt2rTIGAMCOtkqQvauqfruqvreqzkny1iTvPNybauNQ2GuTXNfdm78L87Ik50yPz0ny5k3Lz66qe1TVqUlOS3LFiv8OAIAj1ipfnfT8qnp6kkdPiy7q7jet8LcfleTZST5UVVdPy34kycuSXFpVz03yiWzc+T/dfU1VXZrk2mx8QvO87r79S/nHAAAciQ4bZEkyBdgqEbb5Pb+fra8LS5LHH+I9Fya58Ev57wAAHOlWOWUJAMCMBBkAwGCHDLKqunz6/Z/XNw4AwPJsdw3ZCVX1TUmeWlWX5KDrwbr7/bNOBgCwENsF2Y9n43smT0ryioNe6ySPm2soAIAl2e5O/W9I8oaq+rHufukaZwIAWJRV7kP20qp6ag7ch+xd3f2WeccCAFiOw37Ksqp+IskLsnHD1muTvGBaBgDAXWCVG8M+OckZ3X1HklTVxUn+KMkFcw4GALAUq96H7L6bHv+jGeYAAFisVY6Q/USSP6qqd2bj1hePjqNjAAB3mVUu6n99Vb0ryb/IRpD9cHf/2dyDAQAsxapfLn5TkstmngUAYJF8lyUAwGCCDABgsG2DrKruVlUfXtcwAABLtG2QTfce+0BVPWhN8wAALM4qF/WfkOSaqroiyV/tX9jdT51tKgCABVklyF4y+xQAAAu2yn3I3l1VD05yWnf/blV9eZJj5h8NAGAZVvly8X+b5A1J/vu06MQkvzHjTAAAi7LKbS/OS/KoJJ9Nku7+aJIHzjkUAMCSrBJkt3b3F/Y/qapjk/R8IwEALMsqQfbuqvqRJPesqm9J8mtJfnPesQAAlmOVIDs/yb4kH0ryvCRvS/Kjcw4FALAkq3zK8o6qujjJe7NxqvL67nbKEgDgLnLYIKuqJyd5dZI/TlJJTq2q53X32+ceDgBgCVa5MezLkzy2u/ckSVU9JMlbkwgyAIC7wCrXkN2yP8YmH0tyy0zzAAAsziGPkFXVM6aH11TV25Jcmo1ryJ6Z5H1rmA0AYBG2O2X5lE2Pb07yTdPjfUnuN9tEAAALc8gg6+7nrHMQAIClWuVTlqcm+f4kp2xev7ufOt9YAADLscqnLH8jyWuzcXf+O2adBgBggVYJsr/t7p+bfRIAgIVaJch+tqpelOR3kty6f2F3v3+2qQAAFmSVIPvaJM9O8rgcOGXZ03MAAO6kVYLs6Um+uru/MPcwAABLtMqd+j+Q5L4zzwEAsFirHCE7PslHqup9+eJryNz2AgDgLrBKkL1o9ikAABbssEHW3e9exyAAAEu1yp36P5eNT1Umyd2THJfkr7r7PnMOBgCwFKscIbv35udV9bQkZ841EADA0qzyKcsv0t2/EfcgAwC4y6xyyvIZm57eLcnuHDiFCQDAnbTKpyyfsunxbUluSHLWLNMAACzQKteQPWcdgwAALNUhg6yqfnyb93V3v3SGeQAAFme7I2R/tcWyeyV5bpJ/nESQAQDcBQ4ZZN398v2Pq+reSV6Q5DlJLkny8kO9DwCAL82215BV1f2T/Mck35Xk4iSP7O6/XMdgAABLsd01ZD+Z5BlJLkrytd39+bVNBQCwINvdGPYHk3xVkh9NcmNVfXb6+VxVfXY94wEAHP22u4bsS76LPwAAXzrRBQAwmCADABhMkAEADCbIAAAGE2QAAIPNFmRV9bqquqWqPrxp2Yur6k+r6urp50mbXrugqvZU1fVV9YS55gIA2GnmPEL2i0meuMXyn+7uM6aftyVJVZ2e5OwkD5/e88qqOmbG2QAAdozZgqy735PkL1Zc/awkl3T3rd398SR7kpw512wAADvJiGvInl9VH5xOad5vWnZikk9uWmfvtAwA4Ki37iB7VZKHJDkjyU1JXj4try3W7a3+QFWdW1VXVtWV+/btm2VIAIB1WmuQdffN3X17d9+R5Bdy4LTk3iQnb1r1pCQ3HuJvXNTdu7t7965du+YdGABgDdYaZFV1wqanT0+y/xOYlyU5u6ruUVWnJjktyRXrnA0AYJRDfrn4nVVVr0/ymCQPqKq9SV6U5DFVdUY2TkfekOR5SdLd11TVpUmuTXJbkvO6+/a5ZgMA2ElmC7LuftYWi1+7zfoXJrlwrnkAAHYqd+oHABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGmy3Iqup1VXVLVX1407L7V9U7quqj0+/7bXrtgqraU1XXV9UT5poLAGCnmfMI2S8meeJBy85Pcnl3n5bk8ul5qur0JGcnefj0nldW1TEzzgYAsGPMFmTd/Z4kf3HQ4rOSXDw9vjjJ0zYtv6S7b+3ujyfZk+TMuWYDANhJ1n0N2fHdfVOSTL8fOC0/McknN623d1oGAHDU2ykX9dcWy3rLFavOraorq+rKffv2zTwWAMD81h1kN1fVCUky/b5lWr43ycmb1jspyY1b/YHuvqi7d3f37l27ds06LADAOqw7yC5Lcs70+Jwkb960/OyqukdVnZrktCRXrHk2AIAhjp3rD1fV65M8JskDqmpvkhcleVmSS6vquUk+keSZSdLd11TVpUmuTXJbkvO6+/a5ZgMA2ElmC7LuftYhXnr8Ida/MMmFc80DALBT7ZSL+gEAFkuQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGCCDABgMEEGADCYIAMAGEyQAQAMJsgAAAYTZAAAgx074j9aVTck+VyS25Pc1t27q+r+Sf5XklOS3JDkX3f3X46YDwBgnUYeIXtsd5/R3bun5+cnuby7T0ty+fQcAOCot5NOWZ6V5OLp8cVJnjZuFACA9RkVZJ3kd6rqqqo6d1p2fHfflCTT7wcOmg0AYK2GXEOW5FHdfWNVPTDJO6rqI6u+cQq4c5PkQQ960FzzAQCszZAjZN194/T7liRvSnJmkpur6oQkmX7fcoj3XtTdu7t7965du9Y1MgDAbNYeZFV1r6q69/7HSb41yYeTXJbknGm1c5K8ed2zAQCMMOKU5fFJ3lRV+//7v9rdv1VV70tyaVU9N8knkjxzwGwcZU45/60rrXfDy5488yQAcGhrD7Lu/liSr9ti+aeSPH7d8wAAjLaTbnsBALBIggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAEADCbIAAAGE2QAAIMJMgCAwY4dPQAcaU45/60rrXfDy5488yQAHC0EGSzUyLAUtQBfTJAB/AOtGpaJuAS25xoyAIDBHCFjS04pAcD6OEIGADCYIAMAGMwpS+4UpzaZk/0LWApHyAAABnOEjB3FEREAlsgRMgCAwRwhW5Av5SaW3HlHy9E+Nz8FmJ8jZAAAgzlCxhHJ0T42O1qORgLL5QgZAMBgggwAYDBBBgAwmCADABjMRf0wmAvSAXCEDABgMEfIAHCkFgZzhAwAYDBBBgAwmFOWADuIU4ewTIIM4CC+mgtYN6csAQAGc4QMjjKO7rCZ/QGODI6QAQAMJsgAAAZzyhKAlY38FOio/7ZPvrIOggxgDVzLBWxHkAEwlFgF15ABAAwnyAAABnPKEgDuAl/KqVcfAOBgggyAo4pPRXIkcsoSAGAwQQYAMJggAwAYTJABAAzmon4AWAgfeNi5HCEDABjMETIA4Kh1pBwVdIQMAGCwHRdkVfXEqrq+qvZU1fmj5wEAmNuOOmVZVcck+fkk35Jkb5L3VdVl3X3t2MkA4K5zV59G+1K+tumu/HtznOY7Uk4x3tV2VJAlOTPJnu7+WJJU1SVJzkoyNMiWunMAAOux005Znpjkk5ue752WAQActaq7R8/w96rqmUme0N3/Znr+7CRndvf3b1rn3CTnTk8fluT6tQ+68zwgyZ+PHmIHsB0OsC0OsC0OsC022A4H2BYHrGNbPLi7d231wk47Zbk3ycmbnp+U5MbNK3T3RUkuWudQO11VXdndu0fPMZrtcIBtcYBtcYBtscF2OMC2OGD0tthppyzfl+S0qjq1qu6e5Owklw2eCQBgVjvqCFl331ZVz0/y20mOSfK67r5m8FgAALPaUUGWJN39tiRvGz3HEcYp3A22wwG2xQG2xQG2xQbb4QDb4oCh22JHXdQPALBEO+0aMgCAxRFkR5CqOqaq/qiq3rLFa1VVPzd95dQHq+qRI2Zcl8Nsi8dU1Weq6urp58dHzLgOVXVDVX1o+ndeucXri9kvVtgWi9gvquq+VfWGqvpIVV1XVd9w0OtL2icOty2Wsk88bNO/8eqq+mxVvfCgdRaxX6y4LYbsFzvuGjK29YIk1yW5zxavfVuS06aff5nkVdPvo9V22yJJ/nd3f/sa5xnpsd19qHvnLG2/2G5bJMvYL342yW9193dMn1b/8oNeX9I+cbhtkSxgn+ju65Ockfz9VxT+aZI3HbTaIvaLFbdFMmC/cITsCFFVJyV5cpLXHGKVs5L8Um/4wyT3raoT1jbgGq2wLThgMfsFSVXdJ8mjk7w2Sbr7C9396YNWW8Q+seK2WKLHJ/nj7v6Tg5YvYr84yKG2xRCC7MjxM0l+KMkdh3h9SV879TPZflskyTdU1Qeq6u1V9fD1jDVEJ/mdqrpq+haLgy1pvzjctkiO/v3iq5PsS/I/plP6r6mqex20zlL2iVW2RXL07xMHOzvJ67dYvpT9YrNDbYtkwH4hyI4AVfXtSW7p7qu2W22LZUfdR2hX3Bbvz8bXU3xdkv+a5DfWMdsgj+ruR2bjdMN5VfXog15fxH4xOdy2WMJ+cWySRyZ5VXc/IslfJTn/oHWWsk+ssi2WsE/8vem07VOT/NpWL2+x7GjcL5IcdlsM2S8E2ZHhUUmeWlU3JLkkyeOq6n8etM5hv3bqKHHYbdHdn+3uz0+P35bkuKp6wNonXYPuvnH6fUs2roM486BVlrJfHHZbLGS/2Jtkb3e/d3r+hmxEycHrLGGfOOy2WMg+sdm3JXl/d9+8xWtL2S/2O+S2GLVfCLIjQHdf0N0ndfcp2TjE+nvd/d0HrXZZku+ZPinz9Uk+0903rXvWua2yLarqK6uqpsdnZmM//9Tah51ZVd2rqu69/3GSb03y4YNWW8R+scq2WMJ+0d1/luSTVfWwadHjk1x70GqL2CdW2RZL2CcO8qwc+hTdIvaLTQ65LUbtFz5leQSrqn+XJN396mx8u8GTkuxJ8tdJnjNwtLU7aFt8R5Lvq6rbkvxNkrP76LwD8vFJ3jT9f+PYJL/a3b+10P1ilW2xlP3i+5P8ynRK5mNJnrPQfSI5/LZYyj6RqvryJN+S5Hmbli1yv1hhWwzZL9ypHwBgMKcsAQAGE2QAAIMJMgCAwQQZAMBgggwAYDBBBgAwmCADABhMkAFMquqlVfWCTc8vrKofGDkTsAxuDAswqapTkvx6dz+yqu6W5KNJzuzuo/nrdIAdwFcnAUy6+4aq+lRVPSIbX8f0R2IMWAdBBvDFXpPke5N8ZZLXjR0FWAqnLAE2mb6I+kNJjktyWnffPngkYAEcIQPYpLu/UFXvTPJpMQasiyAD2GS6mP/rkzxz9CzAcrjtBcCkqk5PsifJ5d390dHzAMvhGjIAgMEcIQMAGEyQAQAMJsgAAAYTZAAAgwkyAIDBBBkAwGD/D56HJ+9/Dje6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(all_ys, 50)\n",
    "plt.xlabel(\"y\")\n",
    "plt.ylabel(\"Number of data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, yhat):\n",
    "    return torch.sqrt(torch.mean((y.flatten()-yhat.flatten())**2))\n",
    "\n",
    "def run_vgp_pytorch_experiment(num_inducing, ds_tr_batched, ds_te_batched, kernel_name=None, kernel_params=None, mean_name=\"LinearMean\", beta=1.0, device=\"cpu\", n_epochs=50):\n",
    "    dev = torch.device(device)\n",
    "    net_variational_gp = pinot.Net(\n",
    "        pinot.representation.Sequential(\n",
    "            pinot.representation.dgl_legacy.gn(kwargs={\"allow_zero_in_degree\":True}),\n",
    "                [64, 'relu', 64, 'relu', 64, 'relu']),\n",
    "        output_regressor_class=pinot.regressors.VariationalGP,\n",
    "        n_inducing_points=num_inducing,\n",
    "        beta = beta,\n",
    "        covar = getattr(gpytorch.kernels, kernel_name)(**kernel_params) if kernel_name is not None else None\n",
    "    ).to(dev)\n",
    "    \n",
    "    lr = 1e-4\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': net_variational_gp.representation.parameters(), 'weight_decay': 1e-4},\n",
    "        {'params': net_variational_gp.output_regressor.parameters(), 'lr': lr*0.1}\n",
    "    ], lr=lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    for n in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for (g, y) in ds_tr_batched:\n",
    "            optimizer.zero_grad()\n",
    "            loss = net_variational_gp.loss(g.to(dev), y.flatten().to(dev))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    squared_error_tr = 0.\n",
    "    n_train = 0\n",
    "    squared_error_te = 0.\n",
    "    n_test = 0\n",
    "    \n",
    "    for (g, y) in ds_tr_batched:\n",
    "        n_train += len(y)\n",
    "        yhat = net_variational_gp.condition(g.to(dev)).mean.cpu()\n",
    "        squared_error_tr += torch.sum((y.flatten()-yhat.flatten())**2)\n",
    "        \n",
    "    \n",
    "    for (g, y) in ds_te_batched:\n",
    "        n_test += len(y)\n",
    "        yhat = net_variational_gp.condition(g.to(dev)).mean.cpu()\n",
    "        squared_error_te += torch.sum((y.flatten()-yhat.flatten())**2)\n",
    "    \n",
    "    train_rmse = torch.sqrt(squared_error_tr/n_train)\n",
    "    test_rmse = torch.sqrt(squared_error_te/n_test)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"VGP (Pytorch) Train rmse = {train_rmse}, test rmse = {test_rmse} for {kernel_name} kernel, beta = {beta}, num_inducing_points = {num_inducing}, mean = {mean_name}, time = {end-start}\")\n",
    "    return net_variational_gp\n",
    "    \n",
    "    \n",
    "def run_vgp_experiment(num_inducing, ds_tr_batched, ds_te_batched, kernel_name=None, kernel_params=None, mean_name=\"LinearMean\", beta=1.0, device=\"cpu\", n_epochs=50):\n",
    "    dev = torch.device(device)\n",
    "    net_variational_gp = pinot.Net(\n",
    "        pinot.representation.Sequential(\n",
    "            pinot.representation.dgl_legacy.gn(kwargs={\"allow_zero_in_degree\":True}),\n",
    "                [64, 'relu', 64, 'relu', 64, 'relu']),\n",
    "        output_regressor_class=pinot.regressors.VariationalGaussianProcessRegressor,\n",
    "        n_inducing_points=num_inducing\n",
    "    ).to(dev)\n",
    "    \n",
    "    lr = 1e-4\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': net_variational_gp.representation.parameters(), 'weight_decay': 1e-4},\n",
    "        {'params': net_variational_gp.output_regressor.parameters(), 'lr': lr*0.1}\n",
    "    ], lr=lr)\n",
    "    \n",
    "    start = time.time()\n",
    "    for n in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for (g, y) in ds_tr_batched:\n",
    "            optimizer.zero_grad()\n",
    "            loss = net_variational_gp.loss(g.to(dev), y.flatten().to(dev))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    squared_error_tr = 0.\n",
    "    n_train = 0\n",
    "    squared_error_te = 0.\n",
    "    n_test = 0\n",
    "    \n",
    "    for (g, y) in ds_tr_batched:\n",
    "        n_train += len(y)\n",
    "        yhat = net_variational_gp.condition(g.to(dev)).mean.cpu()\n",
    "        squared_error_tr += torch.sum((y.flatten()-yhat.flatten())**2)\n",
    "        \n",
    "    \n",
    "    for (g, y) in ds_te_batched:\n",
    "        n_test += len(y)\n",
    "        yhat = net_variational_gp.condition(g.to(dev)).mean.cpu()\n",
    "        squared_error_te += torch.sum((y.flatten()-yhat.flatten())**2)\n",
    "    \n",
    "    train_rmse = torch.sqrt(squared_error_tr/n_train)\n",
    "    test_rmse = torch.sqrt(squared_error_te/n_test)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"VGP Train rmse = {train_rmse}, test rmse = {test_rmse} for {kernel_name} kernel, beta = {beta}, num_inducing_points = {num_inducing}, mean = {mean_name}, time = {end-start}\")\n",
    "    return net_variational_gp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ds_tr_batched  = pinot.data.utils.batch(train_data, batch_size)\n",
    "ds_te_batched = pinot.data.utils.batch(test_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGP (Pytorch) Train rmse = 1.0664124488830566, test rmse = 1.153848648071289 for RBFKernel kernel, beta = 1.0, num_inducing_points = 400, mean = LinearMean, time = 476.57427167892456\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "num_inducing = 400\n",
    "vgp_pytorch = run_vgp_pytorch_experiment(num_inducing, ds_tr_batched, ds_te_batched, \"RBFKernel\", {}, device=\"cuda\", n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.3533, 3.3177, 3.5358, 4.5628, 4.4440, 3.9767, 4.9748, 2.5144, 2.9575,\n",
      "        4.4615, 1.6951, 5.4024, 3.9388, 4.8422, 5.5997, 5.3198, 3.4552, 5.9828,\n",
      "        3.7343, 6.1566, 5.1174, 4.4126, 3.8361, 4.6145, 4.1536, 4.4109, 3.5869,\n",
      "        4.3214, 5.6809, 4.0563, 4.3001, 5.1315], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(vgp_pytorch.condition(ds_te_batched[0][0].to(torch.device(\"cuda\"))).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGP Train rmse = 4.60581636428833, test rmse = 4.710196018218994 for RBFKernel kernel, beta = 1.0, num_inducing_points = 400, mean = LinearMean, time = 544.0692403316498\n"
     ]
    }
   ],
   "source": [
    "vgp = run_vgp_experiment(num_inducing, ds_tr_batched, ds_te_batched, \"RBFKernel\", {}, device=\"cuda\", n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2629, 0.2409, 0.2089, 0.2554, 0.2005, 0.2241, 0.2607, 0.2145, 0.2509,\n",
      "        0.2358, 0.2050, 0.2383, 0.2345, 0.2409, 0.2099, 0.2166, 0.2343, 0.2530,\n",
      "        0.2284, 0.2520, 0.2482, 0.2545, 0.2071, 0.2551, 0.2112, 0.2171, 0.2443,\n",
      "        0.2450, 0.2491, 0.2398, 0.2196, 0.2667], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(vgp.condition(ds_te_batched[0][0].to(torch.device(\"cuda\"))).mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
