Sender: LSF System <lsfadmin@lt05>
Subject: Job 15088084: <gpu-semi> in cluster <lila> Done

Job <gpu-semi> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jun 29 15:25:21 2020
Job was executed on host(s) <12*lt05>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jun 29 15:25:21 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jun 29 15:25:21 2020
Terminated at Mon Jun 29 15:27:33 2020
Results reported at Mon Jun 29 15:27:33 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/semi_supervised/semi_supervised_comparison.py --n_epochs 1 --cuda --regressor_type gp --architecture GATConv 64 3 attention_pool concat activation tanh GATConv 128 3 attention_pool mean activation tanh --output /home/nguyenm5/coding/pinot/semi-supervised-out-2020-06-29/ --labeled_data moonshot --unlabeled_data moonshot_unlabeled_small
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   558.23 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.46 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   132 sec.
    Turnaround time :                            132 sec.

The output (if any) follows:



PS:

Read file </home/nguyenm5/coding/pinot/semi-supervised-err/gp_GATConv 64 3 attention_pool concat activation tanh GATConv 128 3 attention_pool mean activation tanh.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt05>
Subject: Job 15088089: <gpu-semi> in cluster <lila> Exited

Job <gpu-semi> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jun 29 15:30:36 2020
Job was executed on host(s) <12*lt05>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jun 29 15:30:37 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jun 29 15:30:37 2020
Terminated at Tue Jun 30 01:30:37 2020
Results reported at Tue Jun 30 01:30:37 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/semi_supervised/semi_supervised_comparison.py --n_epochs 1000 --cuda --regressor_type gp --architecture GATConv 64 3 attention_pool concat activation tanh GATConv 128 3 attention_pool mean activation tanh --output /home/nguyenm5/coding/pinot/semi-supervised-out-2020-06-29/ --labeled_data moonshot --unlabeled_data moonshot_unlabeled_small
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   205509.70 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.98 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   36002 sec.
    Turnaround time :                            36001 sec.

The output (if any) follows:



PS:

Read file </home/nguyenm5/coding/pinot/semi-supervised-err/gp_GATConv 64 3 attention_pool concat activation tanh GATConv 128 3 attention_pool mean activation tanh.stderr> for stderr output of this job.

