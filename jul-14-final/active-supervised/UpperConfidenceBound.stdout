Sender: LSF System <lsfadmin@lt06>
Subject: Job 15333023: <supervised> in cluster <lila> Done

Job <supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Tue Jul 14 11:19:20 2020
Job was executed on host(s) <12*lt06>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Tue Jul 14 11:19:20 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Tue Jul 14 11:19:20 2020
Terminated at Tue Jul 14 11:19:43 2020
Results reported at Tue Jul 14 11:19:43 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition UpperConfidenceBound --output_folder /home/nguyenm5/coding/pinot/jul-14-final/active-supervised --index 3
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   18.04 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.14 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   23 sec.
    Turnaround time :                            23 sec.

The output (if any) follows:

0
Probability of improvement:
tensor([0.3155, 0.4097, 0.2950, 0.3931, 0.3390, 0.3281, 0.3729, 0.4142, 0.4222,
        0.3085, 0.4101, 0.2912, 0.4013, 0.3232, 0.2932, 0.3575, 0.3908, 0.3382,
        0.3239, 0.2920, 0.3263, 0.3080, 0.3396, 0.3333, 0.3774, 0.3000, 0.3753,
        0.3762, 0.2927, 0.2976, 0.2962, 0.2947, 0.4077, 0.2929, 0.3723, 0.4008,
        0.2961, 0.3842, 0.3158, 0.3728, 0.3012, 0.2994, 0.2917, 0.3398, 0.2958,
        0.3231, 0.4021, 0.3004, 0.3213, 0.3922, 0.3869, 0.3327, 0.3084, 0.3538,
        0.3024, 0.3011, 0.3695, 0.3842, 0.3266, 0.3099, 0.3822, 0.3902, 0.3313,
        0.4208, 0.4086, 0.2955, 0.2936, 0.3706, 0.3878, 0.3398, 0.3994, 0.3216,
        0.4096, 0.3216, 0.3746, 0.3242, 0.4278, 0.3083, 0.3812, 0.4239, 0.3964,
        0.3154, 0.3295, 0.3613, 0.3908, 0.3717, 0.3783, 0.2900, 0.2955, 0.3028,
        0.3197, 0.2991, 0.2946, 0.2945, 0.3160, 0.3680, 0.3165, 0.3042, 0.3142,
        0.4022, 0.3373, 0.2844, 0.4441, 0.2800, 0.3041, 0.3633, 0.2972, 0.4148,
        0.2935, 0.4031, 0.4028, 0.4163, 0.4152, 0.4061, 0.2921, 0.3404, 0.3845,
        0.2945, 0.3254, 0.3361, 0.2963, 0.4173, 0.2996, 0.2848, 0.3699, 0.2956,
        0.2966, 0.3087, 0.4087, 0.3340, 0.3157, 0.3879, 0.3113, 0.2939, 0.3323,
        0.4004, 0.3789, 0.4186, 0.3402, 0.3091, 0.4081, 0.3922, 0.3321, 0.3296,
        0.3795, 0.3909, 0.2955, 0.3448, 0.3157, 0.4304, 0.3454, 0.3091, 0.3517,
        0.3915, 0.3923, 0.3141, 0.4057, 0.3155, 0.3549, 0.3705, 0.3213, 0.3060,
        0.3337, 0.3101, 0.3821, 0.3137, 0.2897, 0.4172, 0.3158, 0.3386, 0.3427,
        0.3961, 0.3570, 0.4138, 0.4099, 0.3847, 0.3203, 0.4007, 0.3690, 0.3483,
        0.4201, 0.2984, 0.3191, 0.3010, 0.3895, 0.2766, 0.3574, 0.4062, 0.3979,
        0.3003, 0.2998, 0.4188, 0.2859, 0.3672, 0.4354, 0.3601, 0.3094, 0.3676,
        0.3346, 0.3995, 0.3359, 0.2934, 0.4295, 0.4210, 0.3028, 0.4019, 0.3000,
        0.3007, 0.3919, 0.3455, 0.4211, 0.3789, 0.3372, 0.3360, 0.4288, 0.3412,
        0.3089, 0.2747, 0.4044, 0.3706, 0.2976, 0.3980, 0.3246, 0.3161, 0.3221,
        0.3893, 0.3163, 0.4109, 0.3969, 0.3714, 0.2923, 0.4209, 0.3881, 0.2963,
        0.3435, 0.3414, 0.3715, 0.3082, 0.2944, 0.3713, 0.3328, 0.4317, 0.3276,
        0.2964, 0.3968, 0.3336, 0.2960, 0.4082, 0.3245, 0.3773, 0.3563, 0.4083,
        0.3808, 0.3900, 0.3400, 0.2919, 0.3005, 0.4024, 0.4014, 0.3998, 0.3968,
        0.3330, 0.2924, 0.3267, 0.3600, 0.2991, 0.3734, 0.3892, 0.4070, 0.3752,
        0.3309, 0.3260, 0.4082, 0.4236, 0.3322, 0.3083, 0.4186, 0.3052, 0.3397,
        0.3833, 0.3036, 0.2964, 0.4130, 0.4072, 0.3179, 0.2952, 0.3985, 0.3278,
        0.3445, 0.3629, 0.4214, 0.3831, 0.3192, 0.3358, 0.3895, 0.4102, 0.3165,
        0.3873, 0.3805, 0.3842, 0.3225, 0.3445, 0.3374, 0.3204, 0.3245, 0.2930,
        0.4036, 0.3118, 0.3040, 0.3575, 0.4303, 0.3240, 0.3028, 0.3310, 0.3137,
        0.2902, 0.3957, 0.4015, 0.2962, 0.3959, 0.4438, 0.3294, 0.3835, 0.3162,
        0.3809, 0.3204, 0.3962, 0.3947, 0.3373, 0.3388, 0.2992, 0.3781, 0.3151,
        0.3961, 0.4240, 0.3475, 0.3390, 0.3562, 0.3495, 0.3173, 0.4117, 0.3036,
        0.3709, 0.2965, 0.3640, 0.3751, 0.3391, 0.3801, 0.3338, 0.3567, 0.2942,
        0.3251, 0.3037, 0.3897, 0.3856, 0.2955, 0.3124, 0.3157, 0.3588, 0.3770,
        0.4151, 0.4178, 0.3067, 0.4004, 0.4005, 0.4082, 0.3549, 0.3561, 0.3026,
        0.3211, 0.3426, 0.3843, 0.2952, 0.3201], device='cuda:0',
       grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4441, device='cuda:0')
That took 11.22105097770691 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14-final/active-supervised/UpperConfidenceBound.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt22>
Subject: Job 15333021: <supervised> in cluster <lila> Done

Job <supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Tue Jul 14 11:19:19 2020
Job was executed on host(s) <12*lt22>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Tue Jul 14 11:19:20 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Tue Jul 14 11:19:20 2020
Terminated at Tue Jul 14 11:19:53 2020
Results reported at Tue Jul 14 11:19:53 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition UpperConfidenceBound --output_folder /home/nguyenm5/coding/pinot/jul-14-final/active-supervised --index 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   29.83 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.26 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   34 sec.
    Turnaround time :                            34 sec.

The output (if any) follows:

0
Probability of improvement:
tensor([0.4954, 0.4936, 0.4953, 0.4937, 0.4946, 0.4954, 0.4944, 0.4936, 0.4933,
        0.4962, 0.4932, 0.4951, 0.4931, 0.4963, 0.4950, 0.4947, 0.4931, 0.4954,
        0.4962, 0.4951, 0.4962, 0.4973, 0.4947, 0.4957, 0.4943, 0.4958, 0.4943,
        0.4942, 0.4951, 0.4958, 0.4954, 0.4955, 0.4931, 0.4951, 0.4941, 0.4929,
        0.4956, 0.4942, 0.4967, 0.4926, 0.4958, 0.4957, 0.4949, 0.4954, 0.4956,
        0.4964, 0.4938, 0.4962, 0.4961, 0.4939, 0.4928, 0.4959, 0.4962, 0.4951,
        0.4959, 0.4964, 0.4944, 0.4941, 0.4956, 0.4965, 0.4942, 0.4928, 0.4958,
        0.4932, 0.4937, 0.4955, 0.4955, 0.4944, 0.4928, 0.4920, 0.4929, 0.4963,
        0.4931, 0.4963, 0.4941, 0.4959, 0.4934, 0.4966, 0.4943, 0.4933, 0.4939,
        0.4969, 0.4957, 0.4947, 0.4931, 0.4939, 0.4941, 0.4946, 0.4955, 0.4964,
        0.4960, 0.4961, 0.4953, 0.4954, 0.4968, 0.4944, 0.4965, 0.4958, 0.4964,
        0.4930, 0.4952, 0.4938, 0.4934, 0.4927, 0.4959, 0.4946, 0.4954, 0.4936,
        0.4951, 0.4938, 0.4937, 0.4936, 0.4936, 0.4931, 0.4951, 0.4957, 0.4930,
        0.4954, 0.4959, 0.4956, 0.4955, 0.4931, 0.4962, 0.4938, 0.4943, 0.4955,
        0.4955, 0.4966, 0.4933, 0.4958, 0.4962, 0.4927, 0.4961, 0.4954, 0.4956,
        0.4939, 0.4926, 0.4932, 0.4954, 0.4965, 0.4931, 0.4928, 0.4957, 0.4960,
        0.4943, 0.4939, 0.4957, 0.4949, 0.4961, 0.4934, 0.4949, 0.4970, 0.4948,
        0.4938, 0.4939, 0.4968, 0.4931, 0.4965, 0.4947, 0.4946, 0.4962, 0.4966,
        0.4957, 0.4966, 0.4927, 0.4970, 0.4945, 0.4931, 0.4965, 0.4955, 0.4952,
        0.4930, 0.4948, 0.4936, 0.4936, 0.4941, 0.4965, 0.4939, 0.4944, 0.4952,
        0.4932, 0.4959, 0.4964, 0.4957, 0.4940, 0.4918, 0.4945, 0.4938, 0.4938,
        0.4959, 0.4961, 0.4932, 0.4940, 0.4946, 0.4934, 0.4947, 0.4965, 0.4946,
        0.4956, 0.4934, 0.4953, 0.4951, 0.4933, 0.4933, 0.4958, 0.4937, 0.4956,
        0.4958, 0.4938, 0.4951, 0.4934, 0.4943, 0.4956, 0.4957, 0.4933, 0.4953,
        0.4959, 0.4911, 0.4938, 0.4940, 0.4958, 0.4929, 0.4963, 0.4961, 0.4960,
        0.4928, 0.4963, 0.4936, 0.4935, 0.4939, 0.4949, 0.4936, 0.4941, 0.4955,
        0.4954, 0.4953, 0.4941, 0.4976, 0.4955, 0.4944, 0.4959, 0.4934, 0.4961,
        0.4956, 0.4935, 0.4958, 0.4956, 0.4931, 0.4963, 0.4942, 0.4949, 0.4936,
        0.4927, 0.4928, 0.4957, 0.4952, 0.4960, 0.4936, 0.4938, 0.4929, 0.4938,
        0.4958, 0.4949, 0.4960, 0.4950, 0.4960, 0.4944, 0.4941, 0.4931, 0.4944,
        0.4959, 0.4958, 0.4931, 0.4933, 0.4958, 0.4962, 0.4932, 0.4956, 0.4957,
        0.4941, 0.4958, 0.4953, 0.4932, 0.4936, 0.4953, 0.4956, 0.4929, 0.4960,
        0.4952, 0.4946, 0.4935, 0.4941, 0.4961, 0.4954, 0.4928, 0.4936, 0.4968,
        0.4928, 0.4942, 0.4941, 0.4960, 0.4952, 0.4921, 0.4953, 0.4963, 0.4951,
        0.4931, 0.4965, 0.4962, 0.4947, 0.4933, 0.4958, 0.4958, 0.4957, 0.4963,
        0.4947, 0.4932, 0.4930, 0.4953, 0.4928, 0.4934, 0.4962, 0.4937, 0.4963,
        0.4942, 0.4964, 0.4928, 0.4939, 0.4955, 0.4952, 0.4962, 0.4941, 0.4969,
        0.4934, 0.4935, 0.4950, 0.4920, 0.4949, 0.4949, 0.4961, 0.4930, 0.4963,
        0.4945, 0.4955, 0.4925, 0.4943, 0.4920, 0.4941, 0.4957, 0.4948, 0.4953,
        0.4961, 0.4962, 0.4929, 0.4941, 0.4955, 0.4962, 0.4961, 0.4948, 0.4944,
        0.4936, 0.4932, 0.4966, 0.4940, 0.4929, 0.4930, 0.4947, 0.4948, 0.4963,
        0.4966, 0.4953, 0.4941, 0.4951, 0.4964], device='cuda:0',
       grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4976, device='cuda:0')
Probability of improvement:
tensor([3.8385e-05, 0.0000e+00, 1.1921e-07, 3.0442e-02, 8.8003e-02, 3.5763e-07,
        1.7303e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4484e-04,
        0.0000e+00, 0.0000e+00, 4.2140e-04, 2.2954e-03, 2.4115e-01, 1.1921e-07,
        0.0000e+00, 8.3447e-07, 0.0000e+00, 1.0729e-05, 8.0081e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2727e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 4.4362e-02, 4.8459e-05, 2.4712e-04, 2.4378e-05, 1.3111e-02,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9802e-07, 0.0000e+00, 5.1618e-05,
        3.5763e-07, 0.0000e+00, 0.0000e+00, 8.5652e-04, 2.3842e-07, 7.8330e-02,
        1.1283e-04, 6.3449e-04, 0.0000e+00, 0.0000e+00, 1.0431e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.0814e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0214e-04, 5.9605e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0729e-06,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3471e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3115e-04, 0.0000e+00, 5.2512e-05, 1.7881e-07,
        2.0845e-01, 5.9605e-08, 5.6380e-02, 0.0000e+00, 0.0000e+00, 2.6652e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4901e-06, 3.9458e-04, 2.1560e-01,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5896e-05, 1.0839e-02,
        4.2915e-06, 0.0000e+00, 1.1921e-07, 0.0000e+00, 1.9711e-03, 0.0000e+00,
        0.0000e+00, 7.1526e-07, 3.0945e-01, 2.2901e-03, 1.7583e-04, 0.0000e+00,
        7.1526e-07, 0.0000e+00, 1.1921e-07, 4.9710e-04, 1.1921e-07, 7.3649e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3181e-02, 1.1647e-04, 0.0000e+00,
        1.0550e-05, 9.7668e-04, 0.0000e+00, 2.7336e-02, 6.2138e-03, 0.0000e+00,
        0.0000e+00, 3.5207e-03, 1.9372e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4734e-04,
        0.0000e+00, 0.0000e+00, 2.3371e-02, 5.2333e-05, 9.5367e-07, 0.0000e+00,
        0.0000e+00, 2.3842e-06, 6.2444e-03, 8.8681e-02, 0.0000e+00, 2.3842e-07,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6757e-02, 5.4754e-03, 7.7486e-07,
        2.0742e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0564e-02, 0.0000e+00,
        0.0000e+00, 1.4608e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.0548e-03, 0.0000e+00, 3.9995e-05, 0.0000e+00, 4.3571e-04, 4.7684e-07,
        0.0000e+00, 3.6359e-05, 0.0000e+00, 0.0000e+00, 2.3842e-06, 0.0000e+00,
        1.1921e-07, 2.7540e-02, 7.8082e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.6202e-03, 0.0000e+00, 0.0000e+00, 4.0026e-03, 1.4305e-06, 0.0000e+00,
        4.1723e-07, 0.0000e+00, 4.7588e-02, 1.4770e-04, 1.0705e-04, 0.0000e+00,
        0.0000e+00, 4.3467e-02, 0.0000e+00, 0.0000e+00, 7.1526e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.1904e-03, 2.4327e-02, 4.9263e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.2983e-06, 1.1921e-07, 1.1921e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 3.5763e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.9535e-01, 5.7680e-03, 0.0000e+00, 0.0000e+00, 1.1921e-07,
        8.7768e-04, 0.0000e+00, 1.0610e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.0610e-05, 7.7420e-04, 4.7499e-02, 0.0000e+00,
        1.1921e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.4651e-04, 1.3113e-06, 6.7949e-06, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0201e-06,
        8.7428e-04, 4.1723e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 5.9605e-08, 0.0000e+00, 0.0000e+00, 1.1921e-07, 0.0000e+00,
        0.0000e+00, 2.1532e-01, 5.2452e-06, 1.6093e-05, 0.0000e+00, 3.8614e-03,
        0.0000e+00, 1.8623e-01, 0.0000e+00, 0.0000e+00, 1.6093e-06, 3.4392e-05,
        0.0000e+00, 0.0000e+00, 2.0730e-04, 0.0000e+00, 0.0000e+00, 4.7755e-04,
        2.6226e-06, 3.5763e-07, 0.0000e+00, 1.1921e-07, 1.0252e-05, 6.5947e-04,
        0.0000e+00, 0.0000e+00, 1.2517e-06, 4.3541e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.1116e-04, 0.0000e+00, 5.9605e-08, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0599e-06, 0.0000e+00,
        0.0000e+00, 8.3447e-07, 0.0000e+00, 1.9765e-03, 2.4783e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9605e-08, 0.0000e+00, 6.1470e-02,
        0.0000e+00, 1.2972e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0958e-03,
        2.6226e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5711e-01,
        4.9976e-03, 1.7414e-02, 0.0000e+00, 0.0000e+00, 7.2348e-04, 0.0000e+00,
        0.0000e+00, 4.4703e-05, 3.5763e-07, 8.3447e-07, 0.0000e+00, 4.7684e-07,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.8387e-03, 1.7299e-03, 1.0837e-03, 1.1746e-03, 8.4639e-06, 0.0000e+00,
        0.0000e+00, 9.2342e-02], device='cuda:0', grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.3095, device='cuda:0')
That took 20.183706521987915 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14-final/active-supervised/UpperConfidenceBound.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt06>
Subject: Job 15333022: <supervised> in cluster <lila> Done

Job <supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Tue Jul 14 11:19:20 2020
Job was executed on host(s) <12*lt06>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Tue Jul 14 11:19:20 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Tue Jul 14 11:19:20 2020
Terminated at Tue Jul 14 11:20:06 2020
Results reported at Tue Jul 14 11:20:06 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition UpperConfidenceBound --output_folder /home/nguyenm5/coding/pinot/jul-14-final/active-supervised --index 2
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   182.93 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.52 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   46 sec.
    Turnaround time :                            46 sec.

The output (if any) follows:

0
Probability of improvement:
tensor([0.4539, 0.4733, 0.4503, 0.4714, 0.4579, 0.4563, 0.4650, 0.4730, 0.4782,
        0.4528, 0.4811, 0.4497, 0.4805, 0.4555, 0.4500, 0.4622, 0.4800, 0.4584,
        0.4554, 0.4498, 0.4557, 0.4528, 0.4579, 0.4571, 0.4653, 0.4512, 0.4654,
        0.4656, 0.4499, 0.4507, 0.4505, 0.4502, 0.4826, 0.4499, 0.4669, 0.4851,
        0.4505, 0.4668, 0.4540, 0.4771, 0.4515, 0.4509, 0.4497, 0.4586, 0.4504,
        0.4550, 0.4701, 0.4512, 0.4550, 0.4688, 0.4820, 0.4567, 0.4526, 0.4607,
        0.4512, 0.4515, 0.4643, 0.4671, 0.4570, 0.4530, 0.4659, 0.4823, 0.4572,
        0.4816, 0.4712, 0.4503, 0.4501, 0.4646, 0.4823, 0.4666, 0.4869, 0.4552,
        0.4823, 0.4550, 0.4655, 0.4560, 0.4760, 0.4525, 0.4661, 0.4781, 0.4694,
        0.4541, 0.4562, 0.4628, 0.4803, 0.4667, 0.4666, 0.4493, 0.4503, 0.4517,
        0.4552, 0.4510, 0.4502, 0.4502, 0.4541, 0.4644, 0.4541, 0.4517, 0.4538,
        0.4840, 0.4585, 0.4484, 0.4770, 0.4478, 0.4519, 0.4631, 0.4504, 0.4732,
        0.4500, 0.4703, 0.4719, 0.4730, 0.4743, 0.4825, 0.4498, 0.4579, 0.4796,
        0.4502, 0.4558, 0.4578, 0.4504, 0.4822, 0.4510, 0.4485, 0.4648, 0.4504,
        0.4505, 0.4529, 0.4761, 0.4570, 0.4537, 0.4813, 0.4533, 0.4501, 0.4572,
        0.4696, 0.4787, 0.4823, 0.4584, 0.4528, 0.4826, 0.4831, 0.4570, 0.4564,
        0.4652, 0.4684, 0.4504, 0.4600, 0.4540, 0.4756, 0.4607, 0.4528, 0.4601,
        0.4697, 0.4681, 0.4539, 0.4806, 0.4539, 0.4625, 0.4638, 0.4546, 0.4520,
        0.4572, 0.4525, 0.4810, 0.4536, 0.4493, 0.4825, 0.4542, 0.4583, 0.4592,
        0.4798, 0.4620, 0.4727, 0.4732, 0.4673, 0.4547, 0.4693, 0.4641, 0.4596,
        0.4820, 0.4508, 0.4547, 0.4513, 0.4684, 0.4473, 0.4628, 0.4706, 0.4691,
        0.4512, 0.4511, 0.4823, 0.4486, 0.4631, 0.4774, 0.4623, 0.4529, 0.4635,
        0.4575, 0.4745, 0.4581, 0.4500, 0.4793, 0.4784, 0.4517, 0.4716, 0.4511,
        0.4512, 0.4692, 0.4599, 0.4757, 0.4652, 0.4577, 0.4574, 0.4776, 0.4585,
        0.4529, 0.4471, 0.4710, 0.4663, 0.4507, 0.4867, 0.4552, 0.4539, 0.4553,
        0.4823, 0.4541, 0.4712, 0.4737, 0.4667, 0.4498, 0.4730, 0.4670, 0.4505,
        0.4583, 0.4592, 0.4659, 0.4529, 0.4502, 0.4644, 0.4567, 0.4756, 0.4558,
        0.4506, 0.4728, 0.4567, 0.4506, 0.4823, 0.4551, 0.4660, 0.4610, 0.4729,
        0.4806, 0.4819, 0.4578, 0.4498, 0.4512, 0.4718, 0.4702, 0.4873, 0.4698,
        0.4571, 0.4499, 0.4559, 0.4613, 0.4511, 0.4647, 0.4676, 0.4816, 0.4642,
        0.4570, 0.4563, 0.4823, 0.4786, 0.4573, 0.4527, 0.4823, 0.4519, 0.4578,
        0.4671, 0.4518, 0.4504, 0.4798, 0.4728, 0.4548, 0.4504, 0.4825, 0.4562,
        0.4595, 0.4631, 0.4744, 0.4669, 0.4553, 0.4576, 0.4820, 0.4735, 0.4541,
        0.4822, 0.4660, 0.4666, 0.4553, 0.4595, 0.4661, 0.4553, 0.4552, 0.4499,
        0.4808, 0.4533, 0.4519, 0.4622, 0.4783, 0.4562, 0.4518, 0.4569, 0.4536,
        0.4494, 0.4770, 0.4833, 0.4506, 0.4829, 0.4770, 0.4559, 0.4708, 0.4539,
        0.4661, 0.4549, 0.4824, 0.4698, 0.4583, 0.4585, 0.4510, 0.4668, 0.4536,
        0.4753, 0.4740, 0.4604, 0.4663, 0.4615, 0.4599, 0.4544, 0.4834, 0.4519,
        0.4642, 0.4505, 0.4752, 0.4653, 0.4664, 0.4668, 0.4572, 0.4614, 0.4501,
        0.4558, 0.4520, 0.4838, 0.4675, 0.4504, 0.4539, 0.4540, 0.4617, 0.4649,
        0.4729, 0.4824, 0.4523, 0.4689, 0.4876, 0.4838, 0.4614, 0.4615, 0.4517,
        0.4546, 0.4589, 0.4675, 0.4500, 0.4551], device='cuda:0',
       grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4876, device='cuda:0')
Probability of improvement:
tensor([0.0000e+00, 1.3201e-02, 0.0000e+00, 4.9806e-04, 1.1144e-02, 1.5855e-04,
        1.0848e-02, 3.0271e-03, 7.3167e-02, 0.0000e+00, 4.2650e-02, 0.0000e+00,
        7.2682e-02, 4.9472e-06, 0.0000e+00, 3.9852e-04, 1.0459e-02, 1.6850e-04,
        4.0054e-05, 0.0000e+00, 5.4240e-06, 0.0000e+00, 7.2995e-03, 5.7340e-04,
        9.6594e-03, 0.0000e+00, 6.4923e-03, 1.9728e-03, 2.3842e-07, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 4.8506e-02, 0.0000e+00, 4.5075e-03, 3.1793e-04,
        0.0000e+00, 1.5769e-02, 3.2067e-05, 4.7159e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 2.2054e-03, 0.0000e+00, 0.0000e+00, 3.5409e-02, 1.6689e-06,
        1.8665e-03, 1.1928e-02, 9.0951e-02, 7.0528e-03, 0.0000e+00, 2.7728e-04,
        0.0000e+00, 0.0000e+00, 5.8314e-03, 5.4992e-03, 0.0000e+00, 0.0000e+00,
        4.8897e-03, 4.2140e-02, 2.1571e-04, 4.4894e-04, 7.1891e-02, 0.0000e+00,
        0.0000e+00, 5.9702e-03, 7.8392e-02, 1.1332e-01, 2.9433e-02, 0.0000e+00,
        2.3986e-02, 2.1827e-03, 5.7519e-03, 4.7684e-07, 3.2408e-02, 0.0000e+00,
        6.7917e-03, 3.6378e-02, 1.5362e-02, 5.9605e-08, 1.5134e-03, 1.1141e-03,
        1.0489e-02, 0.0000e+00, 4.0767e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        4.1842e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7899e-04, 8.9288e-05,
        2.6822e-05, 0.0000e+00, 0.0000e+00, 8.4324e-02, 7.4148e-05, 1.1921e-07,
        3.1606e-03, 0.0000e+00, 0.0000e+00, 8.7873e-03, 0.0000e+00, 6.3908e-02,
        0.0000e+00, 1.2682e-03, 2.3190e-03, 1.0352e-02, 8.9583e-03, 8.2250e-02,
        1.5497e-06, 1.2063e-03, 1.1452e-02, 0.0000e+00, 5.8413e-04, 5.6028e-06,
        0.0000e+00, 8.5295e-03, 0.0000e+00, 0.0000e+00, 1.2406e-02, 0.0000e+00,
        2.2000e-03, 7.6294e-06, 4.9343e-02, 1.7226e-03, 2.2173e-05, 2.8129e-02,
        0.0000e+00, 0.0000e+00, 3.3938e-03, 9.0120e-03, 3.0461e-02, 1.9440e-02,
        9.7013e-03, 0.0000e+00, 4.6648e-02, 5.9340e-02, 8.3142e-03, 1.5426e-03,
        9.1066e-03, 1.4849e-03, 0.0000e+00, 4.1354e-04, 5.6696e-04, 5.1725e-03,
        0.0000e+00, 0.0000e+00, 1.0014e-02, 4.9788e-04, 4.3081e-03, 3.9029e-04,
        6.6865e-02, 7.1526e-06, 1.0049e-04, 1.0144e-02, 1.1921e-07, 0.0000e+00,
        7.2946e-03, 5.9605e-08, 4.3900e-02, 1.0893e-03, 1.2934e-05, 2.1642e-02,
        7.1526e-07, 3.2597e-03, 7.2266e-03, 2.5117e-02, 4.2558e-03, 2.6108e-02,
        1.0615e-02, 8.4074e-03, 8.4708e-03, 1.0303e-02, 6.2227e-05, 1.1921e-07,
        2.1507e-03, 2.3842e-07, 3.8385e-05, 0.0000e+00, 2.3130e-03, 3.3379e-05,
        2.9993e-04, 5.8656e-02, 1.3137e-04, 5.7459e-05, 0.0000e+00, 1.7248e-02,
        0.0000e+00, 5.7825e-03, 5.6836e-02, 2.3842e-07, 0.0000e+00, 1.0555e-02,
        1.0860e-03, 6.9181e-03, 1.3486e-03, 5.4777e-05, 5.2295e-02, 7.6374e-02,
        1.6451e-05, 1.3620e-03, 0.0000e+00, 4.0531e-06, 1.1824e-02, 7.4955e-03,
        1.3597e-02, 2.0165e-03, 2.3842e-07, 6.2090e-04, 9.2993e-03, 1.2118e-03,
        0.0000e+00, 3.5763e-05, 8.7990e-03, 1.7409e-03, 0.0000e+00, 4.7553e-02,
        6.2001e-04, 0.0000e+00, 1.8009e-03, 3.8099e-02, 2.5928e-05, 9.7145e-03,
        8.6187e-03, 0.0000e+00, 0.0000e+00, 2.3069e-02, 9.7117e-03, 0.0000e+00,
        6.1839e-03, 4.1938e-04, 3.7214e-03, 0.0000e+00, 0.0000e+00, 1.3590e-05,
        7.3180e-03, 6.8758e-03, 1.4055e-03, 0.0000e+00, 1.0994e-02, 9.9334e-03,
        0.0000e+00, 6.2153e-02, 5.1177e-04, 3.1698e-04, 5.3780e-03, 1.3778e-02,
        5.1582e-02, 2.2584e-03, 8.2445e-04, 0.0000e+00, 0.0000e+00, 2.2544e-03,
        6.1019e-02, 2.0855e-02, 9.4832e-03, 9.9599e-05, 0.0000e+00, 1.0729e-06,
        9.4466e-03, 0.0000e+00, 8.7148e-03, 4.7665e-03, 8.2117e-03, 7.0619e-03,
        2.1279e-05, 1.7464e-05, 6.2794e-02, 6.0976e-04, 3.2187e-06, 0.0000e+00,
        1.8331e-02, 0.0000e+00, 5.2059e-04, 8.9371e-03, 0.0000e+00, 0.0000e+00,
        6.0708e-02, 7.9306e-03, 2.2185e-04, 0.0000e+00, 5.0941e-03, 2.6226e-06,
        8.9634e-03, 7.9036e-05, 1.0480e-03, 4.1014e-03, 3.5499e-03, 2.2238e-03,
        2.1451e-02, 5.8073e-03, 4.0251e-04, 1.0454e-01, 4.1450e-02, 4.6034e-03,
        9.2021e-03, 1.4064e-03, 1.0932e-01, 4.7684e-07, 5.4705e-04, 0.0000e+00,
        4.0140e-02, 1.2517e-06, 0.0000e+00, 1.5643e-03, 8.9433e-03, 0.0000e+00,
        2.2054e-05, 5.8699e-04, 2.9385e-05, 0.0000e+00, 3.0859e-02, 9.6039e-03,
        0.0000e+00, 1.7356e-03, 6.2597e-04, 0.0000e+00, 1.1132e-03, 3.8604e-03,
        1.7778e-02, 1.1921e-07, 8.4499e-03, 1.0327e-02, 9.4414e-05, 9.0928e-03,
        0.0000e+00, 4.8631e-03, 0.0000e+00, 1.0475e-02, 5.7741e-02, 2.6345e-05,
        1.1577e-01, 2.7355e-02, 1.3471e-05, 0.0000e+00, 8.6380e-03, 0.0000e+00,
        9.5751e-03, 5.9605e-07, 9.6994e-02, 7.0698e-03, 1.1526e-01, 7.1555e-03,
        3.5707e-03, 1.1420e-04, 0.0000e+00, 2.8849e-05, 1.0529e-03, 3.7455e-02,
        9.0703e-03, 0.0000e+00, 1.1921e-07, 4.8494e-04, 5.4581e-03, 9.6632e-03,
        2.9171e-02, 2.1736e-02, 0.0000e+00, 6.7900e-03, 1.3328e-04, 1.5122e-02,
        6.5565e-07, 7.0751e-03, 0.0000e+00, 0.0000e+00, 9.3205e-03, 8.8543e-03,
        4.7133e-03, 5.4836e-05], device='cuda:0', grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.1158, device='cuda:0')
Probability of improvement:
tensor([1.8891e-03, 0.0000e+00, 0.0000e+00, 6.9857e-05, 0.0000e+00, 9.6107e-03,
        0.0000e+00, 6.4373e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 7.8678e-06, 0.0000e+00, 6.7707e-03, 1.0540e-01, 6.8545e-06,
        0.0000e+00, 0.0000e+00, 7.5424e-04, 0.0000e+00, 0.0000e+00, 2.4259e-04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3842e-07, 3.5763e-07, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5964e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.9407e-07, 1.0067e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.5060e-03, 0.0000e+00, 5.0664e-06, 0.0000e+00, 0.0000e+00,
        7.8369e-03, 0.0000e+00, 0.0000e+00, 1.6536e-02, 0.0000e+00, 4.2427e-04,
        0.0000e+00, 0.0000e+00, 4.2319e-05, 2.1970e-04, 5.4854e-04, 0.0000e+00,
        4.5300e-05, 0.0000e+00, 1.6093e-06, 1.2040e-05, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.5076e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9683e-05, 1.7250e-03,
        8.0937e-02, 1.1486e-02, 1.8954e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        3.5763e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5032e-04, 1.1151e-02,
        5.3525e-05, 0.0000e+00, 6.5565e-07, 0.0000e+00, 6.8982e-03, 5.9605e-08,
        2.6226e-06, 0.0000e+00, 0.0000e+00, 1.1257e-03, 3.5763e-07, 0.0000e+00,
        0.0000e+00, 3.5763e-07, 4.2899e-03, 2.3944e-03, 2.6345e-04, 0.0000e+00,
        2.3842e-07, 2.4516e-02, 0.0000e+00, 0.0000e+00, 3.6664e-03, 1.6749e-04,
        0.0000e+00, 9.7752e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        9.3579e-05, 1.7524e-05, 0.0000e+00, 1.7405e-05, 2.0878e-03, 0.0000e+00,
        1.4001e-04, 0.0000e+00, 4.3511e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        6.0691e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6901e-02, 0.0000e+00,
        1.8358e-05, 0.0000e+00, 0.0000e+00, 1.1262e-02, 3.5886e-03, 1.6403e-04,
        9.2983e-06, 0.0000e+00, 0.0000e+00, 6.5941e-03, 1.4880e-03, 3.5882e-05,
        0.0000e+00, 3.1114e-05, 3.3617e-05, 5.9605e-08, 2.1642e-04, 0.0000e+00,
        1.7651e-02, 0.0000e+00, 0.0000e+00, 3.4022e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 9.0599e-06, 2.1624e-02, 0.0000e+00, 3.7516e-03, 0.0000e+00,
        2.7996e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1351e-03, 2.6126e-03,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9605e-08, 1.9073e-06,
        2.3961e-05, 0.0000e+00, 5.8585e-04, 2.2650e-06, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 1.3930e-02, 0.0000e+00, 1.1098e-02, 0.0000e+00, 0.0000e+00,
        1.3284e-02, 1.8785e-02, 0.0000e+00, 5.6028e-06, 0.0000e+00, 0.0000e+00,
        1.6689e-06, 3.9679e-04, 0.0000e+00, 2.7418e-05, 0.0000e+00, 1.2190e-03,
        0.0000e+00, 1.7015e-02, 1.1878e-02, 1.1023e-02, 8.0640e-03, 5.3949e-03,
        0.0000e+00, 8.3447e-07, 5.9605e-08, 5.7311e-03, 0.0000e+00, 0.0000e+00,
        2.8149e-03, 1.8954e-05, 5.3060e-04, 0.0000e+00, 8.3447e-07, 0.0000e+00,
        1.4126e-05, 6.8187e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        1.0500e-03, 2.4438e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2558e-03,
        1.1896e-02, 5.3084e-04, 1.4484e-05, 0.0000e+00, 0.0000e+00, 3.2641e-03,
        0.0000e+00, 0.0000e+00, 2.3631e-03, 7.8427e-03, 8.0144e-04, 0.0000e+00,
        0.0000e+00, 4.2915e-06, 2.4817e-02, 0.0000e+00, 0.0000e+00, 1.9491e-05,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4346e-05, 0.0000e+00, 4.9436e-04,
        5.9605e-08, 0.0000e+00, 1.5676e-05, 1.8120e-05, 0.0000e+00, 1.4186e-05,
        1.0312e-05, 3.6120e-05, 0.0000e+00, 1.0633e-04, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 2.3224e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 3.4142e-03, 8.2394e-03, 0.0000e+00, 1.4421e-03, 6.7072e-03,
        3.1609e-03, 2.8545e-03, 1.1735e-03, 1.3152e-03, 4.3243e-04, 1.8105e-02,
        0.0000e+00, 1.1086e-05, 7.8785e-04, 0.0000e+00, 1.4067e-05, 8.9633e-04,
        7.3857e-03, 6.2346e-05, 0.0000e+00, 4.5967e-04, 1.9392e-03, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6112e-03, 3.9661e-04, 3.5107e-05,
        4.7684e-06, 3.1481e-03, 7.4387e-04, 5.9605e-08, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 7.9632e-05, 7.5102e-06, 1.8853e-02, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5198e-04, 1.9513e-03, 3.4673e-03,
        0.0000e+00, 2.0710e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4547e-03,
        0.0000e+00, 0.0000e+00, 1.1761e-03, 1.0133e-06, 2.7337e-03, 0.0000e+00,
        0.0000e+00, 3.5763e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5497e-06,
        1.6570e-05, 1.4705e-02, 0.0000e+00, 8.8215e-05, 3.8117e-04, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 1.7881e-07, 2.3293e-03, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9605e-08, 0.0000e+00, 0.0000e+00,
        1.5453e-02, 1.7205e-03, 0.0000e+00, 1.1921e-06, 2.3842e-07, 4.7261e-04,
        3.1937e-03, 3.5763e-06], device='cuda:0', grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.1054, device='cuda:0')
That took 34.03538274765015 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14-final/active-supervised/UpperConfidenceBound.stderr> for stderr output of this job.

