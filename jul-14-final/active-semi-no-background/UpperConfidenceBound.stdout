Sender: LSF System <lsfadmin@lt06>
Subject: Job 15333033: <supervised> in cluster <lila> Done

Job <supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Tue Jul 14 11:25:06 2020
Job was executed on host(s) <12*lt06>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Tue Jul 14 11:25:07 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Tue Jul 14 11:25:07 2020
Terminated at Tue Jul 14 12:33:04 2020
Results reported at Tue Jul 14 12:33:04 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net semi --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition UpperConfidenceBound --output_folder /home/nguyenm5/coding/pinot/jul-14-final/active-semi-no-background --index 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   40657.17 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.99 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   4078 sec.
    Turnaround time :                            4078 sec.

The output (if any) follows:

0
Probability of improvement:
tensor([0.5489, 0.5488, 0.5489, 0.5456, 0.5489, 0.5489, 0.5489, 0.5488, 0.5489,
        0.5489, 0.5461, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5486, 0.5489, 0.5489, 0.5488,
        0.5489, 0.5487, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5484, 0.5489, 0.5489, 0.5489, 0.5486, 0.5489,
        0.5486, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5484, 0.5489,
        0.5469, 0.5489, 0.5474, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5487, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5440, 0.5419, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5472, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5487, 0.5489, 0.5482, 0.5489, 0.5489, 0.5483, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5488, 0.5489, 0.5489, 0.5489, 0.5397, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5487, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5488, 0.5489, 0.5489, 0.5483, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5479, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5467, 0.5489, 0.5489, 0.5489, 0.5484, 0.5489, 0.5489, 0.5484, 0.5489,
        0.5489, 0.5489, 0.5481, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5483,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5474, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5485, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5484, 0.5489, 0.5489, 0.5488, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5488, 0.5487, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5427, 0.5489,
        0.5489, 0.5114, 0.5489, 0.5489, 0.5440, 0.5489, 0.5488, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5398, 0.5487, 0.5489,
        0.5489, 0.5489, 0.5441, 0.5489, 0.5489, 0.5489, 0.5479, 0.5489, 0.5489,
        0.5488, 0.5489, 0.5489, 0.5489, 0.5488, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5468, 0.5488, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5484, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5487, 0.5489, 0.5489, 0.5483, 0.5489, 0.5483, 0.5489,
        0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5437, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489,
        0.5475, 0.5489, 0.5489, 0.5489, 0.5489, 0.5444, 0.5489, 0.5489, 0.5489,
        0.5489, 0.5489, 0.5488, 0.5489, 0.5489, 0.5489, 0.5489, 0.5489, 0.5486,
        0.5485, 0.5477, 0.5489, 0.5489, 0.5487, 0.5489, 0.5489, 0.5480, 0.5489,
        0.5489, 0.5489, 0.5455, 0.5489, 0.5489], device='cuda:0',
       grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.5489, device='cuda:0')
That took 4067.698713541031 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14-final/active-semi-no-background/UpperConfidenceBound.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@ls07>
Subject: Job 15333035: <supervised> in cluster <lila> Done

Job <supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Tue Jul 14 11:25:06 2020
Job was executed on host(s) <12*ls07>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Tue Jul 14 11:25:07 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Tue Jul 14 11:25:07 2020
Terminated at Tue Jul 14 13:34:37 2020
Results reported at Tue Jul 14 13:34:37 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net semi --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition UpperConfidenceBound --output_folder /home/nguyenm5/coding/pinot/jul-14-final/active-semi-no-background --index 3
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   77196.67 sec.
    Max Memory :                                 2 GB
    Average Memory :                             2.00 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   7770 sec.
    Turnaround time :                            7771 sec.

The output (if any) follows:

0
Probability of improvement:
tensor([0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4952, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4953, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4989, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4954, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4964, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951, 0.4951,
        0.4951, 0.4951, 0.4951, 0.4951, 0.4951], device='cuda:0',
       grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4989, device='cuda:0')
Probability of improvement:
tensor([3.5763e-07, 2.7418e-06, 1.3801e-01, 1.5741e-01, 4.7684e-07, 1.6928e-05,
        2.3842e-06, 8.3447e-07, 1.4308e-01, 1.3628e-01, 6.6161e-06, 2.5034e-06,
        1.3731e-01, 2.3842e-06, 1.3297e-01, 4.2915e-06, 4.0304e-01, 1.1325e-06,
        5.3108e-05, 5.6028e-06, 6.5565e-07, 1.3698e-01, 1.2172e-01, 1.3244e-01,
        1.5320e-01, 1.3873e-01, 1.4802e-01, 1.3923e-01, 1.3775e-01, 1.3723e-01,
        1.3626e-01, 1.1866e-01, 1.2891e-01, 1.3749e-01, 1.3949e-01, 2.4438e-06,
        6.6749e-02, 1.3986e-01, 1.5190e-01, 1.3712e-01, 1.8144e-01, 1.3701e-01,
        1.3796e-01, 1.3170e-01, 1.3497e-01, 1.3904e-01, 1.3697e-01, 1.3640e-01,
        1.3970e-01, 1.3151e-01, 1.3739e-01, 1.2432e-01, 1.3759e-01, 1.3989e-01,
        1.3702e-01, 1.6362e-01, 1.3944e-01, 1.3940e-01, 1.4078e-01, 1.3697e-01,
        1.4428e-01, 3.5763e-07, 1.3765e-01, 4.7684e-07, 1.4121e-01, 1.3758e-01,
        1.4613e-01, 1.3941e-01, 1.3760e-01, 3.5763e-07, 1.2414e-01, 1.3852e-01,
        5.2452e-06, 4.7088e-06, 1.6363e-01, 1.3365e-01, 1.4091e-01, 1.3727e-01,
        1.5826e-01, 6.3956e-05, 1.4807e-01, 1.3845e-01, 5.3644e-07, 1.3901e-01,
        3.3470e-01, 1.3688e-01, 0.0000e+00, 2.2650e-06, 1.3796e-01, 7.1526e-07,
        1.3692e-01, 1.3339e-01, 1.3745e-01, 1.4144e-01, 1.4598e-01, 1.3919e-01,
        1.5267e-01, 1.3427e-01, 9.5797e-04, 1.3767e-01, 1.3824e-01, 4.0531e-06,
        1.2997e-01, 1.3693e-01, 1.3844e-01, 1.9882e-01, 1.4295e-01, 1.3700e-01,
        1.3728e-01, 4.6492e-06, 1.5661e-01, 1.9131e-01, 4.5193e-03, 1.4169e-01,
        1.3756e-01, 1.6932e-01, 3.3736e-05, 1.6368e-01, 1.4067e-01, 1.3272e-01,
        1.1068e-01, 1.3551e-01, 1.3693e-01, 1.3743e-01, 1.4814e-01, 1.3762e-01,
        1.3840e-01, 7.9699e-02, 1.3732e-01, 1.4030e-01, 1.3739e-01, 2.3842e-07,
        1.3735e-01, 1.5237e-01, 1.4106e-01, 1.4193e-01, 2.2650e-06, 1.0744e-01,
        1.1828e-01, 1.4352e-01, 1.0764e-01, 1.2627e-01, 1.3821e-01, 1.3413e-01,
        6.1989e-06, 1.4082e-01, 1.6122e-01, 1.3841e-01, 1.3490e-01, 1.4341e-01,
        1.3917e-01, 1.3729e-01, 1.3591e-01, 1.2237e-01, 1.4345e-01, 1.3760e-01,
        1.0133e-06, 1.3970e-01, 1.3929e-01, 8.0407e-05, 1.3929e-01, 1.3710e-01,
        1.3239e-01, 1.3686e-01, 4.0531e-06, 1.3698e-01, 1.3792e-01, 1.2571e-01,
        1.4639e-01, 1.4308e-01, 1.3444e-01, 5.9605e-07, 1.4262e-01, 1.4738e-01,
        2.0175e-02, 1.4635e-01, 1.2638e-01, 3.0398e-06, 1.2974e-01, 5.9605e-07,
        1.3160e-01, 1.3700e-01, 1.4357e-01, 1.3590e-01, 5.9605e-07, 1.3693e-01,
        1.4275e-01, 1.4448e-04, 5.9605e-08, 1.4172e-01, 1.5975e-01, 1.0986e-01,
        1.3725e-01, 1.3928e-01, 1.3767e-01, 1.5354e-04, 1.4363e-01, 1.4425e-01,
        1.3221e-01, 1.8214e-01, 1.4244e-01, 1.2293e-01, 2.6489e-02, 1.4501e-01,
        1.8871e-04, 1.0418e-01, 1.3726e-01, 1.3703e-01, 1.8477e-06, 1.5032e-01,
        1.4012e-01, 1.3198e-01, 1.3586e-01, 1.3249e-01, 4.6201e-02, 8.3447e-07,
        1.3714e-01, 1.3693e-01, 1.4713e-01, 1.3689e-01, 1.5849e-01, 1.2782e-01,
        1.3243e-01, 1.3123e-01, 1.3568e-01, 3.5763e-07, 1.3873e-01, 1.1921e-07,
        2.0266e-06, 1.3685e-01, 4.4107e-06, 4.1723e-06, 1.0729e-06, 1.3653e-01,
        1.3763e-01, 1.4047e-01, 2.2650e-06, 1.3726e-01, 1.3727e-01, 3.9212e-02,
        1.2651e-01, 1.7044e-01, 1.3702e-01, 1.3777e-01, 1.7310e-01, 1.3798e-01,
        1.1322e-01, 5.3644e-06, 1.3731e-01, 1.4227e-01, 1.7490e-01, 2.3842e-06,
        3.5763e-07, 1.9073e-06, 1.7008e-01, 1.3536e-01, 1.4102e-01, 2.1458e-06,
        1.3693e-01, 2.4140e-05, 1.4305e-06, 1.3399e-01, 1.3717e-01, 1.3661e-01,
        1.3966e-01, 1.3570e-01, 1.3792e-01, 1.1351e-01, 1.1921e-06, 1.4049e-01,
        1.4162e-01, 1.3961e-01, 1.7856e-02, 1.3990e-01, 1.3305e-01, 1.4151e-01,
        3.5763e-07, 1.3715e-01, 1.7619e-01, 1.0729e-06, 8.3447e-07, 4.2319e-06,
        1.3010e-01, 1.4146e-01, 1.5204e-01, 1.8358e-05, 1.3652e-01, 1.3690e-01,
        1.4970e-01, 1.4328e-01, 1.6437e-01, 1.4151e-01, 1.3680e-01, 1.3977e-01,
        2.2159e-02, 4.7684e-07, 1.3413e-01, 1.3748e-01, 1.3681e-01, 8.9407e-07,
        1.4645e-01, 1.4234e-01, 1.3693e-01, 1.3553e-01, 1.3742e-01, 1.3782e-01,
        1.3753e-01, 1.4555e-01, 1.3812e-01, 1.4023e-01, 1.4057e-01, 1.2570e-01,
        1.4277e-01, 1.3643e-01, 1.3922e-01, 1.3741e-01, 1.2802e-01, 2.1863e-04,
        1.2821e-01, 5.9605e-08, 1.4267e-01, 1.4183e-01, 1.3709e-06, 1.4062e-01,
        1.3703e-01, 1.3858e-01, 1.1921e-06, 3.6228e-03, 1.3691e-01, 1.3422e-01,
        1.3794e-01, 1.3904e-01, 1.2046e-01, 1.1752e-01, 1.3868e-01, 1.3982e-01,
        2.9802e-07, 7.1526e-07, 3.4571e-06, 1.2924e-01, 7.1526e-07, 1.3696e-01,
        1.4262e-01, 1.3791e-01, 8.3447e-07, 1.4544e-01, 5.9605e-07, 6.5565e-06,
        1.0695e-01, 7.7367e-05, 2.3842e-06, 1.3787e-01, 1.3593e-01, 7.7486e-07,
        6.7949e-06, 1.3910e-01, 1.3789e-01, 1.3140e-01, 1.3692e-01, 1.4548e-01,
        1.3997e-01, 6.9739e-02, 1.4901e-06, 1.3806e-01, 1.6451e-05, 1.3986e-01,
        1.3650e-01, 1.4311e-01, 1.3693e-01, 1.3828e-01, 1.3690e-01, 1.5003e-01,
        1.8310e-01, 1.6689e-06], device='cuda:0', grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4030, device='cuda:0')
That took 7761.09148979187 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14-final/active-semi-no-background/UpperConfidenceBound.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@ls07>
Subject: Job 15333034: <supervised> in cluster <lila> Done

Job <supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Tue Jul 14 11:25:06 2020
Job was executed on host(s) <12*ls07>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Tue Jul 14 11:25:07 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Tue Jul 14 11:25:07 2020
Terminated at Tue Jul 14 14:37:38 2020
Results reported at Tue Jul 14 14:37:38 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net semi --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition UpperConfidenceBound --output_folder /home/nguyenm5/coding/pinot/jul-14-final/active-semi-no-background --index 2
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   114744.80 sec.
    Max Memory :                                 2 GB
    Average Memory :                             2.00 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   11553 sec.
    Turnaround time :                            11552 sec.

The output (if any) follows:

0
Probability of improvement:
tensor([0.2232, 0.2200, 0.2200, 0.2200, 0.2203, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2209, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2252, 0.2284, 0.2200, 0.2201, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2234, 0.2200, 0.2200, 0.2200, 0.2200, 0.2207, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2330, 0.2200, 0.2200, 0.2201, 0.2202, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2201,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200, 0.2204, 0.2202, 0.2203,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2242, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2202, 0.2200, 0.2200, 0.2200, 0.2200, 0.2205, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200, 0.2200, 0.2219, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2237, 0.2200, 0.2200, 0.2200, 0.2217,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2625, 0.2277, 0.2200, 0.2200, 0.2200, 0.2200, 0.2203, 0.2200, 0.2208,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2201, 0.2201, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2201, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2202, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200, 0.2200, 0.2200,
        0.2201, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2240, 0.2395,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200, 0.2200,
        0.2200, 0.2200, 0.4285, 0.2200, 0.2200, 0.2204, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2201, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2210, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2202, 0.2200, 0.2200, 0.2200, 0.2202, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2201, 0.2200, 0.2200, 0.2200, 0.2226, 0.2200, 0.2200, 0.2201,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2201, 0.2200, 0.2284, 0.2200, 0.2200, 0.2350, 0.2206, 0.2200,
        0.2200, 0.2201, 0.2202, 0.2200, 0.2200, 0.2200, 0.2201, 0.2214, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2258, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2201, 0.2209, 0.2200, 0.2200, 0.2200, 0.2200, 0.2235, 0.2200, 0.2200,
        0.2200, 0.2200, 0.2203, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200, 0.2200,
        0.2200, 0.2203, 0.2200, 0.2200, 0.2200], device='cuda:0',
       grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4285, device='cuda:0')
Probability of improvement:
tensor([9.0599e-06, 1.7760e-01, 1.0071e-02, 1.7757e-01, 1.2994e-05, 1.7910e-01,
        1.7760e-01, 1.7592e-01, 1.7735e-01, 7.3731e-05, 1.7760e-01, 1.7972e-01,
        1.7756e-01, 2.1942e-01, 2.0235e-01, 1.7760e-01, 1.7760e-01, 1.7637e-01,
        1.7760e-01, 1.7728e-01, 1.7760e-01, 1.7760e-01, 5.9605e-07, 2.0146e-05,
        0.0000e+00, 3.0193e-03, 1.2109e-01, 6.1393e-05, 1.5095e-03, 1.7881e-07,
        1.8203e-01, 1.8712e-01, 1.7754e-01, 1.8403e-01, 1.7758e-01, 1.7760e-01,
        1.8963e-01, 1.7757e-01, 1.7881e-07, 1.7760e-01, 1.7580e-01, 1.7760e-01,
        1.7975e-01, 1.8751e-02, 1.7881e-07, 1.7759e-01, 5.4598e-05, 1.7765e-01,
        2.5523e-04, 1.7655e-01, 1.7758e-01, 4.6396e-02, 1.3113e-06, 1.7637e-01,
        1.7761e-01, 1.7359e-01, 1.7641e-01, 1.7747e-01, 1.7760e-01, 1.7809e-01,
        1.6679e-01, 1.7760e-01, 2.0387e-01, 1.7759e-01, 1.7633e-01, 5.0724e-05,
        1.7739e-01, 1.7565e-01, 1.7757e-01, 1.7760e-01, 1.7759e-01, 9.3579e-05,
        1.7760e-01, 1.7757e-01, 1.7730e-01, 1.8132e-01, 1.7753e-01, 1.7760e-01,
        1.1409e-01, 1.7729e-01, 1.7166e-01, 1.8860e-01, 2.2588e-01, 1.7708e-01,
        1.7760e-01, 1.7760e-01, 1.7760e-01, 1.7912e-01, 1.0500e-01, 1.7844e-01,
        1.7760e-01, 1.7792e-01, 2.5034e-06, 1.7718e-01, 6.0976e-05, 1.7759e-01,
        4.1127e-05, 1.7989e-04, 7.6274e-03, 1.7756e-01, 1.7753e-01, 1.7760e-01,
        1.7736e-01, 1.7765e-01, 1.8454e-04, 3.4392e-05, 1.7174e-01, 1.7857e-01,
        1.7840e-01, 1.7760e-01, 1.7759e-01, 1.7757e-01, 1.7760e-01, 1.7749e-01,
        1.6246e-01, 1.6627e-01, 1.7760e-01, 1.7685e-01, 2.8729e-05, 1.7752e-01,
        3.0041e-05, 1.7760e-01, 1.7761e-01, 1.7754e-01, 1.7760e-01, 6.0558e-05,
        4.2430e-02, 1.0718e-02, 1.7775e-01, 1.7760e-01, 1.7767e-01, 1.7760e-01,
        2.1160e-04, 1.7615e-01, 1.7759e-01, 1.7685e-01, 1.7760e-01, 1.7759e-01,
        1.4678e-01, 3.5584e-05, 1.7755e-01, 1.7759e-01, 1.3947e-05, 2.5749e-05,
        1.7759e-01, 1.7588e-01, 1.7615e-01, 1.7740e-01, 1.8239e-05, 1.7760e-01,
        1.7745e-01, 1.7763e-01, 1.9073e-06, 1.7760e-01, 1.7513e-01, 2.1285e-01,
        1.7758e-01, 9.5367e-07, 1.7756e-01, 1.3646e-01, 1.7760e-01, 1.7760e-01,
        2.7537e-05, 4.1246e-05, 1.7760e-01, 1.7790e-01, 1.7777e-01, 1.7757e-01,
        8.9407e-07, 1.7464e-01, 3.9279e-05, 1.7760e-01, 1.7755e-01, 1.7725e-01,
        1.7760e-01, 1.6685e-01, 1.7748e-01, 1.7760e-01, 1.7760e-01, 1.7760e-01,
        1.7760e-01, 1.7800e-01, 5.3704e-05, 3.6359e-06, 1.7760e-01, 1.7760e-01,
        1.7758e-01, 1.7753e-01, 1.7760e-01, 1.7410e-02, 1.7150e-01, 1.7758e-01,
        1.7760e-01, 1.7671e-01, 1.7744e-01, 1.7760e-01, 4.6670e-05, 1.7723e-01,
        2.1126e-01, 1.7760e-01, 1.7760e-01, 2.0570e-01, 1.7758e-01, 1.7723e-01,
        2.9238e-03, 1.7760e-01, 1.8297e-01, 1.7999e-01, 1.7760e-01, 9.7752e-05,
        1.7759e-01, 1.7760e-01, 4.0575e-01, 1.7755e-01, 1.7760e-01, 1.6155e-01,
        4.5300e-06, 1.7760e-01, 1.7726e-01, 1.7760e-01, 1.7492e-01, 1.7760e-01,
        3.2689e-01, 8.2612e-05, 1.7138e-03, 1.7760e-01, 1.2159e-04, 1.7760e-01,
        1.7760e-01, 1.7760e-01, 1.8327e-01, 1.7681e-01, 1.7760e-01, 1.7560e-01,
        1.7760e-01, 1.7756e-01, 1.7760e-01, 1.8594e-01, 6.7296e-03, 1.7760e-01,
        6.9862e-02, 1.7756e-01, 1.7760e-01, 9.4891e-05, 1.7758e-01, 2.6770e-01,
        9.8348e-05, 1.7759e-01, 8.3789e-02, 1.7757e-01, 3.7377e-01, 1.7760e-01,
        1.7760e-01, 1.7760e-01, 1.6792e-01, 1.5771e-04, 7.1740e-04, 1.7760e-01,
        1.8963e-01, 1.7760e-01, 1.7760e-01, 1.7760e-01, 2.0164e-01, 2.8849e-05,
        1.7593e-01, 5.7399e-04, 3.1819e-02, 1.7760e-01, 1.7760e-01, 1.6681e-01,
        1.7759e-01, 5.3644e-07, 1.7759e-01, 1.7724e-01, 1.7768e-01, 1.6689e-06,
        1.7758e-01, 3.7032e-04, 1.7436e-01, 1.7760e-01, 2.4796e-05, 7.5817e-05,
        1.7755e-01, 1.7734e-01, 2.2948e-05, 1.7791e-01, 1.7760e-01, 4.5180e-05,
        1.7008e-01, 1.6338e-01, 1.7759e-01, 1.7681e-01, 1.7760e-01, 1.7231e-01,
        1.7760e-01, 1.7760e-01, 2.5139e-01, 1.7758e-01, 3.7544e-02, 1.7760e-01,
        1.8477e-06, 1.7760e-01, 1.7760e-01, 8.2254e-05, 1.4180e-02, 2.1458e-06,
        1.7755e-01, 5.2333e-05, 1.2457e-05, 1.7760e-01, 1.7760e-01, 1.1325e-06,
        2.0215e-01, 8.8306e-02, 1.7760e-01, 1.8185e-01, 1.7760e-01, 1.7760e-01,
        8.7619e-05, 1.7760e-01, 1.7748e-01, 1.7758e-01, 1.7760e-01, 3.5763e-07,
        1.7489e-01, 2.0237e-01, 1.7760e-01, 1.7538e-01, 1.7760e-01, 1.7643e-05,
        1.7815e-01, 1.7760e-01, 2.3442e-01, 1.7759e-01, 1.7722e-01, 1.6479e-01,
        1.7760e-01, 1.7841e-01, 1.7760e-01, 6.2430e-04, 1.7760e-01, 1.7761e-01,
        1.7754e-01, 2.5159e-03, 1.7760e-01, 1.4786e-01, 1.7760e-01, 1.7756e-01,
        1.9340e-01, 1.7759e-01, 1.8890e-01, 2.9075e-04, 3.2099e-02, 1.7760e-01,
        1.7430e-01, 2.7543e-04, 2.1048e-01, 1.5497e-06, 4.0770e-05, 1.7758e-01,
        1.7743e-01, 1.7759e-01, 4.7922e-05, 1.5855e-05, 1.7760e-01, 1.7753e-01,
        1.7760e-01, 1.7754e-01, 1.7760e-01, 1.8161e-01, 4.3750e-05, 1.7759e-01,
        1.7536e-01, 1.7803e-01], device='cuda:0', grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.4057, device='cuda:0')
Probability of improvement:
tensor([0.0000e+00, 8.3447e-07, 5.9676e-04, 1.2185e-01, 1.1921e-07, 5.6028e-06,
        7.1526e-07, 1.1969e-01, 1.2058e-01, 7.1526e-07, 1.2049e-01, 7.1526e-07,
        1.2005e-01, 8.3447e-07, 1.6054e-01, 1.1921e-06, 1.1539e-01, 1.0509e-01,
        1.2309e-01, 1.2390e-01, 1.1921e-07, 4.7684e-07, 0.0000e+00, 1.7881e-07,
        0.0000e+00, 1.1313e-04, 4.7127e-02, 5.9605e-07, 4.5836e-05, 0.0000e+00,
        1.3228e-01, 2.4438e-06, 1.2269e-01, 1.5242e-01, 1.1590e-01, 1.5150e-01,
        1.1981e-01, 1.2275e-01, 0.0000e+00, 1.2375e-01, 1.2083e-01, 4.1723e-06,
        1.2250e-01, 1.5899e-03, 0.0000e+00, 1.1613e-01, 5.3644e-07, 1.8942e-04,
        5.1856e-06, 1.2842e-01, 1.2274e-01, 4.6338e-03, 0.0000e+00, 1.1847e-01,
        5.7817e-06, 1.1375e-01, 1.2034e-01, 1.2291e-01, 1.2330e-01, 2.3842e-07,
        8.8460e-02, 5.9605e-08, 2.9802e-07, 1.1280e-01, 1.1875e-01, 3.5763e-07,
        1.2548e-01, 1.2040e-01, 1.2273e-01, 1.2010e-01, 1.2298e-01, 1.5497e-06,
        1.6689e-06, 1.2308e-01, 1.2259e-01, 1.3113e-06, 1.2256e-01, 1.2279e-01,
        1.2483e-01, 1.2204e-01, 1.1867e-01, 2.1458e-06, 1.1921e-07, 1.2171e-01,
        3.0893e-01, 3.9402e-01, 0.0000e+00, 6.5565e-07, 8.0859e-02, 1.7881e-07,
        1.1956e-01, 9.5367e-07, 0.0000e+00, 1.2015e-01, 5.9605e-07, 1.2297e-01,
        3.5763e-07, 2.5034e-06, 3.8189e-04, 1.2191e-01, 1.2102e-01, 1.1921e-06,
        1.2250e-01, 1.0133e-06, 2.6226e-06, 1.1921e-07, 1.1830e-01, 1.1670e-01,
        1.4901e-06, 2.2650e-06, 1.2115e-01, 1.2333e-01, 2.9882e-03, 1.2250e-01,
        1.1157e-01, 1.1768e-01, 1.3709e-05, 1.1928e-01, 2.3842e-07, 1.2172e-01,
        2.3842e-07, 1.1619e-01, 0.0000e+00, 1.2277e-01, 1.2036e-01, 5.9605e-07,
        5.0398e-03, 7.1907e-04, 3.5763e-07, 1.2300e-01, 4.5300e-06, 1.7881e-07,
        4.1127e-06, 1.1973e-01, 1.2188e-01, 1.1567e-01, 1.0249e-01, 1.2234e-01,
        1.7247e-01, 2.3842e-07, 1.2278e-01, 1.2264e-01, 1.1921e-07, 1.1921e-07,
        1.2325e-01, 1.2034e-01, 1.1974e-01, 1.2068e-01, 1.1921e-07, 1.1661e-01,
        1.2256e-01, 2.3842e-07, 0.0000e+00, 9.7661e-02, 1.2032e-01, 4.7684e-07,
        1.2310e-01, 0.0000e+00, 1.2318e-01, 1.2041e-01, 1.2307e-01, 7.1526e-07,
        3.5763e-07, 3.5763e-07, 1.2306e-01, 0.0000e+00, 3.5763e-05, 1.2281e-01,
        0.0000e+00, 1.2170e-01, 2.3842e-07, 1.1921e-07, 1.2303e-01, 1.2236e-01,
        1.2964e-02, 1.0807e-01, 1.1586e-01, 8.3447e-07, 3.6712e-01, 1.1921e-07,
        1.1150e-01, 9.5367e-07, 3.5763e-07, 0.0000e+00, 1.1393e-01, 1.7285e-06,
        1.2313e-01, 1.2263e-01, 1.2106e-01, 1.0359e-03, 1.1084e-01, 1.2286e-01,
        1.1325e-05, 1.1683e-01, 8.0857e-02, 1.2128e-01, 4.1723e-07, 1.2187e-01,
        0.0000e+00, 5.9605e-07, 1.2216e-01, 1.3984e-01, 1.2286e-01, 1.2167e-01,
        9.4771e-05, 8.7708e-02, 0.0000e+00, 1.2871e-03, 4.7684e-07, 1.1921e-06,
        1.2313e-01, 1.1869e-01, 1.5347e-01, 1.1858e-01, 3.3216e-02, 1.1252e-01,
        0.0000e+00, 5.3644e-07, 1.2285e-01, 1.1783e-01, 1.1917e-01, 1.2307e-01,
        9.8237e-02, 5.9605e-07, 3.7909e-05, 5.9605e-08, 8.3447e-07, 1.2141e-01,
        6.5565e-07, 1.1935e-01, 1.3113e-06, 1.2124e-01, 1.1617e-01, 1.2104e-01,
        1.1993e-01, 1.2295e-01, 1.1841e-01, 5.3644e-07, 3.4392e-04, 3.0491e-02,
        1.0563e-02, 1.2337e-01, 4.1723e-07, 7.1526e-07, 1.2332e-01, 7.3516e-02,
        1.0729e-06, 1.2341e-01, 1.3047e-02, 1.2315e-01, 1.5151e-01, 8.3447e-07,
        1.1921e-07, 1.1168e-01, 1.2231e-01, 2.0266e-06, 1.4901e-05, 1.7640e-01,
        8.3447e-07, 1.2139e-01, 4.7684e-07, 0.0000e+00, 2.0266e-06, 2.3842e-07,
        1.1525e-01, 1.2100e-05, 2.9578e-03, 9.6799e-02, 3.5763e-07, 6.6616e-02,
        1.2277e-01, 0.0000e+00, 1.2292e-01, 1.2172e-01, 0.0000e+00, 0.0000e+00,
        1.2309e-01, 6.7949e-06, 1.3472e-01, 2.3842e-07, 1.7881e-07, 4.7684e-07,
        1.2279e-01, 1.2256e-01, 2.3842e-07, 5.8413e-06, 8.3447e-07, 4.7684e-07,
        1.5848e-01, 1.1777e-01, 1.2304e-01, 1.2204e-01, 1.7881e-07, 1.1567e-01,
        2.3842e-07, 8.3053e-02, 3.0875e-05, 1.2275e-01, 3.7182e-03, 3.5763e-07,
        0.0000e+00, 1.2320e-01, 0.0000e+00, 7.7486e-07, 8.2445e-04, 0.0000e+00,
        1.2261e-01, 5.9605e-07, 1.1921e-07, 1.2365e-01, 1.2275e-01, 0.0000e+00,
        4.6261e-02, 1.1926e-02, 1.6093e-06, 3.9824e-03, 1.1774e-01, 1.2004e-01,
        5.9605e-07, 3.5763e-07, 1.2257e-01, 1.1987e-01, 1.1923e-01, 0.0000e+00,
        1.3243e-01, 0.0000e+00, 7.1526e-07, 1.2071e-01, 1.2235e-01, 1.1921e-07,
        1.1921e-07, 1.2037e-01, 4.7684e-07, 1.2293e-01, 1.1189e-01, 1.2143e-01,
        1.2148e-01, 1.7881e-07, 1.3864e-01, 1.2696e-05, 1.2202e-01, 4.1723e-07,
        1.2259e-01, 7.7009e-05, 2.3842e-07, 9.1632e-02, 1.2085e-01, 1.2297e-01,
        1.4305e-06, 1.2320e-01, 1.2229e-01, 5.2452e-06, 4.2009e-03, 1.2323e-01,
        1.2023e-01, 4.5896e-06, 2.3842e-07, 0.0000e+00, 3.5763e-07, 1.2246e-01,
        1.2270e-01, 1.2315e-01, 4.7684e-07, 1.1921e-07, 1.1737e-01, 1.2259e-01,
        3.8670e-01, 1.2283e-01, 1.2226e-01, 0.0000e+00, 3.5763e-07, 1.2310e-01,
        1.1887e-01, 4.7684e-07], device='cuda:0', grad_fn=<RsubBackward1>)
Max probability of improvement:
tensor(0.3940, device='cuda:0')
That took 11541.971183776855 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14-final/active-semi-no-background/UpperConfidenceBound.stderr> for stderr output of this job.

