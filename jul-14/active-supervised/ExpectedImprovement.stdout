Sender: LSF System <lsfadmin@lt20>
Subject: Job 15330921: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
Job was executed on host(s) <12*lt20>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 23:26:12 2020
Terminated at Mon Jul 13 23:26:31 2020
Results reported at Mon Jul 13 23:26:31 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-14/active-supervised --index 4
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   17.15 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.36 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                9
    Run time :                                   20 sec.
    Turnaround time :                            19 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.2616, 0.2004, 0.2551, 0.2290, 0.2641, 0.2639, 0.2564, 0.2099, 0.1483,
        0.2597, 0.1607, 0.2535, 0.1886, 0.2629, 0.2545, 0.2618, 0.1796, 0.2642,
        0.2634, 0.2539, 0.2634, 0.2601, 0.2641, 0.2640, 0.2521, 0.2567, 0.2505,
        0.2494, 0.2543, 0.2558, 0.2556, 0.2548, 0.1607, 0.2539, 0.2527, 0.1860,
        0.2556, 0.2477, 0.2621, 0.2321, 0.2576, 0.2562, 0.2537, 0.2642, 0.2552,
        0.2631, 0.2341, 0.2575, 0.2627, 0.2329, 0.2150, 0.2640, 0.2595, 0.2626,
        0.2581, 0.2575, 0.2557, 0.2469, 0.2638, 0.2600, 0.2495, 0.2106, 0.2641,
        0.0988, 0.2223, 0.2549, 0.2545, 0.2559, 0.2101, 0.2618, 0.1857, 0.2629,
        0.1465, 0.2633, 0.2515, 0.2633, 0.1752, 0.2597, 0.2509, 0.1476, 0.2366,
        0.2616, 0.2634, 0.2603, 0.1802, 0.2504, 0.2519, 0.2529, 0.2551, 0.2584,
        0.2627, 0.2568, 0.2550, 0.2549, 0.2620, 0.2563, 0.2619, 0.2583, 0.2612,
        0.1835, 0.2642, 0.2501, 0.1696, 0.2483, 0.2582, 0.2594, 0.2561, 0.2043,
        0.2543, 0.2283, 0.2219, 0.2046, 0.2061, 0.1755, 0.2540, 0.2641, 0.1935,
        0.2550, 0.2633, 0.2642, 0.2555, 0.1458, 0.2567, 0.2504, 0.2542, 0.2551,
        0.2558, 0.2596, 0.2091, 0.2641, 0.2612, 0.2084, 0.2600, 0.2547, 0.2639,
        0.2393, 0.2262, 0.1224, 0.2641, 0.2599, 0.1594, 0.2062, 0.2641, 0.2638,
        0.2524, 0.2354, 0.2554, 0.2639, 0.2616, 0.1789, 0.2636, 0.2603, 0.2631,
        0.2365, 0.2389, 0.2613, 0.1810, 0.2617, 0.2614, 0.2567, 0.2627, 0.2591,
        0.2641, 0.2604, 0.2219, 0.2614, 0.2526, 0.1266, 0.2617, 0.2641, 0.2641,
        0.1869, 0.2615, 0.2114, 0.2142, 0.2459, 0.2626, 0.2330, 0.2563, 0.2637,
        0.2562, 0.2620, 0.2574, 0.2430, 0.2465, 0.2597, 0.2266, 0.2392, 0.2571,
        0.2568, 0.1206, 0.2508, 0.2598, 0.1770, 0.2603, 0.2598, 0.2570, 0.2641,
        0.2185, 0.2642, 0.2546, 0.1335, 0.1483, 0.2581, 0.2251, 0.2571, 0.2573,
        0.2333, 0.2633, 0.1954, 0.2537, 0.2642, 0.2642, 0.1706, 0.2640, 0.2601,
        0.2455, 0.2249, 0.2528, 0.2559, 0.1890, 0.2631, 0.2619, 0.2629, 0.2096,
        0.2617, 0.2275, 0.2118, 0.2506, 0.2541, 0.2085, 0.2470, 0.2554, 0.2639,
        0.2640, 0.2546, 0.2600, 0.2550, 0.2555, 0.2640, 0.1706, 0.2635, 0.2558,
        0.2192, 0.2641, 0.2557, 0.1625, 0.2631, 0.2538, 0.2614, 0.2038, 0.2228,
        0.1996, 0.2641, 0.2539, 0.2573, 0.2236, 0.2271, 0.1806, 0.2335, 0.2641,
        0.2541, 0.2633, 0.2609, 0.2569, 0.2536, 0.2422, 0.1600, 0.2560, 0.2640,
        0.2635, 0.1628, 0.1862, 0.2640, 0.2599, 0.1217, 0.2586, 0.2641, 0.2490,
        0.2581, 0.2556, 0.1624, 0.2143, 0.2617, 0.2552, 0.1807, 0.2638, 0.2639,
        0.2591, 0.1892, 0.2477, 0.2624, 0.2641, 0.2057, 0.2064, 0.2619, 0.2196,
        0.2458, 0.2473, 0.2630, 0.2638, 0.2621, 0.2628, 0.2631, 0.2544, 0.1885,
        0.2606, 0.2584, 0.2607, 0.1575, 0.2635, 0.2582, 0.2639, 0.2615, 0.2529,
        0.1924, 0.1747, 0.2553, 0.1904, 0.1714, 0.2637, 0.2444, 0.2616, 0.2501,
        0.2627, 0.1838, 0.2355, 0.2642, 0.2641, 0.2568, 0.2533, 0.2619, 0.2016,
        0.1924, 0.2625, 0.2621, 0.2609, 0.2630, 0.2619, 0.1504, 0.2584, 0.2555,
        0.2556, 0.2441, 0.2508, 0.2620, 0.2489, 0.2640, 0.2619, 0.2548, 0.2632,
        0.2581, 0.2010, 0.2452, 0.2552, 0.2610, 0.2616, 0.2613, 0.2537, 0.2093,
        0.1259, 0.2592, 0.2380, 0.1741, 0.1782, 0.2617, 0.2613, 0.2572, 0.2629,
        0.2638, 0.2443, 0.2552, 0.2632], device='cuda:0',
       grad_fn=<AddBackward0>)
That took 10.638349056243896 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt20>
Subject: Job 15330922: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
Job was executed on host(s) <12*lt20>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:13 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 23:26:13 2020
Terminated at Mon Jul 13 23:26:40 2020
Results reported at Mon Jul 13 23:26:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-14/active-supervised --index 5
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   27.34 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.53 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   29 sec.
    Turnaround time :                            28 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.3419, 0.3980, 0.2571, 0.3969, 0.3849, 0.3704, 0.3931, 0.3972, 0.3987,
        0.3025, 0.3992, 0.3167, 0.3994, 0.3571, 0.2911, 0.3898, 0.3993, 0.3789,
        0.3637, 0.3061, 0.3671, 0.2995, 0.3850, 0.3734, 0.3935, 0.2125, 0.3933,
        0.3935, 0.2979, 0.2112, 0.2365, 0.2677, 0.3992, 0.2961, 0.3941, 0.3995,
        0.2384, 0.3945, 0.3363, 0.4002, 0.2646, 0.2893, 0.3087, 0.3787, 0.2743,
        0.3545, 0.3962, 0.1885, 0.3505, 0.3957, 0.3999, 0.3713, 0.2908, 0.3877,
        0.2551, 0.2095, 0.3920, 0.3944, 0.3720, 0.3075, 0.3940, 0.3998, 0.3721,
        0.3989, 0.3972, 0.2503, 0.2823, 0.3928, 0.3998, 0.4009, 0.3995, 0.3521,
        0.3992, 0.3547, 0.3922, 0.3617, 0.3980, 0.3150, 0.3938, 0.3986, 0.3965,
        0.3327, 0.3723, 0.3902, 0.3994, 0.3956, 0.3950, 0.3340, 0.2484, 0.2380,
        0.3609, 0.0958, 0.2712, 0.2663, 0.3363, 0.3937, 0.3385, 0.2590, 0.3323,
        0.3994, 0.3790, 0.3786, 0.3982, 0.3931, 0.2476, 0.3907, 0.2677, 0.3974,
        0.2879, 0.3969, 0.3974, 0.3978, 0.3981, 0.3993, 0.3061, 0.3785, 0.3996,
        0.2934, 0.3607, 0.3757, 0.2344, 0.3989, 0.2231, 0.3768, 0.3929, 0.2772,
        0.2297, 0.3067, 0.3981, 0.3758, 0.3539, 0.3998, 0.3096, 0.3018, 0.3769,
        0.3960, 0.4001, 0.3990, 0.3793, 0.2963, 0.3992, 0.3997, 0.3712, 0.3685,
        0.3936, 0.3956, 0.2562, 0.3842, 0.3319, 0.3980, 0.3854, 0.2981, 0.3876,
        0.3967, 0.3953, 0.3344, 0.3994, 0.3347, 0.3891, 0.3924, 0.3647, 0.2805,
        0.3733, 0.2916, 0.4000, 0.3274, 0.3401, 0.3990, 0.3337, 0.3794, 0.3812,
        0.3989, 0.3891, 0.3968, 0.3978, 0.3944, 0.3490, 0.3960, 0.3934, 0.3856,
        0.3989, 0.2555, 0.3448, 0.2342, 0.3953, 0.3996, 0.3900, 0.3965, 0.3958,
        0.1634, 0.2030, 0.3990, 0.3710, 0.3909, 0.3983, 0.3911, 0.3068, 0.3916,
        0.3732, 0.3978, 0.3772, 0.2877, 0.3984, 0.3987, 0.2472, 0.3974, 0.1766,
        0.1788, 0.3959, 0.3838, 0.3983, 0.3935, 0.3777, 0.3773, 0.3984, 0.3805,
        0.2997, 0.4012, 0.3964, 0.3953, 0.2095, 0.3995, 0.3583, 0.3369, 0.3535,
        0.3998, 0.3384, 0.3967, 0.3980, 0.3955, 0.3013, 0.3974, 0.3950, 0.2367,
        0.3842, 0.3833, 0.3936, 0.2993, 0.2703, 0.3935, 0.3714, 0.3981, 0.3691,
        0.2302, 0.3982, 0.3725, 0.2352, 0.3992, 0.3581, 0.3945, 0.3885, 0.3979,
        0.3999, 0.3998, 0.3783, 0.3097, 0.1637, 0.3970, 0.3963, 0.3995, 0.3961,
        0.3755, 0.3041, 0.3627, 0.3888, 0.1731, 0.3924, 0.3957, 0.3993, 0.3935,
        0.3742, 0.3635, 0.3992, 0.3985, 0.3725, 0.2966, 0.3990, 0.2658, 0.3781,
        0.3949, 0.2460, 0.2497, 0.3992, 0.3976, 0.3521, 0.2500, 0.3995, 0.3652,
        0.3810, 0.3919, 0.3977, 0.3942, 0.3614, 0.3801, 0.3998, 0.3976, 0.3386,
        0.3999, 0.3941, 0.3951, 0.3534, 0.3850, 0.4010, 0.3574, 0.3581, 0.3095,
        0.3993, 0.3149, 0.2648, 0.3902, 0.3984, 0.3644, 0.2475, 0.3699, 0.3392,
        0.3290, 0.3992, 0.3993, 0.2489, 0.3996, 0.3982, 0.3686, 0.3966, 0.3363,
        0.3938, 0.3503, 0.3995, 0.3967, 0.3809, 0.3808, 0.3940, 0.3270, 0.3988,
        0.3978, 0.3855, 0.4009, 0.3879, 0.3874, 0.3409, 0.3991, 0.2843, 0.3934,
        0.2304, 0.4004, 0.3933, 0.4009, 0.3948, 0.3754, 0.3895, 0.2921, 0.3603,
        0.2746, 0.3998, 0.3945, 0.2557, 0.3381, 0.3318, 0.3886, 0.3928, 0.3968,
        0.3990, 0.2704, 0.3959, 0.3995, 0.3992, 0.3904, 0.3887, 0.2657, 0.3518,
        0.3813, 0.3952, 0.2820, 0.3563], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.4656e-05,  1.4183e-08,  1.6455e-03,  6.8164e-06,  8.5761e-07,
         3.3213e-07,  2.3412e-05,  1.5486e-08,  9.3400e-06,  5.9427e-05,
         4.9242e-12,  3.0588e-06,  3.6521e-07,  6.0483e-05,  6.9848e-10,
         1.5530e-03,  8.7443e-08,  2.7210e-10,  2.1426e-05,  4.8722e-19,
         1.1266e-11,  8.3220e-05,  1.9908e-04,  4.0791e-09,  3.4298e-04,
         6.2806e-09,  7.4220e-08,  6.9761e-04,  4.1849e-04,  1.8015e-08,
         9.3134e-06,  1.3839e-05,  6.6839e-09, -1.9562e-09,  5.0902e-03,
        -2.8525e-09, -1.7194e-09,  1.8661e-05,  2.9692e-07,  5.0974e-14,
         4.7377e-08,  5.3857e-05,  4.2044e-03,  2.7884e-06,  2.3175e-08,
         8.5510e-12,  2.1945e-11,  1.0001e-04,  4.9467e-09,  3.1389e-12,
         5.3079e-05,  2.8161e-12,  2.4269e-05,  2.9637e-07,  1.2530e-06,
         6.6774e-07,  1.4844e-04,  1.3283e-04,  1.2187e-05,  3.6278e-07,
         1.4370e-05,  2.4671e-09,  9.8137e-05,  1.4508e-08,  4.9088e-03,
         7.5834e-03,  3.6355e-06,  2.9012e-12,  1.1264e-08,  3.6938e-04,
         1.0448e-11,  3.5279e-03,  2.6310e-07,  1.7443e-04,  1.6515e-02,
         1.0043e-09,  9.8047e-06,  5.3398e-08,  9.4501e-04,  1.6519e-03,
         6.2970e-05,  6.7517e-05,  4.6953e-06,  8.0504e-03,  1.7167e-08,
         1.8733e-08,  3.2805e-07,  3.8787e-02,  4.4503e-09,  1.8766e-02,
         3.2619e-11,  2.3162e-07,  1.2109e-02,  5.9663e-05,  6.0124e-03,
        -2.0212e-09,  7.0864e-06,  2.8615e-04,  1.3221e-03,  5.4938e-06,
         3.4595e-03,  1.7368e-08,  1.4832e-08, -5.9700e-09,  1.5459e-08,
         1.5431e-07, -1.1191e-09,  1.1558e-08,  2.6000e-13,  1.6418e-03,
         7.4918e-04,  2.7206e-07,  9.5402e-07,  2.6351e-03,  1.9073e-06,
         5.6338e-02,  4.2652e-13,  8.0779e-12,  1.8721e-07,  1.2361e-08,
         7.4150e-03,  2.0855e-06,  1.1858e-07,  1.6417e-04,  1.3271e-06,
         9.5902e-05,  2.9969e-06,  3.1659e-07,  4.5844e-02,  2.0961e-09,
         9.0046e-09,  1.3869e-11,  2.3661e-09,  6.6528e-07, -1.9994e-09,
         1.7158e-05,  4.0600e-04,  2.5799e-04,  3.4832e-06,  2.0158e-06,
         1.4163e-06,  4.6497e-11,  3.0470e-05,  9.5564e-11,  3.6296e-09,
         1.8436e-02,  2.1155e-03,  5.8884e-10,  5.8727e-06,  5.2309e-05,
         8.5601e-08,  6.9444e-07,  1.0615e-07,  1.2311e-08,  2.5510e-08,
        -3.7075e-10,  5.0428e-09,  1.6939e-10,  1.5753e-09, -5.6682e-09,
         1.4959e-02,  7.4908e-04,  3.1306e-08,  2.2244e-09,  2.1964e-11,
        -9.0089e-09,  5.1186e-04,  4.9370e-10,  2.6184e-09,  7.5048e-10,
         2.8554e-07,  7.5163e-19,  4.7473e-03,  4.3174e-08,  1.5224e-08,
         1.4860e-08,  7.8846e-06,  4.1147e-02,  1.6046e-03,  1.1479e-05,
         4.2470e-05,  1.5966e-06,  3.7231e-08,  1.5781e-05,  3.1774e-09,
         8.6425e-09,  1.5992e-08,  1.2876e-09,  1.7621e-04,  2.3779e-03,
         5.8704e-07,  1.7641e-04,  1.0235e-08,  2.9932e-10,  7.2088e-08,
         6.8206e-09,  5.0235e-04,  6.1341e-12,  7.0639e-09,  1.3366e-08,
         1.5488e-07,  1.0105e-07,  8.2561e-06,  3.4654e-06,  2.4423e-05,
         3.0217e-08,  9.7263e-08,  2.5182e-06,  9.1337e-07,  1.2067e-06,
         2.8714e-05,  1.6601e-06,  7.6570e-06,  4.8180e-07,  7.3889e-03,
         1.2696e-04,  2.3911e-02,  8.3023e-12,  2.0921e-07,  1.6547e-06,
         4.8653e-03,  7.5664e-09, -2.0207e-09,  1.2088e-05,  1.8003e-06,
         2.6658e-06,  6.3795e-10,  1.8429e-02, -1.2854e-08,  1.7271e-07,
         1.0025e-07,  9.7085e-09,  8.7007e-09, -5.1348e-09,  4.1379e-05,
        -1.8743e-09,  1.7303e-05,  1.1763e-05,  1.3046e-08,  6.5536e-10,
        -4.7984e-09,  1.4826e-06,  1.2185e-02,  9.2224e-05,  4.5982e-05,
         2.9252e-07,  1.0990e-08,  1.4318e-03,  6.3580e-06,  1.7223e-05,
         1.8824e-11,  3.9146e-06,  1.9787e-06,  5.0813e-09,  1.7271e-19,
         3.4834e-02,  8.6173e-04,  1.0210e-06,  8.6192e-03,  1.1705e-07,
         1.2742e-05,  4.5782e-12,  4.6440e-03,  3.1531e-09,  3.4077e-07,
         1.3436e-09,  1.3448e-08, -3.9184e-09, -9.2716e-10,  8.0716e-04,
         6.9904e-04,  8.1184e-04,  1.8939e-03,  9.9237e-05,  1.0618e-09,
         3.7254e-06,  6.6280e-04], device='cuda:0', grad_fn=<AddBackward0>)
That took 19.73398208618164 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@ls18>
Subject: Job 15330919: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
Job was executed on host(s) <12*ls18>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 23:26:12 2020
Terminated at Mon Jul 13 23:26:53 2020
Results reported at Mon Jul 13 23:26:53 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-14/active-supervised --index 2
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   180.85 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.61 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   41 sec.
    Turnaround time :                            41 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.3656, 0.2983, 0.3668, 0.3171, 0.3609, 0.3636, 0.3462, 0.2977, 0.2435,
        0.3664, 0.2232, 0.3668, 0.2208, 0.3648, 0.3668, 0.3535, 0.2495, 0.3611,
        0.3643, 0.3668, 0.3642, 0.3662, 0.3609, 0.3628, 0.3402, 0.3668, 0.3404,
        0.3391, 0.3668, 0.3668, 0.3668, 0.3668, 0.1960, 0.3668, 0.3411, 0.3668,
        0.3378, 0.3654, 0.2620, 0.3667, 0.3668, 0.3668, 0.3611, 0.3668, 0.3649,
        0.3203, 0.3667, 0.3650, 0.3223, 0.2144, 0.3626, 0.3664, 0.3563, 0.3667,
        0.3667, 0.3460, 0.3350, 0.3634, 0.3663, 0.3384, 0.1962, 0.3628, 0.2225,
        0.3058, 0.3668, 0.3668, 0.3448, 0.2107, 0.3388, 0.1477, 0.3647, 0.2046,
        0.3648, 0.3420, 0.3644, 0.2663, 0.3664, 0.3390, 0.2501, 0.3248, 0.3657,
        0.3637, 0.3513, 0.2454, 0.3407, 0.3409, 0.3668, 0.3668, 0.3666, 0.3648,
        0.3668, 0.3668, 0.3668, 0.3655, 0.3481, 0.3656, 0.3666, 0.3659, 0.1701,
        0.3613, 0.3667, 0.2704, 0.3666, 0.3666, 0.3500, 0.3668, 0.2939, 0.3668,
        0.3196, 0.3138, 0.2998, 0.2953, 0.1882, 0.3668, 0.3610, 0.2569, 0.3668,
        0.3644, 0.3620, 0.3668, 0.2162, 0.3668, 0.3668, 0.3428, 0.3668, 0.3668,
        0.3664, 0.2705, 0.3627, 0.3658, 0.1935, 0.3662, 0.3668, 0.3631, 0.3254,
        0.2426, 0.2099, 0.3607, 0.3663, 0.1971, 0.1842, 0.3628, 0.3632, 0.3419,
        0.3251, 0.3668, 0.3588, 0.3657, 0.2791, 0.3576, 0.3662, 0.3568, 0.3274,
        0.3294, 0.3658, 0.2079, 0.3657, 0.3535, 0.3473, 0.3652, 0.3665, 0.3623,
        0.3662, 0.2285, 0.3658, 0.3668, 0.2061, 0.3656, 0.3614, 0.3601, 0.2549,
        0.3535, 0.2997, 0.3029, 0.3341, 0.3651, 0.3253, 0.3483, 0.3590, 0.2194,
        0.3668, 0.3654, 0.3667, 0.3346, 0.3665, 0.3513, 0.3172, 0.3273, 0.3667,
        0.3668, 0.2105, 0.3668, 0.3500, 0.2652, 0.3534, 0.3663, 0.3477, 0.3625,
        0.2992, 0.3615, 0.3668, 0.2508, 0.2411, 0.3666, 0.3153, 0.3667, 0.3667,
        0.3266, 0.3581, 0.2805, 0.3428, 0.3617, 0.3621, 0.2680, 0.3601, 0.3662,
        0.3665, 0.3127, 0.3422, 0.3668, 0.1542, 0.3644, 0.3657, 0.3649, 0.2036,
        0.3657, 0.3141, 0.3009, 0.3411, 0.3668, 0.2979, 0.3359, 0.3668, 0.3602,
        0.3600, 0.3441, 0.3662, 0.3668, 0.3472, 0.3626, 0.2765, 0.3641, 0.3668,
        0.3059, 0.3624, 0.3668, 0.1955, 0.3644, 0.3426, 0.3548, 0.3014, 0.2354,
        0.1699, 0.3611, 0.3668, 0.3667, 0.3123, 0.3150, 0.1498, 0.3226, 0.3627,
        0.3668, 0.3641, 0.3535, 0.3668, 0.3436, 0.3329, 0.2172, 0.3443, 0.3631,
        0.3640, 0.1953, 0.2587, 0.3626, 0.3663, 0.2099, 0.3665, 0.3612, 0.3391,
        0.3666, 0.3668, 0.2224, 0.3072, 0.3656, 0.3668, 0.1829, 0.3637, 0.3596,
        0.3516, 0.2872, 0.3361, 0.3649, 0.3624, 0.1800, 0.2981, 0.3655, 0.2189,
        0.3361, 0.3382, 0.3648, 0.3591, 0.3402, 0.3648, 0.3644, 0.3668, 0.2486,
        0.3661, 0.3666, 0.3534, 0.2606, 0.3639, 0.3666, 0.3633, 0.3660, 0.3668,
        0.2674, 0.2004, 0.3668, 0.1629, 0.2708, 0.3639, 0.3277, 0.3657, 0.3384,
        0.3649, 0.1620, 0.3245, 0.3615, 0.3613, 0.3668, 0.3400, 0.3656, 0.2897,
        0.2876, 0.3568, 0.3399, 0.3539, 0.3585, 0.3655, 0.2070, 0.3666, 0.3470,
        0.3668, 0.2882, 0.3407, 0.3397, 0.3370, 0.3627, 0.3551, 0.3668, 0.3645,
        0.3666, 0.1934, 0.3332, 0.3668, 0.3659, 0.3657, 0.3535, 0.3443, 0.2977,
        0.2071, 0.3664, 0.3234, 0.1479, 0.1850, 0.3558, 0.3542, 0.3667, 0.3649,
        0.3596, 0.3350, 0.3668, 0.3646], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 4.9053e-11,  2.1364e-04,  1.7196e-03,  9.5127e-04,  3.5298e-07,
         1.2774e-03,  4.5145e-04,  6.3961e-03,  2.4605e-04,  3.4257e-03,
         2.3703e-07,  2.4542e-06,  1.3936e-03,  4.9817e-06,  2.7868e-06,
         1.7263e-06,  1.7470e-04,  3.0963e-06,  1.7573e-03,  1.5312e-03,
         7.9578e-04,  1.6184e-03,  1.2830e-04,  1.0003e-04,  2.7531e-07,
         4.2660e-03,  1.5890e-04,  1.8380e-08,  6.1345e-05,  1.7811e-04,
         4.5760e-05,  9.9387e-03,  5.3450e-04,  1.2352e-04,  1.7379e-03,
         1.6494e-03,  1.7720e-06,  1.6806e-03,  2.2392e-04,  1.4818e-06,
         3.0078e-05,  3.6747e-03,  1.6995e-03,  6.4247e-03,  2.8386e-03,
         3.4573e-03,  6.2969e-09,  1.8988e-04,  1.3861e-04,  1.7693e-05,
         9.0386e-08,  4.5018e-03,  1.7267e-03,  4.7713e-04,  2.6843e-04,
         8.0066e-14,  1.6511e-06,  2.7439e-05,  1.3041e-03,  1.9730e-05,
         1.4877e-03,  3.1555e-07,  8.1111e-06,  1.3956e-03,  7.6607e-06,
         3.2428e-09,  7.7141e-03,  2.3139e-05,  1.4061e-04,  9.2804e-04,
         2.5329e-03,  1.1400e-03,  1.5747e-03,  4.3882e-04,  1.7735e-03,
         9.1729e-03,  3.7219e-05,  1.2351e-03,  2.7157e-05,  1.3204e-07,
         8.5981e-04,  1.8605e-03,  6.9245e-04,  4.0940e-07,  7.7091e-09,
         2.9235e-06,  5.3788e-07,  1.7815e-03,  6.4023e-05,  1.9199e-03,
         1.4162e-03,  1.3846e-03,  1.4067e-03,  1.4165e-03,  4.3755e-05,
         8.7110e-04,  7.1044e-04,  8.0642e-05,  4.5689e-05,  7.4901e-05,
         3.1552e-09,  1.0164e-03,  1.4989e-03,  2.1467e-04,  7.9211e-06,
         4.4961e-03,  4.0934e-06,  5.0567e-06,  1.6377e-03,  3.9494e-05,
         7.3070e-04,  6.2946e-03,  3.8071e-05,  2.3477e-03, -5.1713e-09,
         9.8621e-06,  7.0404e-04,  2.8062e-05,  2.7003e-04,  1.6851e-03,
         1.3762e-03,  1.6905e-03,  1.0798e-05,  1.3905e-03,  6.3560e-04,
         1.8460e-07,  4.8062e-05,  1.2363e-06,  1.4569e-03,  3.9437e-05,
         1.6890e-03,  1.7277e-03,  1.6354e-03,  4.4988e-04,  1.0621e-03,
         2.6612e-04,  1.6140e-03,  1.1644e-04,  5.7339e-04,  4.8739e-06,
         1.5641e-03,  7.4030e-03,  1.6862e-03,  9.4083e-04,  1.7242e-03,
         1.1636e-04,  4.9590e-05,  6.0949e-06,  6.8679e-04,  1.4884e-04,
         1.4784e-04,  8.1876e-04,  5.4181e-09,  7.1592e-03,  2.7159e-06,
         5.4344e-12,  4.5358e-05,  1.9253e-05,  5.5254e-07,  1.1881e-03,
         1.7166e-03,  2.1124e-05,  3.2728e-05,  1.6725e-03,  5.3477e-04,
         1.1082e-08,  1.7669e-05,  6.1145e-04,  5.9231e-04,  1.1812e-03,
         1.1406e-05,  1.7228e-03,  1.2985e-03,  3.9828e-03,  1.7281e-06,
         3.0318e-04,  1.7418e-03,  1.6781e-04,  2.1128e-03,  1.2642e-03,
         1.7919e-05,  9.8407e-04,  2.2018e-03,  2.3204e-03,  1.6158e-03,
         2.0803e-05,  1.4875e-08,  1.2803e-03,  6.9387e-04,  1.6584e-03,
         3.1409e-04,  1.6855e-03,  2.4395e-09,  3.6165e-07,  4.1151e-03,
         8.3555e-04,  4.7237e-07,  1.7743e-03,  6.9631e-06,  1.6968e-03,
         2.9340e-03,  5.4547e-04,  1.6996e-12,  2.5804e-04,  4.1201e-04,
         1.3272e-08,  1.3873e-03,  3.3282e-05,  1.5489e-03,  1.1022e-05,
         7.9436e-09,  3.8557e-05,  8.3214e-04,  3.5604e-06,  1.7049e-02,
         7.8641e-04,  1.5631e-03,  9.3508e-04,  1.2016e-05,  2.0015e-02,
        -1.4554e-09,  1.9847e-06,  2.6354e-04,  3.8582e-12,  1.1555e-05,
         2.5573e-04,  4.9027e-05,  2.1124e-05,  1.4377e-07,  2.1481e-05,
         7.1564e-04,  4.8099e-05,  1.1495e-05, -6.4969e-09,  2.1336e-05,
         5.8858e-05,  9.3760e-05,  3.2921e-08,  7.7498e-04,  1.6266e-03,
         2.0740e-04,  1.4083e-03,  4.4200e-04,  1.2388e-14,  1.7270e-03,
         2.6474e-03,  8.0831e-07,  4.2997e-03,  6.2063e-05,  4.8469e-07,
         4.1936e-09,  7.6551e-05,  1.0399e-03,  1.1513e-02,  1.5910e-03,
         4.0584e-03,  1.7368e-03,  2.3432e-08,  3.6139e-04,  8.4831e-07,
         1.7135e-04,  1.6362e-03,  1.3426e-08,  3.7878e-05,  1.6395e-03,
         1.7309e-03,  1.7255e-03,  2.3041e-03,  3.2309e-04,  8.7559e-06,
         8.3369e-05,  2.2669e-04,  6.2497e-04,  5.5741e-13,  1.6458e-03,
         1.6552e-03,  3.5379e-08], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.1897e-08, -9.6713e-09,  1.0348e-08,  5.4706e-13,  1.2017e-05,
         1.2993e-09,  4.5916e-08,  1.7690e-10,  4.3845e-08,  8.0610e-09,
         1.5615e-06,  2.7103e-09,  1.0947e-08,  1.3513e-10,  7.1559e-08,
         1.1743e-07,  9.8759e-07,  2.6950e-11,  1.0304e-08,  5.7333e-07,
         1.0209e-11,  2.1829e-08,  1.1040e-05,  2.2601e-03,  6.5024e-06,
         3.5544e-09,  3.6348e-08, -2.0072e-09, -1.0424e-08,  3.6549e-09,
         9.7163e-08,  5.4282e-04,  3.8372e-11,  3.7511e-16,  2.8606e-09,
         1.5629e-09,  2.7128e-06, -1.2891e-08,  1.0208e-02,  9.4034e-06,
         1.8569e-08,  6.5499e-09,  3.1027e-08,  2.8329e-07,  1.2153e-07,
        -4.6959e-10,  4.2952e-13,  1.3115e-02,  2.6213e-14,  2.6461e-11,
         5.9679e-06,  1.6493e-07,  4.5236e-10,  5.8530e-04,  2.8288e-03,
         4.5173e-08,  1.3772e-04,  3.0327e-11,  2.0372e-08,  1.5261e-06,
         3.2495e-10,  6.3398e-07,  1.8051e-10,  2.2652e-06, -5.0953e-09,
         1.5728e-08,  6.6659e-07,  1.4599e-08,  4.7050e-12,  3.1574e-07,
         2.9788e-03,  1.0409e-08, -2.2641e-09,  3.7936e-07,  1.8933e-02,
         2.8489e-10,  5.7180e-03, -9.1633e-09, -1.0016e-09,  3.6677e-04,
         1.5920e-08,  9.5370e-10,  6.0128e-09,  6.6395e-06,  7.9969e-09,
         5.7182e-08,  4.4996e-05,  1.1166e-09,  8.1141e-05,  2.0789e-03,
         8.1180e-08,  1.5914e-09,  1.4041e-04,  3.3248e-06,  7.7866e-06,
         1.2096e-05,  1.4689e-08, -8.4263e-09,  1.4068e-05,  3.1821e-07,
         6.2291e-12,  1.9354e-06,  1.8960e-08,  2.2405e-09,  1.0173e-02,
         2.4621e-09,  9.2193e-10,  1.0193e-02,  1.2661e-02,  1.7068e-06,
         1.3468e-05,  2.5185e-07,  3.1829e-08,  7.1517e-04, -1.5002e-09,
         9.2144e-12,  1.0328e-05,  1.8746e-08,  4.3030e-09,  8.8359e-06,
         4.4600e-09,  2.4420e-07,  2.9126e-10,  5.3183e-09, -2.4372e-09,
         3.8230e-10,  7.9666e-04,  1.1093e-10,  1.3184e-06,  2.9138e-07,
         1.4988e-08,  4.1261e-06,  2.9544e-03,  3.6419e-04,  3.0056e-09,
         2.4574e-08,  9.0293e-06,  8.4895e-09,  1.4080e-03,  1.4822e-08,
        -5.3598e-10,  7.6259e-08,  1.6786e-11, -6.5409e-09,  2.3224e-03,
         1.7339e-07,  1.4850e-08,  2.5747e-11, -8.2775e-09,  7.8531e-09,
         6.3896e-10,  6.6878e-07,  2.3781e-08, -9.2391e-09,  5.3947e-05,
         8.8484e-08,  4.0442e-09,  2.4707e-09,  1.0089e-08,  2.5173e-03,
        -5.6471e-09,  1.2082e-07,  2.0871e-02,  3.3014e-07,  4.1707e-09,
         2.2991e-08,  2.3910e-05,  7.5814e-08,  3.7176e-05,  1.0973e-02,
         3.8636e-11,  4.1541e-09,  2.9212e-06,  5.2755e-11,  8.3668e-10,
         4.3106e-10,  1.3268e-11,  7.8232e-04,  5.2005e-08,  1.1841e-08,
         5.6247e-07], device='cuda:0', grad_fn=<AddBackward0>)
That took 31.91992449760437 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@ls18>
Subject: Job 15330920: <active-supervised> in cluster <lila> Exited

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
Job was executed on host(s) <12*ls18>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 23:26:12 2020
Terminated at Mon Jul 13 23:27:04 2020
Results reported at Mon Jul 13 23:27:04 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-14/active-supervised --index 3
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   307.96 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.68 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   51 sec.
    Turnaround time :                            52 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.2865, 0.3119, 0.2428, 0.3124, 0.3096, 0.3005, 0.3123, 0.3123, 0.3117,
        0.2547, 0.3113, 0.2707, 0.3111, 0.2934, 0.2602, 0.3113, 0.3112, 0.3055,
        0.2968, 0.2609, 0.2986, 0.2406, 0.3095, 0.3030, 0.3124, 0.2148, 0.3123,
        0.3124, 0.2579, 0.2025, 0.2377, 0.2317, 0.3113, 0.2648, 0.3124, 0.3110,
        0.2109, 0.3125, 0.2772, 0.3100, 0.2359, 0.1986, 0.2688, 0.3064, 0.2215,
        0.2937, 0.3125, 0.1465, 0.2903, 0.3125, 0.3106, 0.3024, 0.2518, 0.3107,
        0.2107, 0.1737, 0.3122, 0.3125, 0.3019, 0.2576, 0.3124, 0.3108, 0.3017,
        0.3115, 0.3123, 0.2394, 0.2474, 0.3122, 0.3107, 0.3088, 0.3109, 0.2887,
        0.3113, 0.2948, 0.3125, 0.2953, 0.3120, 0.2547, 0.3124, 0.3117, 0.3124,
        0.2745, 0.3010, 0.3113, 0.3112, 0.3125, 0.3125, 0.2842, 0.2367, 0.1994,
        0.2901, 0.1757, 0.2424, 0.2316, 0.2754, 0.3124, 0.2807, 0.2366, 0.2752,
        0.3111, 0.3062, 0.3058, 0.3119, 0.3125, 0.2330, 0.3116, 0.1943, 0.3122,
        0.2635, 0.3123, 0.3122, 0.3121, 0.3120, 0.3112, 0.2685, 0.3073, 0.3109,
        0.2236, 0.2960, 0.3051, 0.2286, 0.3115, 0.1604, 0.3050, 0.3124, 0.2243,
        0.2265, 0.2532, 0.3120, 0.3044, 0.2852, 0.3107, 0.2659, 0.2408, 0.3046,
        0.3125, 0.3104, 0.3114, 0.3070, 0.2549, 0.3113, 0.3109, 0.3025, 0.2988,
        0.3123, 0.3125, 0.2180, 0.3089, 0.2794, 0.3120, 0.3092, 0.2516, 0.3106,
        0.3124, 0.3125, 0.2716, 0.3112, 0.2777, 0.3107, 0.3122, 0.2970, 0.2277,
        0.3035, 0.2555, 0.3104, 0.2694, 0.2850, 0.3114, 0.2749, 0.3074, 0.3078,
        0.3112, 0.3110, 0.3123, 0.3121, 0.3125, 0.2889, 0.3124, 0.3125, 0.3101,
        0.3115, 0.1809, 0.2841, 0.2289, 0.3125, 0.3106, 0.3112, 0.3124, 0.3125,
        0.2049, 0.3114, 0.3009, 0.3118, 0.3119, 0.3121, 0.2537, 0.3122, 0.3034,
        0.3122, 0.3065, 0.2586, 0.3116, 0.3116, 0.2311, 0.3122, 0.2262, 0.2111,
        0.3124, 0.3092, 0.3119, 0.3123, 0.3059, 0.3059, 0.3117, 0.3072, 0.2588,
        0.3079, 0.3124, 0.3125, 0.1826, 0.3109, 0.2936, 0.2786, 0.2925, 0.3108,
        0.2807, 0.3124, 0.3119, 0.3125, 0.2672, 0.3122, 0.3125, 0.2385, 0.3096,
        0.3086, 0.3124, 0.2428, 0.2407, 0.3125, 0.3025, 0.3119, 0.2990, 0.2379,
        0.3120, 0.3031, 0.2342, 0.3113, 0.2935, 0.3125, 0.3112, 0.3120, 0.3104,
        0.3108, 0.3072, 0.2672, 0.1937, 0.3123, 0.3125, 0.3109, 0.3124, 0.3046,
        0.2715, 0.2965, 0.3115, 0.2024, 0.3123, 0.3125, 0.3113, 0.3124, 0.3029,
        0.2970, 0.3113, 0.3119, 0.3016, 0.2530, 0.3114, 0.2479, 0.3071, 0.3125,
        0.2346, 0.2446, 0.3113, 0.3121, 0.2933, 0.2345, 0.3110, 0.2994, 0.3089,
        0.3121, 0.3121, 0.3125, 0.2886, 0.3080, 0.3107, 0.3121, 0.2768, 0.3106,
        0.3125, 0.3125, 0.2930, 0.3088, 0.3087, 0.2942, 0.2935, 0.2542, 0.3112,
        0.2663, 0.2279, 0.3111, 0.3117, 0.2955, 0.2317, 0.3014, 0.2827, 0.2814,
        0.3114, 0.3113, 0.2410, 0.3109, 0.3119, 0.3011, 0.3125, 0.2762, 0.3125,
        0.2874, 0.3110, 0.3124, 0.3065, 0.3075, 0.1751, 0.3124, 0.2756, 0.3117,
        0.3121, 0.3096, 0.3087, 0.3112, 0.3113, 0.2833, 0.3112, 0.2304, 0.3124,
        0.2284, 0.3097, 0.3123, 0.3087, 0.3125, 0.3043, 0.3113, 0.2332, 0.2953,
        0.2271, 0.3108, 0.3125, 0.2281, 0.2724, 0.2793, 0.3111, 0.3124, 0.3123,
        0.3114, 0.2312, 0.3125, 0.3110, 0.3114, 0.3119, 0.3115, 0.1990, 0.2919,
        0.3079, 0.3125, 0.2334, 0.2910], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 3.1899e-03,  9.7446e-03,  2.2546e-15,  6.9198e-09,  2.7393e-08,
         2.9951e-04,  2.4594e-12,  1.8048e-02,  2.0925e-11,  3.4325e-05,
         1.9301e-02,  5.3898e-12,  1.0324e-02,  1.0579e-06,  7.6105e-09,
         1.7554e-02,  2.9218e-12,  5.1458e-04,  5.2322e-13,  4.9033e-07,
         1.0586e-02,  1.7809e-02,  9.4428e-03,  1.4701e-02,  9.5499e-03,
        -9.1414e-09,  2.6909e-02,  9.1081e-17,  1.0524e-04,  1.4618e-03,
         3.6619e-02,  7.5555e-03,  3.7233e-02,  1.2554e-02,  4.6839e-04,
         1.0018e-02,  9.8257e-10,  3.5250e-03,  7.0741e-03,  2.0954e-10,
         1.5977e-04,  1.1628e-02,  2.0826e-12,  2.1844e-09,  1.5223e-03,
         6.4423e-12,  4.1923e-03,  3.0724e-12,  2.3619e-07,  4.2374e-11,
         2.3733e-02,  1.4621e-02,  5.1786e-10,  1.1021e-02,  2.0478e-11,
         7.5517e-03,  1.2603e-10, -1.2154e-09,  1.7802e-03,  7.5213e-06,
        -6.0557e-09,  2.5659e-03,  9.1766e-04,  8.5506e-11,  1.1396e-02,
         2.4807e-02,  1.4499e-02,  4.5877e-03,  1.5561e-04,  1.0115e-02,
         7.5711e-03,  1.4114e-02,  8.1884e-04,  5.0256e-03,  2.8305e-03,
         7.4938e-05,  2.4455e-10,  4.7206e-04,  4.8473e-02,  1.3353e-10,
         1.4462e-02,  1.0487e-16,  1.0352e-07,  2.7076e-02, -2.1490e-09,
         2.6267e-02,  9.8500e-08,  4.3474e-03,  1.3294e-03,  3.3902e-03,
         1.4493e-15,  1.5516e-02,  7.8388e-13,  4.5402e-04,  4.8598e-02,
         8.7827e-03,  1.8161e-02,  1.7644e-04,  2.7118e-11,  7.5431e-09,
         8.3826e-17,  5.1227e-03,  2.3364e-03,  1.4778e-11,  2.5696e-11,
         1.8955e-09,  2.1481e-06,  1.2757e-03, -4.1031e-09,  2.1432e-13,
         4.0540e-03,  2.8190e-05,  1.9477e-03,  5.7724e-05,  1.0601e-02,
         3.0670e-06,  1.4091e-04,  1.8456e-12,  8.7230e-06,  2.5406e-10,
         8.0991e-03,  1.2242e-09,  8.5682e-09,  2.8376e-06,  5.1027e-06,
         8.7268e-04,  1.3144e-07,  1.8639e-04,  2.6366e-04,  1.0310e-09,
         1.2321e-02,  2.8399e-09,  4.0510e-06,  1.7801e-02,  3.1590e-14,
         1.0738e-03,  5.6695e-15,  1.0054e-11,  7.6212e-03,  1.0167e-02,
         1.5253e-02,  4.2786e-02,  5.9750e-07,  1.2821e-02,  1.5229e-09,
         4.6562e-02,  3.0441e-10, -4.8173e-09,  2.8981e-05,  3.8520e-03,
         1.0730e-08,  2.0630e-02,  1.4893e-11,  8.8805e-09,  4.0039e-03,
         2.0426e-02,  1.8494e-02,  6.1959e-09,  2.7699e-10,  8.4268e-11,
         6.0039e-03,  3.6505e-05,  9.0826e-03,  4.5172e-02,  6.3603e-03,
         1.2255e-10,  1.7353e-03,  1.1965e-03,  1.6519e-03,  2.1369e-12,
         3.2942e-04,  1.2805e-02,  2.4221e-02,  7.4879e-13,  1.5916e-11,
         3.2168e-03,  1.5158e-02,  2.0546e-04,  3.8425e-13,  1.6570e-02,
         2.7639e-07,  1.5477e-02, -8.3598e-09,  1.7167e-03,  1.4843e-09,
         5.8231e-13,  1.2081e-13,  9.1154e-08,  1.8253e-02,  1.5784e-02,
         1.3673e-13,  3.4728e-13,  1.4053e-02,  2.1809e-03,  5.4178e-12,
         1.2435e-02,  1.0140e-10,  1.8898e-12,  5.6653e-03, -9.2414e-09,
         9.2440e-04,  2.7106e-03,  1.2992e-09,  9.2149e-03,  3.3836e-08,
         1.4182e-02,  7.7716e-03,  2.1333e-12,  1.9367e-05,  1.5462e-02,
         3.9178e-04,  1.0897e-07,  1.4606e-13,  3.7694e-05,  1.9180e-10,
         1.6461e-15, -1.1431e-08,  1.3617e-07,  6.0273e-04,  1.8198e-10,
         3.1095e-07,  2.1031e-03,  1.6135e-03,  7.9644e-03,  2.2505e-12,
         8.9853e-04,  1.7132e-03,  1.1361e-14,  3.7711e-05,  1.9544e-06,
         4.4807e-03,  1.1732e-03, -9.5277e-09,  2.5115e-02,  2.3225e-10,
         9.7912e-12,  1.2941e-02,  1.1538e-12,  6.8552e-11,  3.4185e-03,
         5.3076e-03,  2.2341e-12,  3.4007e-12,  5.1479e-07,  1.0175e-02,
         5.8186e-04,  8.4752e-04,  1.3631e-09,  4.1465e-03,  1.2292e-09,
         1.4190e-13,  4.3876e-03,  3.0722e-02,  3.0559e-03,  2.0468e-02,
         5.4041e-05,  4.0202e-03,  7.8064e-14,  4.2005e-11,  7.6113e-05,
         9.1299e-04,  6.2168e-04,  7.3737e-15,  9.8257e-03,  3.9658e-04,
         1.0275e-02,  1.0991e-09,  7.5148e-10,  9.7213e-03,  2.9628e-11,
         1.2894e-11,  4.1613e-12,  3.7444e-03,  1.0094e-08,  1.6209e-06,
         2.9337e-03,  2.7174e-10], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.9949e-08,  2.7596e-09,  4.3668e-08,  7.1276e-08,  7.3902e-15,
         3.6580e-14,  1.0256e-09,  4.3934e-10,  4.1517e-09, -4.1703e-09,
         5.3433e-08,  3.0703e-09,  1.9826e-08, -8.1844e-09,  1.7885e-08,
         2.0470e-13,  4.6971e-05,  2.0525e-07,  2.6349e-11,  1.4406e-10,
         2.4833e-09,  4.6600e-09,  1.0948e-06,  3.2097e-08,  7.9685e-11,
         5.3520e-13,  2.1550e-11,  5.1398e-08,  3.2127e-09,  6.4112e-07,
         1.4085e-08,  9.3709e-08,  4.6302e-08,  1.3342e-10,  2.2027e-07,
         2.5731e-11,  8.0503e-11,  7.5037e-07,  5.2926e-10,  6.6400e-05,
         1.3187e-09,  2.5118e-09,  1.4458e-08,  2.2469e-15,  1.4288e-09,
         8.9527e-10,  4.9665e-10,  1.1343e-07,  3.7347e-06,  1.4338e-07,
         4.2482e-10,  1.8039e-11,  1.3899e-13, -1.8421e-09,  2.2753e-09,
         7.6495e-11,  3.4505e-07,  5.2338e-13, -5.1654e-09,  2.0753e-08,
         9.8068e-12,  3.4875e-09,  3.9335e-12, -1.4005e-08,  1.8613e-08,
         1.4437e-11, -9.4725e-09,  4.7440e-09, -8.1769e-09,  1.2715e-08,
         6.8841e-09,  8.8961e-11,  1.2224e-07,  2.7095e-11,  3.7027e-08,
         3.5699e-03,  2.9412e-08,  2.0431e-08, -2.7246e-09,  7.3528e-09,
         1.6049e-08,  6.2461e-10,  2.6089e-10,  3.7371e-05,  8.4781e-07,
         1.0335e-13,  1.5593e-10,  1.5702e-09,  3.8132e-13,  2.4854e-10,
         1.9108e-09,  7.0507e-11, -6.5036e-09,  9.7030e-09,  1.3296e-07,
         3.4702e-13,  8.3248e-08,  3.1235e-09,  1.3296e-10,  2.8673e-08,
         4.3237e-08,  5.2624e-09,  7.1163e-08,  4.4464e-13,  3.5681e-09,
         3.2036e-10,  9.3094e-09,  3.9310e-09,  1.2749e-07,  1.5023e-08,
         7.6020e-10,  8.8653e-11,  2.8130e-07,  5.0388e-08,  1.2951e-06,
         1.2090e-14,  1.1060e-10,  1.2537e-07, -6.7461e-09, -1.0569e-10,
         2.5701e-13,  1.8164e-09,  3.0027e-13,  1.2895e-10,  2.9556e-07,
         6.4165e-15, -6.1271e-09,  2.4842e-09,  1.0124e-07,  3.2647e-10,
         5.4656e-08,  2.8511e-08,  8.8038e-07,  2.8046e-10,  8.0389e-06,
         2.6747e-05,  6.9592e-13,  9.5390e-09,  5.2469e-09,  2.0050e-09,
         4.1711e-09,  3.1597e-12,  5.3913e-09,  7.9617e-08,  6.0944e-09,
         1.8271e-13, -9.9524e-10,  5.3425e-11,  4.4498e-06,  5.6080e-08,
         2.1192e-11,  5.9086e-08,  1.8224e-13, -1.3436e-08,  5.5130e-09,
         1.1579e-08,  1.6054e-13, -5.8703e-09,  4.0539e-09,  3.4989e-09,
         5.1010e-05,  3.9437e-09,  6.2033e-08,  6.3010e-07,  9.0140e-12,
         5.5355e-12, -1.0976e-08,  7.0706e-08,  1.4137e-13,  2.8167e-09,
         2.3608e-10,  5.9358e-08, -1.2448e-08,  1.1535e-09,  6.7806e-13,
         2.7896e-11,  4.3151e-10,  5.6848e-08,  4.7155e-07,  1.6095e-07,
         2.5041e-08], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 8.6870e-15,  1.0058e-16,  9.4036e-06,  9.4489e-09,  5.6232e-11,
         7.8298e-13,  7.9740e-14,  1.0360e-12,  9.5352e-09,  1.9792e-11,
         3.9538e-11,  3.2705e-11,  1.2030e-10,  5.5610e-15,  2.9709e-07,
         4.2712e-11,  9.5739e-09,  9.0826e-13,  2.0290e-10,  2.5642e-12,
         5.3255e-11,  1.6394e-10,  9.4136e-11,  3.3543e-15,  2.2681e-09,
         1.4547e-12,  1.8276e-12,  4.1645e-07,  1.2042e-13,  9.8870e-11,
         2.4844e-08,  1.7051e-10,  3.4922e-10,  1.6954e-10,  1.0125e-10,
         2.4796e-12,  1.2302e-09, -8.5948e-09,  2.3131e-12,  1.3603e-16,
         1.1078e-12,  9.1391e-12,  1.1532e-15,  1.4117e-08,  7.1987e-13,
         5.7045e-09,  2.5364e-08,  1.9562e-12,  9.3947e-15,  2.0400e-11,
         1.5553e-13,  3.8542e-09,  3.9117e-08,  1.0869e-09,  1.3487e-09,
         1.2167e-12,  8.1405e-11,  5.4583e-09,  1.0250e-11,  5.2272e-11,
         5.1545e-08,  3.6190e-10,  2.8402e-11,  1.4202e-08,  9.9946e-09,
         8.1177e-11,  3.1587e-08,  1.5459e-08,  2.3426e-07,  1.9548e-13,
         7.0822e-10,  5.8995e-11,  7.0995e-10,  1.5651e-10,  8.0208e-09,
         3.6094e-10,  1.6126e-13,  1.4233e-06,  2.3883e-09,  4.2987e-11,
         1.9533e-09,  6.8073e-15,  6.0032e-14,  9.6749e-15,  2.7383e-09],
       device='cuda:0', grad_fn=<AddBackward0>)


PS:

Read file </home/nguyenm5/coding/pinot/jul-14/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt08>
Subject: Job 15330918: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
Job was executed on host(s) <12*lt08>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 23:26:12 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 23:26:12 2020
Terminated at Mon Jul 13 23:27:07 2020
Results reported at Mon Jul 13 23:27:07 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-14/active-supervised --index 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   175.91 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.33 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   56 sec.
    Turnaround time :                            55 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.3881, 0.2646, 0.4013, 0.2454, 0.3642, 0.3736, 0.2733, 0.2617, 0.3100,
        0.3939, 0.3217, 0.4025, 0.3313, 0.3809, 0.4021, 0.3129, 0.3306, 0.3563,
        0.3759, 0.4025, 0.3757, 0.3917, 0.3635, 0.3681, 0.2353, 0.3991, 0.2488,
        0.2394, 0.4023, 0.4003, 0.4008, 0.4015, 0.3343, 0.4022, 0.2685, 0.3467,
        0.4008, 0.2277, 0.3852, 0.3658, 0.3977, 0.3998, 0.4026, 0.3568, 0.4012,
        0.3808, 0.1640, 0.3982, 0.3828, 0.2258, 0.3565, 0.3682, 0.3941, 0.3309,
        0.3975, 0.3980, 0.2714, 0.2311, 0.3693, 0.3929, 0.2249, 0.3570, 0.3663,
        0.3195, 0.2466, 0.4012, 0.4016, 0.2621, 0.3560, 0.3920, 0.3449, 0.3797,
        0.3318, 0.3798, 0.2673, 0.3772, 0.2934, 0.3933, 0.2457, 0.3079, 0.2081,
        0.3871, 0.3749, 0.3007, 0.3326, 0.2665, 0.2482, 0.4032, 0.4011, 0.3961,
        0.3801, 0.3987, 0.4015, 0.4015, 0.3859, 0.2831, 0.3870, 0.3970, 0.3893,
        0.3395, 0.3570, 0.4048, 0.2855, 0.4056, 0.3969, 0.2935, 0.4005, 0.2621,
        0.4020, 0.2132, 0.2254, 0.2409, 0.2549, 0.3360, 0.4021, 0.3573, 0.3380,
        0.4015, 0.3780, 0.3636, 0.4008, 0.3252, 0.3990, 0.4047, 0.2558, 0.4013,
        0.4006, 0.3940, 0.3032, 0.3673, 0.3891, 0.3590, 0.3924, 0.4015, 0.3692,
        0.1969, 0.3678, 0.3228, 0.3537, 0.3939, 0.3338, 0.3543, 0.3675, 0.3703,
        0.2489, 0.2313, 0.4008, 0.3419, 0.3883, 0.2879, 0.3359, 0.3919, 0.3375,
        0.2175, 0.2114, 0.3880, 0.3302, 0.3876, 0.3133, 0.2814, 0.3834, 0.3949,
        0.3651, 0.3925, 0.3621, 0.3880, 0.4034, 0.3243, 0.3864, 0.3595, 0.3500,
        0.3367, 0.3104, 0.2632, 0.2463, 0.2228, 0.3816, 0.2334, 0.2799, 0.3422,
        0.3207, 0.3993, 0.3855, 0.3988, 0.2129, 0.4061, 0.3034, 0.1962, 0.2398,
        0.3989, 0.3992, 0.3226, 0.4045, 0.2952, 0.2893, 0.3092, 0.3928, 0.2776,
        0.3655, 0.2917, 0.3577, 0.4020, 0.3071, 0.3115, 0.3970, 0.2243, 0.3991,
        0.3986, 0.2431, 0.3340, 0.2783, 0.2567, 0.3625, 0.3637, 0.3025, 0.3535,
        0.3927, 0.4063, 0.2387, 0.2649, 0.4002, 0.3475, 0.3788, 0.3881, 0.3812,
        0.3515, 0.3874, 0.2450, 0.2870, 0.2670, 0.4024, 0.2563, 0.2100, 0.4008,
        0.3504, 0.3503, 0.2719, 0.3919, 0.4012, 0.2740, 0.3680, 0.2868, 0.3759,
        0.4004, 0.2716, 0.3667, 0.4005, 0.3334, 0.3790, 0.2544, 0.3220, 0.2615,
        0.3647, 0.3561, 0.3578, 0.4023, 0.3987, 0.2518, 0.2174, 0.3453, 0.2499,
        0.3650, 0.4022, 0.3764, 0.3144, 0.3989, 0.2736, 0.2104, 0.3256, 0.2662,
        0.3691, 0.3753, 0.3334, 0.3025, 0.3654, 0.3930, 0.3228, 0.3964, 0.3584,
        0.2381, 0.3972, 0.4009, 0.3212, 0.2372, 0.3880, 0.4008, 0.3454, 0.3736,
        0.3480, 0.3063, 0.2859, 0.2347, 0.3804, 0.3675, 0.3571, 0.2763, 0.3866,
        0.3570, 0.2415, 0.2266, 0.3806, 0.3448, 0.3909, 0.3814, 0.3790, 0.4022,
        0.3274, 0.3917, 0.3972, 0.3138, 0.3052, 0.3736, 0.3969, 0.3706, 0.3894,
        0.4031, 0.3204, 0.3355, 0.4009, 0.3502, 0.2860, 0.3743, 0.2650, 0.3883,
        0.2362, 0.3808, 0.3491, 0.2106, 0.3586, 0.3578, 0.3987, 0.2476, 0.3868,
        0.2946, 0.2657, 0.3335, 0.3924, 0.3191, 0.3370, 0.3868, 0.3313, 0.3960,
        0.2792, 0.4006, 0.3744, 0.2499, 0.3924, 0.2329, 0.3677, 0.3216, 0.4017,
        0.3787, 0.3973, 0.3533, 0.2202, 0.4012, 0.3887, 0.3883, 0.3151, 0.2659,
        0.2655, 0.3238, 0.3947, 0.3434, 0.3351, 0.3219, 0.3164, 0.3971, 0.3815,
        0.3493, 0.2321, 0.4014, 0.3786], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 6.1119e-10,  1.4987e-06,  3.7081e-04,  4.5102e-04,  2.0796e-06,
         5.1411e-04,  9.5832e-07,  1.8892e-05,  1.5948e-06,  2.5172e-07,
         5.4143e-08,  7.5931e-06,  3.4735e-04,  5.6066e-06,  9.4139e-07,
         2.6758e-07,  3.9960e-09,  2.1815e-04,  9.4384e-06,  3.8174e-04,
         2.0673e-04,  1.8627e-05,  1.6600e-08,  1.5520e-04,  3.7544e-07,
         1.0289e-06,  3.4504e-07,  3.8607e-06,  7.0775e-05,  1.3834e-08,
         9.8668e-06,  6.3161e-05,  3.4628e-06,  4.2652e-04,  2.7731e-04,
         2.2482e-05,  4.4229e-04,  4.2463e-04,  1.9823e-05,  1.9477e-04,
         2.1878e-06,  2.8447e-06,  9.2601e-07,  2.7928e-08,  2.8749e-04,
         1.7910e-05,  1.4359e-07,  1.2244e-09,  1.0915e-05,  6.6899e-05,
         3.5451e-05,  2.5517e-08,  1.6809e-05,  3.2772e-04,  1.3106e-06,
         1.0744e-06,  3.9301e-09,  3.4615e-05,  3.5573e-05,  3.1468e-04,
         1.6392e-08,  3.4131e-04,  1.0163e-06,  3.9319e-06,  1.3447e-04,
         2.1451e-06,  1.2754e-09,  1.2161e-04,  2.4309e-06,  4.2462e-06,
         3.8866e-04,  6.7545e-08,  7.8743e-05,  4.5868e-04,  8.7047e-05,
         5.4774e-04,  2.0278e-04,  3.5303e-05,  3.0637e-04,  1.4385e-05,
        -8.0063e-09,  1.4354e-04,  5.6831e-04,  6.1426e-06,  9.2573e-07,
         2.8840e-07,  4.1882e-06,  9.3880e-05,  4.4437e-04,  5.2345e-06,
         2.5319e-06,  4.5088e-04,  4.4853e-08,  1.5313e-08,  4.3165e-04,
         4.1896e-05,  4.3133e-04,  1.8054e-05,  1.2923e-05,  1.6436e-05,
         4.2075e-06,  2.3154e-09,  6.4275e-15,  4.3198e-04,  3.7328e-05,
         1.3177e-05,  5.7852e-06,  1.3473e-06,  7.0345e-07,  5.4514e-06,
         4.1182e-04,  3.9803e-05,  3.0118e-04,  4.8324e-09,  3.3326e-05,
         1.7551e-06,  4.0063e-09,  2.2869e-10,  2.8171e-04,  1.0441e-05,
         1.4207e-04,  4.5264e-04,  3.7398e-04,  4.4060e-04,  1.9768e-04,
         3.6726e-04,  4.8294e-05,  1.0290e-08,  8.6797e-07,  1.2991e-06,
         1.6050e-04,  2.2337e-05,  2.5233e-08,  3.0755e-04,  3.2087e-06,
         2.5351e-04,  2.6361e-07,  6.6117e-06,  5.0432e-04,  3.9803e-05,
         3.3441e-04,  8.3923e-14,  2.0727e-04,  5.5349e-05,  4.2167e-04,
         3.1619e-04,  3.7926e-04,  9.6364e-07,  8.6128e-05,  7.0808e-07,
         9.9080e-05,  1.4769e-04,  7.9272e-05,  1.5772e-04,  2.8475e-13,
         2.2240e-06,  1.0329e-05,  2.4385e-12,  3.5777e-05,  2.5770e-06,
         2.6625e-07,  3.2128e-04,  4.0512e-04,  2.1414e-08,  5.2950e-06,
         4.4911e-04,  2.0708e-04,  6.7074e-10,  1.1669e-09,  9.9570e-15,
         3.9017e-05,  2.9456e-04,  5.4096e-06,  4.3379e-05,  4.8894e-04,
         4.5179e-04,  5.5319e-08,  7.9390e-06,  5.1854e-05,  4.6636e-04,
         1.2834e-06,  1.1201e-05,  1.1761e-04,  2.1824e-05,  3.6643e-05,
         4.7614e-07,  1.2312e-06,  3.4590e-04,  5.7540e-06,  2.5001e-08,
         4.3579e-04,  1.3935e-04,  2.2779e-04,  4.1037e-06,  3.1597e-04,
         2.0976e-07,  3.7369e-07,  8.1879e-08,  1.3410e-05,  1.8593e-07,
         2.9398e-06,  1.1761e-05,  4.1729e-04,  3.6365e-09,  2.5575e-04,
         4.9754e-09,  2.7349e-05,  2.5435e-05,  1.5454e-08,  1.5819e-04,
         1.5788e-06,  3.8113e-04,  1.2171e-06,  3.6760e-07,  4.2679e-06,
         3.1926e-05,  1.0289e-05,  3.2343e-03,  1.4745e-06,  2.3910e-04,
         3.7703e-04,  3.2269e-05,  4.4314e-03,  4.2567e-09,  8.6176e-06,
         2.9259e-06,  2.1069e-13,  3.3715e-05,  1.9702e-05,  1.4148e-08,
         1.3512e-05,  5.6151e-08,  6.9388e-06,  1.9245e-04,  4.2123e-06,
         6.3869e-07,  7.2851e-09,  3.4881e-05,  1.1763e-04,  4.2319e-06,
         6.9932e-09,  1.3047e-04,  4.2294e-04,  1.7784e-05,  4.4534e-04,
         1.9517e-04,  1.1079e-09,  5.1723e-04, -6.7356e-09,  1.2524e-05,
         1.0689e-05,  8.3293e-08,  1.3894e-08,  5.3816e-06,  4.2506e-04,
         9.8331e-04,  2.3576e-04,  4.5188e-04,  5.1097e-08,  3.4147e-05,
         7.5722e-07,  4.8607e-06,  4.1813e-04,  1.0055e-08,  1.3788e-05,
         2.4984e-04,  4.2115e-04,  4.3624e-04,  1.9499e-06,  5.4770e-07,
         1.3297e-06,  5.0252e-06,  3.0308e-04,  2.0857e-11,  4.3588e-04,
         4.3009e-04,  2.4826e-07], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 6.6322e-11,  1.3579e-12,  1.6927e-07,  5.1649e-11,  2.1498e-06,
        -8.2574e-09,  1.1694e-08,  2.9682e-08,  9.5399e-08, -1.2976e-08,
        -9.9597e-09,  5.3495e-07,  8.9111e-09,  6.6886e-09,  9.7503e-12,
         1.0756e-05,  2.8846e-05,  1.7527e-09,  7.7030e-08,  1.0101e-02,
        -5.1347e-09, -2.0829e-09,  1.0394e-08,  6.9267e-07, -1.1731e-11,
         1.9802e-05,  3.4788e-05, -2.1010e-09,  1.8326e-08,  5.4008e-04,
         3.6247e-05,  2.1228e-08,  4.8492e-04,  1.1787e-08,  8.2933e-06,
         6.0621e-09,  9.5184e-05, -6.5245e-09,  7.9860e-04,  3.4984e-06,
         6.7088e-09,  7.2814e-14,  5.1852e-08,  2.6060e-09,  2.7177e-07,
         3.4145e-09,  8.5427e-09, -5.8465e-09,  1.6553e-09,  2.1950e-07,
         4.0725e-04,  1.7805e-07,  2.4863e-11,  4.3462e-10,  2.3091e-08,
         5.4365e-06,  2.3963e-09,  6.5600e-05,  3.6640e-05,  3.3669e-10,
         3.0892e-10,  7.4120e-04,  1.1615e-05, -9.5038e-09,  2.9213e-08,
         1.0361e-08,  7.5873e-08,  2.0750e-07,  2.0075e-04,  1.2574e-08,
         2.5854e-05,  5.2058e-02,  2.2378e-05,  1.4693e-08,  4.7501e-06,
         2.0518e-08,  1.1936e-07,  1.1651e-07,  1.2115e-04, -1.3432e-09,
         6.4294e-04,  6.2138e-13,  2.1714e-02,  3.8384e-03,  1.0969e-08,
         6.2512e-08,  9.2585e-06,  2.7470e-12, -3.3030e-09,  1.5398e-06,
         7.3931e-04,  3.7263e-12,  5.5777e-08,  8.5500e-08,  1.8639e-03,
         8.2693e-07,  5.0393e-12,  1.6820e-05,  2.3772e-08,  3.8884e-04,
         5.1524e-06,  2.1845e-08,  1.4071e-08,  3.3795e-06, -9.2337e-09,
         4.3108e-07,  5.2361e-08,  2.7948e-04,  7.2719e-03,  3.0476e-10,
         1.0024e-08,  1.0131e-04,  6.7134e-08,  2.1269e-06,  4.0359e-06,
         9.9485e-07,  2.0534e-11,  2.7353e-05,  1.3720e-09,  2.6589e-10,
         1.0426e-06,  7.5654e-04,  1.9921e-09, -7.3407e-09,  2.5455e-10,
         1.1461e-06,  4.0226e-08,  1.8252e-06,  3.7030e-10,  1.2956e-08,
         6.9347e-04,  3.7445e-09,  5.3553e-05, -7.7500e-09,  3.8311e-04,
         9.7918e-06, -1.0576e-08,  1.1410e-02,  1.4639e-05,  2.5729e-07,
         3.3722e-10,  8.0924e-12,  1.6997e-07,  1.9497e-05,  8.9871e-08,
         1.1315e-08,  6.1105e-06,  7.1814e-10,  3.3419e-06,  5.8134e-12,
         3.2679e-03, -1.0374e-11,  2.7634e-08,  4.4069e-09,  6.3585e-12,
         1.2057e-05,  1.0552e-04,  5.5222e-09,  1.6760e-08,  2.2979e-07,
         4.0583e-09,  1.9766e-04,  1.1308e-08,  1.6736e-05,  6.7034e-10,
         1.1181e-05,  7.9546e-09,  5.7177e-09,  3.7753e-03,  7.1082e-06,
         1.6743e-07,  6.5957e-09,  1.8056e-09,  6.1376e-08,  1.9123e-07,
         6.0328e-04,  1.7823e-04,  6.9022e-10,  2.2686e-08,  1.2256e-07,
         3.0673e-05], device='cuda:0', grad_fn=<AddBackward0>)
That took 34.81147265434265 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-14/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

