Sender: LSF System <lsfadmin@lt09>
Subject: Job 15330654: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:36 2020
Job was executed on host(s) <12*lt09>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:36 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 21:31:36 2020
Terminated at Mon Jul 13 21:32:10 2020
Results reported at Mon Jul 13 21:32:10 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-13/active-supervised --index 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   31.59 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.58 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   35 sec.
    Turnaround time :                            34 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.3501, 0.1821, 0.3628, 0.2210, 0.3278, 0.3366, 0.2808, 0.2224, 0.1703,
        0.3528, 0.1239, 0.3644, 0.1438, 0.3395, 0.3646, 0.2925, 0.1768, 0.3217,
        0.3308, 0.3652, 0.3304, 0.3489, 0.3282, 0.3286, 0.2701, 0.3600, 0.2713,
        0.2697, 0.3651, 0.3613, 0.3626, 0.3616, 0.1628, 0.3650, 0.2764, 0.1675,
        0.3612, 0.2738, 0.3434, 0.2313, 0.3584, 0.3606, 0.3650, 0.3246, 0.3624,
        0.3355, 0.2456, 0.3579, 0.3473, 0.2467, 0.1828, 0.3301, 0.3563, 0.3035,
        0.3554, 0.3580, 0.2810, 0.2636, 0.3170, 0.3531, 0.2740, 0.1881, 0.3286,
        0.1594, 0.2313, 0.3628, 0.3621, 0.2779, 0.1932, 0.3013, 0.1621, 0.3425,
        0.1650, 0.3346, 0.2652, 0.3415, 0.1862, 0.3489, 0.2745, 0.1757, 0.2512,
        0.3461, 0.3335, 0.2932, 0.1767, 0.2308, 0.2583, 0.3676, 0.3627, 0.3547,
        0.3408, 0.3580, 0.3635, 0.3631, 0.3442, 0.2790, 0.3473, 0.3576, 0.3478,
        0.1451, 0.3269, 0.3704, 0.1858, 0.3737, 0.3594, 0.2946, 0.3591, 0.2223,
        0.3649, 0.2223, 0.2246, 0.1947, 0.2114, 0.1591, 0.3653, 0.3201, 0.1766,
        0.3626, 0.3415, 0.3252, 0.3628, 0.1531, 0.3574, 0.3704, 0.2640, 0.3623,
        0.3627, 0.3509, 0.1946, 0.3283, 0.3443, 0.1992, 0.3524, 0.3617, 0.3254,
        0.2499, 0.2203, 0.1534, 0.3184, 0.3557, 0.1631, 0.1818, 0.3331, 0.3324,
        0.2772, 0.2485, 0.3605, 0.3169, 0.3519, 0.2010, 0.3035, 0.3471, 0.3135,
        0.2461, 0.2513, 0.3447, 0.1073, 0.3471, 0.2967, 0.2857, 0.3351, 0.3509,
        0.3276, 0.3482, 0.2085, 0.3447, 0.3672, 0.1544, 0.3478, 0.3184, 0.3163,
        0.2100, 0.2940, 0.2074, 0.2026, 0.2606, 0.3359, 0.2335, 0.2651, 0.3086,
        0.1629, 0.3572, 0.3477, 0.3626, 0.2406, 0.3763, 0.2904, 0.2477, 0.2453,
        0.3601, 0.3570, 0.1531, 0.3692, 0.2955, 0.1789, 0.2827, 0.3484, 0.2731,
        0.3352, 0.2107, 0.3168, 0.3653, 0.1826, 0.1714, 0.3570, 0.2283, 0.3626,
        0.3599, 0.2257, 0.3079, 0.1870, 0.2765, 0.3272, 0.3258, 0.1867, 0.3193,
        0.3529, 0.3771, 0.2360, 0.2368, 0.3589, 0.1770, 0.3380, 0.3476, 0.3422,
        0.1796, 0.3476, 0.2303, 0.1793, 0.2321, 0.3649, 0.2132, 0.2463, 0.3628,
        0.3115, 0.3109, 0.2632, 0.3471, 0.3620, 0.2629, 0.3301, 0.1943, 0.3345,
        0.3624, 0.2204, 0.3307, 0.3623, 0.1594, 0.3379, 0.2667, 0.2979, 0.1835,
        0.2379, 0.1992, 0.3196, 0.3643, 0.3597, 0.2008, 0.2500, 0.1771, 0.2153,
        0.3205, 0.3651, 0.3359, 0.2939, 0.3597, 0.2814, 0.2551, 0.1325, 0.2808,
        0.3286, 0.3415, 0.1594, 0.1829, 0.3287, 0.3535, 0.1533, 0.3575, 0.3194,
        0.2711, 0.3600, 0.3624, 0.2226, 0.3482, 0.3624, 0.1895, 0.3329, 0.3157,
        0.2949, 0.2022, 0.2624, 0.3369, 0.3218, 0.1979, 0.1763, 0.3433, 0.1954,
        0.2695, 0.2518, 0.3432, 0.3139, 0.2930, 0.3440, 0.3379, 0.3645, 0.1425,
        0.3541, 0.3586, 0.2945, 0.1814, 0.3315, 0.3570, 0.3343, 0.3421, 0.3670,
        0.1821, 0.1580, 0.3629, 0.1893, 0.1886, 0.3293, 0.2375, 0.3486, 0.2734,
        0.3428, 0.1916, 0.2404, 0.3162, 0.3249, 0.3580, 0.2707, 0.3425, 0.1883,
        0.2023, 0.3035, 0.3003, 0.3069, 0.2937, 0.3470, 0.1753, 0.3555, 0.2764,
        0.3626, 0.2519, 0.2711, 0.3006, 0.2555, 0.3254, 0.2987, 0.3622, 0.3421,
        0.3554, 0.1805, 0.2617, 0.3615, 0.3440, 0.3518, 0.3061, 0.2687, 0.2079,
        0.1538, 0.3528, 0.2512, 0.1668, 0.1532, 0.2850, 0.2851, 0.3523, 0.3343,
        0.3208, 0.2488, 0.3626, 0.3350], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 2.7401e-03,  2.5641e-04,  1.0733e-03,  4.1889e-05,  8.9825e-05,
         1.1600e-03,  2.2802e-05,  4.3005e-04,  1.4512e-03,  3.2580e-11,
         8.3118e-05,  3.0370e-06,  5.8353e-06,  1.6322e-11,  8.8448e-08,
         1.3551e-03, -7.5398e-09,  3.3383e-08,  1.8884e-05,  6.9569e-05,
         8.2507e-06,  1.6147e-03,  3.3913e-04,  2.2681e-05,  4.2440e-07,
         2.1040e-06,  4.9619e-07,  2.3533e-07,  2.3253e-03,  6.6392e-09,
         6.3774e-05,  4.0195e-03,  3.0845e-06,  7.9284e-07,  2.9093e-08,
         6.3668e-13,  5.3286e-04,  4.1368e-03,  4.5716e-03,  4.6317e-08,
         1.1001e-06,  7.7322e-05,  7.2040e-04,  2.0392e-03,  3.4885e-03,
         1.8149e-04,  1.0340e-06,  1.5379e-05,  3.5895e-03, -8.6841e-09,
         2.7800e-05,  2.2037e-04,  1.2332e-04,  6.2429e-06,  1.5042e-04,
         2.1866e-10,  1.0873e-03,  1.1602e-04,  2.9652e-06,  2.8263e-07,
         1.4992e-07,  1.1520e-05,  2.3191e-10,  4.9228e-04,  5.9021e-05,
         9.3824e-10,  3.4123e-03,  3.1600e-06,  3.5344e-07,  2.0239e-05,
         1.4791e-03,  1.7322e-04,  6.1500e-05,  4.9620e-08,  5.7311e-05,
         2.0227e-05,  7.6440e-04,  2.2625e-05,  1.2864e-08,  2.4797e-09,
         2.1235e-04,  3.0653e-04,  1.7760e-03,  2.3142e-05,  8.6034e-04,
         4.6523e-03,  9.2085e-07,  1.8017e-04,  6.0192e-03,  4.6028e-05,
         8.1847e-06,  8.5857e-06,  6.1541e-03,  8.1026e-05,  1.3877e-05,
         1.8520e-03,  2.9678e-05,  9.0053e-06,  9.9531e-07,  4.0672e-07,
         3.3414e-05,  1.7295e-04,  9.1528e-04,  1.0819e-03, -5.2650e-09,
         1.4390e-10,  1.0642e-04,  2.8050e-04,  8.8550e-07,  6.2014e-05,
         2.6203e-09,  9.7543e-05,  1.5859e-04,  4.0886e-10,  2.1507e-04,
         3.9929e-09,  2.9568e-04, -4.1755e-09,  1.6290e-05,  1.5308e-05,
         3.4984e-05,  7.7130e-06, -2.6282e-09,  4.7911e-07,  9.8088e-04,
         1.7031e-07,  4.0268e-06,  2.8261e-05,  1.3953e-06,  5.2992e-04,
         4.0970e-04,  6.5605e-04,  3.4443e-05,  4.9381e-05,  1.7145e-04,
         3.4861e-03,  1.0252e-06,  2.2520e-09,  3.8082e-03,  3.1577e-05,
         2.3326e-03,  2.2643e-03,  1.0280e-03,  2.1802e-05,  5.0544e-05,
         6.5562e-03,  7.7290e-05,  5.6705e-04,  1.3769e-03,  7.4967e-05,
         5.4398e-05,  5.1288e-08,  8.5431e-08,  1.0189e-06,  8.7525e-10,
         4.2354e-04,  1.0214e-05,  5.7368e-08,  6.9135e-08,  8.1888e-03,
         3.1300e-10,  9.3716e-10,  7.7690e-04,  3.8931e-07,  7.5931e-07,
         2.6708e-05,  2.7968e-06,  3.9470e-05,  9.3173e-07,  5.4995e-08,
         2.1614e-08,  3.8221e-06,  4.8752e-04,  5.2360e-05,  8.5454e-05,
         7.6653e-07,  6.3790e-06,  8.6989e-06,  1.9150e-07,  5.8811e-08,
         2.4956e-03,  3.8988e-03,  2.4674e-03,  5.3832e-04,  1.7793e-04,
         1.4450e-03,  6.3203e-05,  7.2326e-03,  7.7666e-13,  1.6344e-08,
         4.4378e-04,  1.3708e-06,  2.2245e-03,  1.3911e-03,  1.9254e-04,
         1.4724e-06,  1.2412e-04,  6.3736e-06,  1.9483e-03,  3.7201e-05,
         4.4970e-05,  3.9419e-04,  2.8425e-03,  3.7910e-04,  1.7443e-10,
         2.4175e-05,  1.7421e-04, -8.1884e-09,  3.6713e-04,  1.5807e-04,
         2.1889e-13,  1.0372e-05,  5.5490e-06,  2.2339e-03,  7.7367e-03,
         6.8735e-09,  5.9781e-04,  5.7185e-05,  1.8753e-05,  4.9297e-06,
         4.1196e-06,  2.6709e-05,  8.4330e-14,  8.0599e-06,  8.3327e-05,
         1.5402e-03,  7.0768e-06,  1.7993e-08,  6.4475e-09,  6.8090e-04,
         1.5988e-03,  1.6212e-06,  3.8078e-04,  5.7058e-07,  3.1552e-08,
         3.2226e-04,  2.7435e-05,  5.2308e-04,  2.0295e-05,  8.5991e-05,
         8.8801e-07,  4.3842e-09,  2.3206e-04,  7.8349e-04,  3.5054e-04,
         1.4446e-04,  4.0021e-05,  3.1364e-04,  3.8492e-03,  8.7969e-05,
         1.7715e-03,  1.1368e-09,  7.5789e-08,  5.8986e-04,  1.3536e-02,
         1.9529e-05,  3.7410e-03,  1.8785e-05,  2.1422e-08,  1.2622e-06,
         1.5329e-07,  2.9595e-03,  7.5626e-08,  2.8990e-08,  4.3232e-06,
         8.1557e-04,  5.7432e-05,  8.7528e-05,  4.4156e-05,  1.3235e-04,
         3.0149e-03,  1.3941e-05,  2.5585e-03,  4.3780e-04,  3.0165e-05,
         3.6895e-03,  3.1025e-06], device='cuda:0', grad_fn=<AddBackward0>)
That took 25.874878883361816 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-13/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt20>
Subject: Job 15330658: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:36 2020
Job was executed on host(s) <12*lt20>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:37 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 21:31:37 2020
Terminated at Mon Jul 13 21:32:12 2020
Results reported at Mon Jul 13 21:32:12 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-13/active-supervised --index 5
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   32.10 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.63 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   35 sec.
    Turnaround time :                            36 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.3514, 0.2206, 0.3617, 0.2526, 0.3310, 0.3430, 0.3058, 0.2465, 0.2085,
        0.3555, 0.1620, 0.3629, 0.1719, 0.3479, 0.3626, 0.3117, 0.1777, 0.3321,
        0.3402, 0.3634, 0.3411, 0.3535, 0.3311, 0.3379, 0.2902, 0.3600, 0.2958,
        0.2943, 0.3633, 0.3611, 0.3614, 0.3616, 0.1720, 0.3627, 0.2843, 0.3614,
        0.3020, 0.3500, 0.2049, 0.3581, 0.3614, 0.3629, 0.3358, 0.3620, 0.3468,
        0.2710, 0.3598, 0.3513, 0.2752, 0.1709, 0.3409, 0.3574, 0.3200, 0.3574,
        0.3593, 0.3058, 0.2901, 0.3346, 0.3561, 0.2987, 0.1658, 0.3388, 0.1921,
        0.2479, 0.3617, 0.3619, 0.2968, 0.1787, 0.2977, 0.1331, 0.3485, 0.1741,
        0.3477, 0.2997, 0.3474, 0.2248, 0.3537, 0.2964, 0.2105, 0.2686, 0.3521,
        0.3394, 0.3099, 0.1781, 0.2698, 0.2903, 0.3640, 0.3616, 0.3570, 0.3443,
        0.3593, 0.3622, 0.3625, 0.3499, 0.3029, 0.3524, 0.3582, 0.3524, 0.1558,
        0.3366, 0.3656, 0.2255, 0.3662, 0.3592, 0.3080, 0.3604, 0.2523, 0.3626,
        0.2598, 0.2563, 0.2333, 0.2352, 0.1705, 0.3629, 0.3331, 0.1929, 0.3627,
        0.3475, 0.3391, 0.3617, 0.1716, 0.3590, 0.3655, 0.2891, 0.3619, 0.3617,
        0.3549, 0.1968, 0.3393, 0.3492, 0.1605, 0.3554, 0.3622, 0.3370, 0.2756,
        0.2054, 0.1881, 0.3340, 0.3580, 0.1716, 0.1646, 0.3433, 0.3404, 0.3012,
        0.2768, 0.3614, 0.3291, 0.3543, 0.2409, 0.3200, 0.3541, 0.3222, 0.2791,
        0.2879, 0.3504, 0.1616, 0.3528, 0.3108, 0.3073, 0.3448, 0.3551, 0.3390,
        0.3542, 0.1747, 0.3515, 0.3637, 0.1904, 0.3519, 0.3352, 0.3309, 0.1983,
        0.3130, 0.2471, 0.2353, 0.2875, 0.3460, 0.2721, 0.2975, 0.3255, 0.1910,
        0.3593, 0.3516, 0.3614, 0.2721, 0.3668, 0.3092, 0.2823, 0.2834, 0.3600,
        0.3596, 0.1880, 0.3652, 0.3124, 0.2131, 0.3079, 0.3541, 0.2979, 0.3431,
        0.2277, 0.3361, 0.3629, 0.2186, 0.2096, 0.3578, 0.2613, 0.3611, 0.3599,
        0.2678, 0.3229, 0.2159, 0.2981, 0.3373, 0.3377, 0.2216, 0.3343, 0.3548,
        0.3668, 0.2669, 0.2722, 0.3603, 0.1320, 0.3460, 0.3519, 0.3477, 0.1572,
        0.3522, 0.2689, 0.2135, 0.2714, 0.3627, 0.2499, 0.2762, 0.3615, 0.3270,
        0.3276, 0.2937, 0.3530, 0.3617, 0.2925, 0.3410, 0.2377, 0.3427, 0.3611,
        0.2388, 0.3402, 0.3612, 0.1715, 0.3459, 0.2883, 0.3179, 0.2226, 0.2115,
        0.1550, 0.3329, 0.3627, 0.3602, 0.2439, 0.2761, 0.1328, 0.2550, 0.3356,
        0.3626, 0.3442, 0.3140, 0.3598, 0.3072, 0.2776, 0.1559, 0.2963, 0.3390,
        0.3467, 0.1715, 0.1962, 0.3389, 0.3556, 0.1881, 0.3577, 0.3327, 0.2949,
        0.3596, 0.3614, 0.1618, 0.2550, 0.3513, 0.3615, 0.1428, 0.3444, 0.3337,
        0.3133, 0.2381, 0.2890, 0.3433, 0.3333, 0.1547, 0.2145, 0.3500, 0.1777,
        0.2972, 0.2866, 0.3484, 0.3248, 0.3021, 0.3468, 0.3459, 0.3629, 0.1732,
        0.3565, 0.3595, 0.3116, 0.2175, 0.3404, 0.3578, 0.3426, 0.3526, 0.3638,
        0.1999, 0.1336, 0.3615, 0.1322, 0.2273, 0.3404, 0.2610, 0.3525, 0.2979,
        0.3495, 0.1407, 0.2625, 0.3296, 0.3366, 0.3593, 0.2921, 0.3505, 0.2099,
        0.2392, 0.3210, 0.2962, 0.3278, 0.3174, 0.3513, 0.1716, 0.3569, 0.2957,
        0.3615, 0.2441, 0.2956, 0.2967, 0.2866, 0.3369, 0.3181, 0.3621, 0.3479,
        0.3575, 0.1576, 0.2885, 0.3614, 0.3485, 0.3543, 0.3195, 0.2984, 0.2475,
        0.1891, 0.3564, 0.2716, 0.1364, 0.1408, 0.3142, 0.3100, 0.3569, 0.3454,
        0.3334, 0.2750, 0.3619, 0.3439], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.6601e-03,  1.5298e-02,  1.7297e-03,  3.4223e-02,  2.9173e-09,
         3.6936e-03,  1.4024e-03,  3.5855e-08,  1.5791e-02,  2.5289e-02,
         1.6880e-09,  9.9425e-03,  4.3874e-03,  4.2961e-08,  6.4351e-11,
         3.1264e-09,  1.4665e-05,  3.5678e-02,  3.5936e-07,  2.0398e-05,
        -1.1237e-08,  5.1120e-08,  7.3195e-05,  3.5892e-06,  1.7948e-03,
        -1.1586e-08,  2.3946e-05,  1.0890e-06,  4.6119e-12,  1.0440e-02,
         1.4537e-08,  2.2758e-06,  1.3591e-02,  4.5859e-03,  2.1890e-06,
         4.1492e-09,  2.4580e-11,  3.0712e-03,  7.6541e-03,  2.5879e-03,
         1.1912e-10,  6.7983e-05,  1.2068e-02,  1.2421e-02,  5.9251e-03,
         1.3537e-02,  2.1676e-03,  8.9655e-07,  1.5050e-04,  8.2198e-04,
         6.8231e-05,  1.3561e-08,  4.7584e-04,  2.5630e-08,  7.9719e-04,
         2.4396e-05,  1.6847e-02,  5.6322e-09,  2.0020e-02,  5.2964e-05,
         4.8382e-03,  4.8797e-08,  3.6467e-07,  3.8420e-12,  7.3030e-12,
         2.9787e-04,  1.2471e-06,  7.6171e-09,  1.2190e-02,  4.9112e-07,
         1.5393e-05,  1.1583e-03,  5.6665e-03,  2.3716e-03,  5.4971e-04,
         7.9206e-11,  8.4382e-03,  1.8188e-08,  8.3505e-03,  5.4241e-03,
         3.2245e-09,  1.9599e-11, -3.5706e-09,  1.1621e-09,  8.6077e-03,
         6.9275e-05,  1.5071e-04,  1.2138e-02,  8.9941e-12,  4.8216e-04,
         8.7548e-03,  9.0010e-04,  2.9964e-04,  6.7020e-05,  1.2050e-02,
         5.5557e-08,  5.5483e-04,  3.2309e-03,  2.2503e-06,  3.8562e-06,
         9.4806e-07,  7.1302e-11,  2.1835e-02,  2.0316e-03,  4.0411e-11,
         6.5207e-12,  2.0344e-03,  3.3787e-07,  4.4887e-08,  4.5369e-04,
         2.4992e-08,  2.6055e-07,  1.9219e-03,  3.1080e-11,  2.2961e-03,
         1.3027e-08,  2.7245e-04,  1.2598e-06,  3.1049e-03,  1.0888e-05,
         1.3785e-03,  7.2849e-03,  8.3754e-13, -5.9732e-09,  1.6861e-07,
         2.3673e-10,  7.6445e-06,  1.1316e-03,  2.1495e-08,  4.9893e-06,
         1.2522e-04,  5.7612e-03,  2.9696e-04,  8.7106e-04,  2.8882e-03,
         1.3936e-02,  1.2730e-10,  4.6519e-03,  1.5537e-04,  7.3880e-06,
         7.9405e-04,  9.7233e-03,  5.5653e-09,  6.0930e-04,  1.4598e-03,
         1.2843e-06,  1.7158e-02,  2.2149e-03,  2.7265e-03,  2.4435e-04,
         1.1169e-09,  2.8146e-05,  6.8501e-09,  1.1214e-07,  3.4099e-03,
         4.9042e-03,  7.7014e-09,  1.9975e-06,  1.6055e-02,  3.7545e-09,
         8.9293e-10,  8.1684e-04,  2.3023e-07,  8.5092e-06,  2.4900e-04,
         5.4401e-03,  8.7420e-05,  3.1943e-03,  8.8044e-06,  1.3303e-08,
         5.0487e-03,  1.1974e-06,  4.8048e-03,  1.6144e-02,  3.3636e-03,
         2.0508e-06,  4.6347e-03,  1.6845e-05,  3.2484e-04,  1.4820e-02,
         1.1331e-04,  7.6024e-03,  7.2213e-03,  1.0143e-07,  6.1100e-03,
         1.3113e-03,  1.6540e-09,  3.2059e-13,  2.0628e-07,  5.6681e-03,
         1.6530e-06,  1.4122e-02,  1.8361e-02,  2.3210e-02,  4.8329e-03,
         2.7336e-07,  2.0477e-06,  9.7111e-04,  9.4769e-09,  9.1834e-04,
         6.1255e-03,  3.3141e-04,  3.5920e-03,  3.6453e-03, -7.0005e-09,
         1.5642e-05,  2.0138e-06,  7.1044e-06,  1.2412e-04,  8.6796e-06,
         5.1264e-12,  1.4110e-12,  6.7157e-03,  5.3381e-03,  6.7194e-04,
         4.5128e-14,  1.6101e-03,  1.4657e-07,  1.1129e-03,  6.4914e-06,
         9.6546e-04,  5.9609e-03,  3.3156e-11,  4.3867e-03,  2.6305e-03,
         1.6043e-05, -2.8408e-09,  1.3531e-09,  6.3188e-08,  2.6068e-03,
         3.5760e-02,  2.1844e-05,  5.6825e-04,  1.7453e-05,  2.8808e-10,
         2.1068e-04,  1.9710e-07,  3.9209e-03,  8.6252e-08,  7.1380e-04,
         4.5972e-03,  2.0731e-11,  2.0247e-06,  5.7078e-05,  3.6818e-08,
         1.7332e-02,  1.3607e-06, -6.8253e-09,  1.5105e-02,  1.0983e-03,
         7.2983e-10, -3.6083e-09,  8.4439e-10,  7.5856e-03,  1.3972e-02,
        -1.1769e-08,  1.4723e-02,  3.4950e-03,  2.7642e-11,  2.4172e-12,
         2.4393e-08,  1.2189e-02,  7.9915e-11,  7.7593e-08,  2.2784e-03,
         9.2882e-15,  1.7220e-03,  1.5039e-03,  7.6008e-03,  2.6190e-03,
         2.4802e-03, -4.0241e-09,  4.8335e-03,  2.2173e-03,  8.9851e-04,
         9.6811e-09,  1.5633e-04], device='cuda:0', grad_fn=<AddBackward0>)
That took 26.81399440765381 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-13/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt15>
Subject: Job 15330655: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:36 2020
Job was executed on host(s) <12*lt15>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:37 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 21:31:37 2020
Terminated at Mon Jul 13 21:32:23 2020
Results reported at Mon Jul 13 21:32:23 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-13/active-supervised --index 2
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   218.95 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.68 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   47 sec.
    Turnaround time :                            47 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.2201, 0.2586, 0.2562, 0.2539, 0.1968, 0.1762, 0.2259, 0.2567, 0.2649,
        0.2234, 0.2664, 0.2595, 0.2664, 0.1608, 0.2614, 0.2139, 0.2712, 0.1689,
        0.1480, 0.2633, 0.1457, 0.2040, 0.1929, 0.1527, 0.2364, 0.2466, 0.2396,
        0.2405, 0.2630, 0.2497, 0.2552, 0.2519, 0.2698, 0.2620, 0.2429, 0.2724,
        0.2508, 0.2296, 0.1913, 0.2770, 0.2406, 0.2503, 0.2627, 0.1666, 0.2536,
        0.1524, 0.2455, 0.2395, 0.2025, 0.2511, 0.2733, 0.1496, 0.2343, 0.1906,
        0.2333, 0.2365, 0.2284, 0.2408, 0.1890, 0.2218, 0.2327, 0.2745, 0.1610,
        0.2654, 0.2495, 0.2550, 0.2523, 0.2267, 0.2744, 0.2847, 0.2705, 0.1800,
        0.2696, 0.1685, 0.2446, 0.1817, 0.2615, 0.2064, 0.2338, 0.2649, 0.2413,
        0.1893, 0.1512, 0.2196, 0.2712, 0.2544, 0.2394, 0.2704, 0.2550, 0.2261,
        0.1866, 0.2393, 0.2579, 0.2568, 0.1906, 0.2218, 0.1993, 0.2416, 0.2036,
        0.2691, 0.1732, 0.2779, 0.2602, 0.2852, 0.2452, 0.2161, 0.2471, 0.2553,
        0.2621, 0.2515, 0.2499, 0.2567, 0.2542, 0.2698, 0.2630, 0.1480, 0.2703,
        0.2558, 0.1808, 0.1501, 0.2552, 0.2679, 0.2373, 0.2776, 0.2415, 0.2531,
        0.2553, 0.2137, 0.2628, 0.1962, 0.2754, 0.2241, 0.2517, 0.1434, 0.2455,
        0.2775, 0.2657, 0.1717, 0.2311, 0.2699, 0.2738, 0.1618, 0.1526, 0.2314,
        0.2506, 0.2473, 0.1894, 0.2193, 0.2608, 0.2122, 0.2016, 0.1808, 0.2447,
        0.2456, 0.1854, 0.2673, 0.1982, 0.2251, 0.2143, 0.1574, 0.2138, 0.1628,
        0.2087, 0.2754, 0.1902, 0.2699, 0.2653, 0.1994, 0.1545, 0.1819, 0.2717,
        0.2164, 0.2598, 0.2552, 0.2419, 0.1556, 0.2505, 0.2353, 0.1891, 0.2657,
        0.2358, 0.2002, 0.2554, 0.2483, 0.2872, 0.2349, 0.2438, 0.2496, 0.2466,
        0.2362, 0.2657, 0.2749, 0.2111, 0.2613, 0.2195, 0.2060, 0.2295, 0.1557,
        0.2632, 0.1868, 0.2634, 0.2633, 0.2646, 0.2377, 0.2495, 0.2555, 0.2467,
        0.2539, 0.1992, 0.2583, 0.2334, 0.1309, 0.1133, 0.2642, 0.1860, 0.2239,
        0.2860, 0.2520, 0.2528, 0.2427, 0.2718, 0.1681, 0.2024, 0.1857, 0.2735,
        0.2021, 0.2537, 0.2648, 0.2541, 0.2628, 0.2574, 0.2435, 0.2553, 0.1666,
        0.1805, 0.2413, 0.1982, 0.2521, 0.2351, 0.1491, 0.2609, 0.1373, 0.2528,
        0.2527, 0.1573, 0.2527, 0.2696, 0.1680, 0.2325, 0.2020, 0.2585, 0.2789,
        0.2752, 0.1496, 0.2593, 0.2456, 0.2611, 0.2462, 0.2716, 0.2581, 0.1649,
        0.2626, 0.1560, 0.2064, 0.2439, 0.2288, 0.2383, 0.2663, 0.2196, 0.1347,
        0.1849, 0.2696, 0.2640, 0.1621, 0.2245, 0.2657, 0.2419, 0.1504, 0.2344,
        0.2474, 0.2542, 0.2670, 0.2500, 0.2205, 0.2527, 0.2733, 0.1494, 0.1766,
        0.2053, 0.2606, 0.2414, 0.1801, 0.1672, 0.2751, 0.2630, 0.1840, 0.2743,
        0.2388, 0.2415, 0.1888, 0.1794, 0.2838, 0.2030, 0.1682, 0.2609, 0.2684,
        0.2254, 0.2417, 0.2170, 0.2644, 0.1734, 0.2377, 0.1608, 0.1893, 0.2683,
        0.2621, 0.2716, 0.2564, 0.2736, 0.2598, 0.1129, 0.2538, 0.2023, 0.2333,
        0.1783, 0.2737, 0.2444, 0.1711, 0.1763, 0.2396, 0.2390, 0.1857, 0.2603,
        0.2592, 0.2108, 0.2846, 0.1926, 0.2127, 0.2024, 0.2693, 0.2302, 0.2248,
        0.2551, 0.2795, 0.2397, 0.2846, 0.2399, 0.1251, 0.2035, 0.2542, 0.1790,
        0.2315, 0.2731, 0.2413, 0.2518, 0.1900, 0.2194, 0.2002, 0.2355, 0.2597,
        0.2655, 0.2218, 0.2425, 0.2706, 0.2698, 0.2225, 0.2195, 0.2226, 0.1472,
        0.1760, 0.2454, 0.2572, 0.1628], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.9478e-05,  2.6226e-08,  3.1959e-10,  1.7825e-02,  4.9419e-02,
        -5.5430e-09,  3.2913e-12,  1.2827e-14,  8.1722e-11,  8.3304e-09,
        -1.1213e-08,  2.8740e-08,  3.2088e-12,  2.3842e-08,  2.4580e-10,
         6.8395e-12,  5.3021e-02,  1.9875e-09,  1.0409e-14,  6.1619e-09,
         1.2569e-11,  1.7851e-12,  6.4209e-07,  2.9105e-10,  1.0279e-08,
         6.6375e-08,  7.6984e-09,  3.6261e-08,  8.4297e-10,  2.7862e-05,
         2.8127e-05, -5.6088e-09,  4.1180e-07,  2.0634e-10,  1.4497e-10,
        -5.1414e-09,  2.1882e-06,  1.2820e-14,  5.5201e-10,  6.1372e-09,
         1.7130e-07,  1.7412e-07,  2.2672e-09,  5.7337e-10,  1.7945e-12,
         9.0612e-12,  2.8488e-08,  2.9823e-09,  1.0249e-09,  2.7099e-08,
         1.1648e-08,  3.1610e-09,  2.4824e-13,  1.6898e-09,  5.7129e-10,
         7.1980e-11,  9.9522e-09,  1.0902e-13,  1.7670e-14, -4.1384e-09,
         5.8040e-09,  2.4210e-09,  6.3675e-14,  1.9385e-05,  3.7368e-04,
         5.8910e-11,  4.4876e-10,  4.3488e-05,  1.6364e-07,  1.8170e-09,
         3.2511e-08,  2.8310e-10,  3.2842e-02,  5.2912e-08,  4.4372e-08,
        -8.7045e-09,  1.2822e-08,  9.2479e-08,  1.4356e-12, -6.8047e-10,
         7.7147e-14,  2.5686e-08,  4.0601e-02,  2.5213e-07,  2.4306e-04,
         4.6200e-11,  2.5640e-06,  2.6053e-08,  4.1614e-08,  3.6950e-09,
         7.7862e-12,  3.8326e-15,  7.9424e-07, -1.0306e-08,  1.6535e-07,
         6.4006e-04,  1.8072e-07,  6.7584e-09,  6.8351e-09,  2.6531e-16,
         3.4203e-04,  4.3511e-05, -1.0648e-09,  1.0719e-11,  2.1413e-11,
         1.8696e-17,  8.9495e-09,  2.1691e-10,  1.1460e-07, -1.0810e-08,
         1.7335e-10,  7.3903e-08,  8.9086e-02,  3.4249e-10,  2.7636e-11,
         1.0703e-06,  3.5532e-12,  1.4716e-07,  1.6634e-03,  6.9948e-13,
         5.0362e-11,  8.9970e-11,  4.1046e-10,  2.8408e-09,  1.2424e-03,
        -7.1572e-09,  2.4176e-13,  7.9535e-15,  8.1067e-13,  2.0153e-15,
         4.3078e-11,  3.1272e-12,  1.8562e-07,  8.6305e-10,  9.5093e-06,
         1.4002e-06,  2.0422e-04,  1.6547e-09,  1.3845e-08,  5.6015e-09,
         1.6232e-10,  8.0801e-11,  1.0311e-08,  8.1485e-11,  5.9856e-08,
         4.6434e-03,  1.4726e-12,  1.7903e-09, -5.6488e-09,  7.1093e-08,
         9.3461e-04,  5.1935e-06,  1.3336e-08,  1.3854e-11,  7.3146e-08,
         1.6827e-13,  1.7256e-13,  3.6053e-04,  1.3915e-08,  4.4837e-11,
         1.1254e-08,  2.9693e-13,  1.3521e-06,  4.5750e-09,  4.7331e-10,
         6.8515e-09,  1.5406e-09, -5.3058e-09,  1.9660e-06,  3.9236e-05,
         1.0578e-10,  1.8110e-09,  1.7449e-09,  1.8035e-07,  5.4172e-02,
         5.0631e-08,  9.4720e-14, -7.6627e-10,  4.1994e-08,  1.1644e-09,
        -6.5541e-09, -9.0107e-09,  9.1624e-04,  1.0676e-09,  2.8265e-07,
         4.5660e-10,  7.2405e-09,  3.8750e-09,  2.2860e-08,  1.7244e-10,
        -3.9561e-09,  2.9457e-10,  6.5198e-12,  9.9747e-07,  1.8451e-12,
         6.0538e-11,  1.2527e-08,  3.2349e-07,  8.5718e-11, -4.5967e-09,
         3.4413e-09,  4.8223e-07,  4.0570e-07,  8.2494e-10,  5.2838e-09,
         8.6715e-08,  1.6698e-10,  9.0853e-15,  6.9150e-06,  7.7477e-07,
         2.7853e-02,  8.5537e-07,  6.3675e-08,  2.1691e-09,  3.0434e-10,
         7.3686e-02,  1.2514e-13,  6.9293e-03,  4.7460e-08,  2.0617e-03,
         5.8649e-12,  1.8242e-09,  1.1820e-10,  1.4970e-08,  1.6073e-06,
         3.7369e-10,  4.7300e-05,  3.7841e-05,  2.7370e-13,  2.3402e-08,
         4.5197e-08,  1.4649e-10,  8.5388e-09,  5.8258e-07,  6.9429e-10,
         3.3198e-10,  1.1480e-08,  7.3157e-11, -6.8877e-09,  7.1773e-04,
         1.1233e-08,  1.7833e-08,  6.8173e-08,  6.1074e-12,  2.2155e-13,
         1.1453e-16,  8.4932e-04, -3.4893e-09,  4.5636e-08,  3.3848e-07,
         1.6603e-04,  4.8625e-08,  5.3232e-10,  8.4675e-12,  3.0032e-02,
         6.0157e-08,  1.1543e-08,  7.9587e-09,  3.8497e-07,  2.6592e-07,
         1.1447e-14,  1.7829e-08,  5.1527e-12,  1.7605e-07,  6.6048e-10,
         2.9922e-14,  1.8251e-14,  2.8782e-08,  2.8881e-11,  5.0464e-08,
         3.1950e-09,  2.5953e-02, -4.8602e-09,  1.0528e-08,  9.3146e-11,
         1.9828e-11,  2.9318e-03], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.2645e-08,  2.4447e-07, -1.0793e-08, -7.8206e-09,  2.5629e-09,
         3.8798e-07,  1.5506e-04, -2.7455e-09,  1.8917e-08,  4.1916e-08,
         1.5711e-09,  4.6291e-07,  1.4582e-08,  3.6728e-07,  3.0577e-09,
         4.3913e-10,  8.1479e-10,  6.2808e-09,  5.3941e-05,  3.3037e-07,
         3.4963e-06,  4.8051e-13,  8.4041e-09,  1.5165e-08,  8.5830e-07,
         1.2311e-08,  1.0738e-04,  1.2965e-08,  6.7197e-09,  5.3953e-07,
         2.1053e-08,  6.1346e-06,  4.7633e-08,  1.9720e-07,  1.3423e-06,
         4.5365e-07,  6.8875e-09,  1.0738e-04,  5.4496e-07,  5.0568e-09,
         6.8888e-07,  1.2929e-08,  1.7081e-08,  4.4643e-08, -7.3441e-09,
         4.2772e-08,  1.3831e-08,  1.5790e-05,  1.2625e-08, -8.6725e-09,
         6.2682e-06,  1.4343e-06,  4.6601e-06,  6.4116e-08,  2.1892e-06,
        -5.8669e-09,  7.1428e-05,  9.5519e-08,  2.8856e-09,  3.2430e-08,
         1.1925e-08,  1.1401e-08,  5.9026e-06,  2.9714e-09,  5.8066e-10,
         1.0136e-08,  8.6987e-06,  1.4985e-13,  2.4042e-08,  1.9458e-07,
         3.1196e-08, -7.9255e-09,  7.2821e-09,  4.9310e-06,  1.7212e-07,
         1.7410e-04,  4.5679e-09,  6.0710e-07,  9.5758e-09,  2.6186e-08,
         5.5037e-08,  1.8703e-05,  7.7591e-07,  1.9719e-09,  9.4883e-08,
         1.0687e-08,  1.1403e-08,  5.3825e-09,  2.4949e-07,  6.0449e-09,
         1.2366e-05,  8.1273e-11,  3.0188e-09,  1.7207e-06,  4.8124e-08,
         9.7625e-06,  4.6957e-09,  5.8338e-08,  3.6881e-07,  4.3552e-07,
        -4.8376e-09,  1.0395e-07, -2.2470e-09,  3.3577e-07,  9.4695e-09,
         8.1116e-10,  4.6858e-08,  1.0710e-06,  2.7008e-08,  1.1035e-07,
         4.0959e-05,  9.3514e-05,  4.2163e-09,  1.4522e-10, -5.2246e-09,
         7.1222e-07,  3.6618e-09, -1.0373e-08,  2.1057e-06,  1.3541e-05,
         1.1339e-04,  2.8571e-09,  2.1442e-08,  1.2955e-04,  9.3421e-05,
         5.0029e-05,  3.6721e-09,  2.2294e-09,  3.3134e-08,  1.6209e-05,
         7.3495e-08,  1.2786e-07,  1.0341e-08,  3.3892e-07,  7.9320e-09,
         2.0600e-07,  3.8059e-08,  5.1055e-05,  2.0254e-08,  3.4677e-07,
         2.9131e-08,  1.1242e-05,  1.5313e-05,  6.3355e-11,  3.1460e-08,
        -4.2875e-09,  7.8363e-09,  1.2404e-09,  1.2774e-07,  7.7654e-05,
         2.4764e-09,  1.3757e-08,  3.2560e-08,  1.0130e-06,  7.9763e-08,
        -1.3449e-08,  8.3397e-13,  1.9897e-08,  2.4218e-04,  8.3477e-08,
        -1.0280e-09,  5.4486e-12,  3.5317e-07,  4.5528e-13,  5.2650e-06,
         1.2950e-08,  3.6021e-10,  3.9414e-05,  1.2578e-07,  1.7343e-07,
         1.4169e-06,  7.2729e-09,  1.6883e-07,  5.4919e-09,  1.0765e-08,
         9.5023e-09,  3.4905e-09,  3.7481e-05,  1.1235e-05,  1.3167e-07,
         2.4180e-05], device='cuda:0', grad_fn=<AddBackward0>)
That took 38.15347719192505 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-13/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt12>
Subject: Job 15330656: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:36 2020
Job was executed on host(s) <12*lt12>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:37 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 21:31:37 2020
Terminated at Mon Jul 13 21:32:24 2020
Results reported at Mon Jul 13 21:32:24 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-13/active-supervised --index 3
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   226.25 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.69 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   48 sec.
    Turnaround time :                            48 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.3105, 0.1760, 0.3339, 0.1941, 0.2811, 0.2957, 0.2428, 0.2093, 0.1915,
        0.3182, 0.1514, 0.3360, 0.1682, 0.3020, 0.3367, 0.2480, 0.1771, 0.2808,
        0.2855, 0.3369, 0.2864, 0.3128, 0.2807, 0.2911, 0.2411, 0.3282, 0.2483,
        0.2487, 0.3369, 0.3316, 0.3339, 0.3319, 0.1727, 0.3373, 0.2335, 0.3313,
        0.2389, 0.3102, 0.1891, 0.3213, 0.3269, 0.3371, 0.2893, 0.3327, 0.2996,
        0.2270, 0.3250, 0.3122, 0.2337, 0.1542, 0.2948, 0.3229, 0.2628, 0.3195,
        0.3258, 0.2469, 0.2330, 0.2743, 0.3183, 0.2475, 0.1328, 0.2913, 0.1589,
        0.2031, 0.3341, 0.3327, 0.2401, 0.1617, 0.2467, 0.1351, 0.3070, 0.1713,
        0.2964, 0.2306, 0.3029, 0.1813, 0.3095, 0.2509, 0.1920, 0.2198, 0.3095,
        0.2891, 0.2558, 0.1775, 0.2043, 0.2188, 0.3411, 0.3338, 0.3227, 0.2938,
        0.3263, 0.3348, 0.3337, 0.3102, 0.2362, 0.3143, 0.3240, 0.3122, 0.1638,
        0.2848, 0.3450, 0.1843, 0.3503, 0.3272, 0.2561, 0.3266, 0.2220, 0.3374,
        0.1951, 0.1958, 0.1869, 0.1843, 0.1719, 0.3372, 0.2804, 0.1866, 0.3323,
        0.3057, 0.2883, 0.3339, 0.1371, 0.3228, 0.3449, 0.2256, 0.3325, 0.3339,
        0.3151, 0.1744, 0.2859, 0.3006, 0.1362, 0.3202, 0.3313, 0.2817, 0.2267,
        0.1582, 0.1601, 0.2851, 0.3212, 0.1726, 0.1318, 0.3006, 0.2940, 0.2467,
        0.2331, 0.3301, 0.2748, 0.3177, 0.1970, 0.2596, 0.3129, 0.2698, 0.2105,
        0.2350, 0.3067, 0.1607, 0.3143, 0.2570, 0.2466, 0.2907, 0.3138, 0.2949,
        0.3155, 0.1472, 0.3102, 0.3378, 0.1614, 0.3127, 0.2779, 0.2822, 0.1886,
        0.2570, 0.1916, 0.1802, 0.2328, 0.2972, 0.2081, 0.2258, 0.2644, 0.1612,
        0.3230, 0.3123, 0.3312, 0.2176, 0.3597, 0.2584, 0.2207, 0.2189, 0.3304,
        0.3252, 0.1601, 0.3427, 0.2597, 0.1873, 0.2415, 0.3133, 0.2356, 0.2989,
        0.1760, 0.2797, 0.3376, 0.1702, 0.1919, 0.3228, 0.1967, 0.3334, 0.3305,
        0.2007, 0.2728, 0.1758, 0.2462, 0.2865, 0.2844, 0.1694, 0.2902, 0.3178,
        0.3628, 0.2150, 0.2103, 0.3281, 0.1387, 0.3028, 0.3133, 0.3073, 0.1387,
        0.3119, 0.2108, 0.1741, 0.2051, 0.3371, 0.2126, 0.2156, 0.3342, 0.2665,
        0.2659, 0.2268, 0.3107, 0.3327, 0.2245, 0.2948, 0.1951, 0.2926, 0.3325,
        0.1980, 0.2955, 0.3322, 0.1701, 0.3027, 0.2269, 0.2633, 0.1760, 0.1816,
        0.1423, 0.2801, 0.3360, 0.3300, 0.1879, 0.2375, 0.1372, 0.1929, 0.2767,
        0.3355, 0.2997, 0.2564, 0.3285, 0.2578, 0.2204, 0.1490, 0.2404, 0.2839,
        0.3036, 0.1701, 0.1734, 0.2915, 0.3180, 0.1601, 0.3243, 0.2799, 0.2346,
        0.3279, 0.3324, 0.1554, 0.1966, 0.3115, 0.3322, 0.1437, 0.2986, 0.2775,
        0.2514, 0.1919, 0.2324, 0.2892, 0.2799, 0.1399, 0.1640, 0.3057, 0.1599,
        0.2553, 0.2156, 0.3087, 0.2686, 0.2423, 0.3027, 0.3028, 0.3358, 0.1738,
        0.3196, 0.3253, 0.2547, 0.1689, 0.2885, 0.3228, 0.2983, 0.3035, 0.3403,
        0.1849, 0.1336, 0.3324, 0.1400, 0.1851, 0.2880, 0.2046, 0.3139, 0.2511,
        0.3058, 0.1437, 0.2097, 0.2703, 0.2885, 0.3264, 0.2356, 0.3084, 0.1847,
        0.2096, 0.2603, 0.2460, 0.2729, 0.2516, 0.3119, 0.1429, 0.3166, 0.2368,
        0.3340, 0.2022, 0.2481, 0.2462, 0.2157, 0.2842, 0.2596, 0.3323, 0.3057,
        0.3208, 0.1501, 0.2334, 0.3319, 0.3027, 0.3177, 0.2724, 0.2385, 0.1920,
        0.1604, 0.3223, 0.2287, 0.1376, 0.1442, 0.2421, 0.2442, 0.3172, 0.2938,
        0.2885, 0.2158, 0.3323, 0.2917], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 5.1992e-06,  2.5439e-02,  1.4750e-06,  1.2143e-02,  9.2108e-09,
         2.6579e-03,  1.3167e-04,  7.0486e-05,  1.9275e-02,  1.7199e-02,
         3.8650e-10,  9.0419e-04,  5.0895e-03,  8.3205e-05,  7.2043e-04,
         4.2662e-05,  2.6278e-08,  1.4928e-02,  3.7789e-05,  1.3142e-04,
         3.4280e-06,  6.4537e-07,  4.4519e-03, -1.2021e-08,  3.7334e-06,
         1.2069e-05,  3.0235e-03,  6.9562e-06,  1.3332e-05,  4.9496e-03,
         8.5651e-09,  4.2853e-05,  1.4818e-02,  2.2873e-04,  2.8575e-05,
         3.1820e-06,  1.4209e-05,  3.8760e-06,  8.6540e-06,  1.6344e-03,
         1.8076e-06,  6.2715e-04,  6.6078e-06,  4.7287e-03,  1.2813e-02,
         1.9753e-02,  7.0011e-03,  1.4447e-09,  3.4086e-03,  1.3080e-04,
         3.7822e-05,  2.3257e-16,  4.5396e-05,  2.0440e-06,  1.5664e-04,
         1.2185e-03,  4.3805e-03,  1.5514e-15,  1.1913e-02,  1.3818e-04,
         4.6016e-03,  3.0395e-03,  3.4137e-05,  9.1777e-10,  1.4978e-07,
         5.3504e-05,  5.9480e-10,  9.1728e-03,  2.8542e-05,  1.3575e-05,
         1.4593e-04,  2.9801e-03,  1.9376e-02,  6.1061e-04,  1.6590e-05,
         6.8905e-03,  1.8923e-03,  1.3187e-02,  8.0090e-03,  8.5563e-08,
         6.9485e-06,  2.7110e-05,  1.3628e-03,  6.3651e-03,  4.1785e-05,
         6.6064e-05,  7.8953e-03,  2.1453e-06,  9.1260e-04,  1.2776e-02,
         2.0588e-03,  1.6441e-05,  4.0336e-03,  9.5665e-03, -1.3043e-08,
         5.9580e-05,  2.5477e-04,  3.8973e-05,  9.7107e-05,  9.5638e-05,
         5.5114e-05,  6.7456e-06,  9.6368e-03,  6.3953e-05,  2.8051e-07,
         1.1032e-08,  7.3327e-03,  1.2707e-07,  4.3519e-05,  7.4396e-05,
         3.2954e-04,  4.6267e-06,  7.8036e-03,  2.0512e-07,  3.7164e-03,
        -5.4050e-09,  6.0874e-07,  7.0177e-07,  2.8268e-04,  4.3056e-05,
         4.3078e-04,  4.2829e-03,  2.5180e-05,  4.1205e-04,  9.2433e-03,
         7.1903e-03,  2.7059e-03,  3.8424e-03,  2.7102e-06,  4.4520e-05,
         4.8033e-09,  3.7965e-04,  1.0449e-07,  2.0169e-03,  1.4760e-03,
         1.5451e-02,  5.2398e-03,  9.7663e-11,  1.5159e-02,  1.5956e-04,
         6.0767e-05,  1.6588e-04,  3.1343e-03,  2.0996e-04,  6.1485e-04,
         4.2780e-03,  2.0401e-07,  1.5989e-02,  5.6052e-04,  1.4749e-04,
         1.3039e-07,  4.0563e-05,  1.9368e-04,  3.4279e-05,  1.4420e-02,
         5.4839e-03,  2.4880e-04,  2.0021e-08,  5.6673e-13,  5.6566e-03,
         1.4945e-15,  1.2707e-04,  1.2648e-02,  3.2607e-03,  1.3916e-03,
         1.4326e-02,  1.3351e-02,  1.1754e-06,  6.9622e-07,  5.5446e-06,
         6.7704e-03,  2.3902e-04,  4.5407e-05,  7.5717e-05,  1.3787e-02,
         4.5968e-05,  9.7868e-04,  2.3423e-04,  9.9390e-04,  1.3566e-07,
         2.4166e-02,  1.8161e-02,  4.2325e-03,  1.1718e-02,  3.7543e-05,
         7.7846e-04,  3.1755e-03,  8.4297e-03,  1.3767e-03,  5.9822e-05,
         1.4066e-02,  6.2608e-05,  2.0217e-02,  1.9561e-02,  1.3004e-02,
         1.4256e-05,  3.7171e-10,  9.7866e-04,  2.3297e-03,  3.4495e-05,
         1.9358e-03,  1.1051e-02,  4.5700e-03,  1.0884e-02,  2.9896e-03,
         8.3949e-09,  2.3201e-05,  1.4568e-06,  5.9642e-06,  7.1607e-07,
         4.0586e-05,  9.5899e-06,  3.9695e-06,  9.4819e-04,  1.5510e-03,
         1.0494e-02, -7.6224e-09,  8.4039e-03,  2.3186e-05,  1.5208e-02,
         1.1106e-05,  1.9039e-05,  2.5922e-02,  9.2197e-07,  2.2650e-04,
         5.0188e-04,  3.0777e-07,  5.0147e-05,  1.1079e-05,  1.7070e-06,
         2.1581e-05,  3.0399e-02,  6.5832e-03,  1.2274e-04,  2.8917e-05,
         7.2919e-05,  3.4133e-04,  5.3169e-05,  4.3198e-07,  4.3355e-04,
         3.3797e-03,  9.1046e-06,  1.0780e-11,  2.4059e-04,  1.6976e-05,
         2.0967e-02,  8.2342e-05,  5.1917e-08,  2.0247e-02,  3.3052e-05,
         1.5071e-02,  5.6538e-10,  5.4515e-05,  1.4200e-02,  3.3535e-02,
         3.2435e-06,  1.9729e-02,  9.2092e-05,  6.9554e-06,  1.6603e-05,
         8.5317e-08,  1.4877e-02,  3.1693e-05,  1.8982e-12,  5.0605e-06,
         2.1609e-03,  6.9375e-04,  2.4054e-03,  4.9293e-03,  9.4880e-03,
         4.8588e-03,  4.3115e-03,  9.1708e-03,  1.3013e-03,  1.0046e-04,
         2.7484e-03,  1.0783e-04], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.4400e-10,  4.4327e-05,  1.4135e-10,  5.7518e-11,  2.4561e-14,
         1.0293e-08,  1.3170e-08,  4.5033e-13,  6.9558e-10,  2.1260e-11,
         1.7196e-09,  3.6232e-11, -3.0143e-09,  8.0345e-13,  2.1060e-09,
         3.3409e-08,  8.4054e-10,  7.5873e-06, -1.3808e-09,  2.1252e-06,
         8.3612e-19, -2.5089e-09,  4.6071e-08,  3.0776e-05,  1.7783e-08,
         3.7629e-09,  1.6426e-05, -6.7518e-09,  7.4555e-08,  9.5209e-06,
         2.4491e-07,  1.0412e-11, -2.8042e-09,  7.4407e-06,  1.2314e-05,
         2.5153e-08,  4.4496e-09, -4.9685e-09,  4.5830e-14,  4.1203e-14,
         8.3143e-09,  8.1191e-17,  2.1944e-04,  2.2638e-08,  1.2731e-07,
         1.3672e-02,  3.8107e-12,  1.4365e-07,  2.3301e-07,  1.1038e-10,
         8.6833e-03,  8.9723e-06,  1.3357e-13,  6.7733e-08,  1.5964e-07,
         2.8107e-14,  1.1421e-04,  5.0155e-05,  8.7723e-05,  7.1654e-09,
         2.9822e-09,  3.6529e-17,  1.3603e-08,  2.4354e-16,  8.9406e-11,
         3.3513e-07,  8.5768e-09,  2.2811e-11,  2.6662e-05,  6.8536e-03,
         3.6798e-08, -8.8667e-09,  6.7996e-09,  2.0495e-05,  9.4802e-04,
         6.0498e-09,  1.0281e-05,  1.8332e-08, -8.9414e-09,  3.4045e-03,
         2.9503e-10,  1.2855e-03,  1.1476e-10,  1.6610e-10,  3.9011e-10,
         2.1604e-09,  6.2368e-11,  9.3815e-09,  1.1907e-07, -8.7877e-09,
         4.5582e-05,  1.1288e-07,  3.0605e-08,  2.7911e-10,  2.6119e-07,
         3.2818e-03,  2.2075e-16,  9.4816e-03,  1.7636e-05, -1.1765e-09,
         8.4243e-09,  5.9336e-04,  1.0762e-05,  2.1359e-12,  2.0357e-09,
         1.2688e-07,  8.3825e-09,  1.2406e-08,  2.7049e-10,  1.0455e-08,
         6.7644e-10,  6.5111e-03,  4.6900e-05,  6.6771e-07,  5.2961e-08,
         1.3320e-08,  1.8220e-11, -2.7484e-09,  3.0292e-15,  8.7662e-08,
         3.7978e-04,  9.7237e-08,  6.6571e-11,  1.6328e-09,  1.0282e-09,
         1.4182e-09,  8.2572e-05,  4.1258e-10,  3.2863e-07,  3.0313e-15,
         6.2390e-14,  6.3159e-04,  2.3251e-04,  1.0520e-05, -1.0649e-08,
         3.5407e-03,  4.9844e-06,  1.5927e-08,  1.0852e-07,  6.7017e-03,
         2.1295e-08, -8.4429e-09,  1.2503e-07,  2.2257e-05,  6.1551e-10,
         3.0327e-13,  8.8027e-08,  8.1074e-05,  1.3624e-06,  8.0774e-05,
         9.0452e-08,  4.0869e-09,  1.0698e-06,  4.0033e-03,  1.2682e-07,
         1.5886e-12,  1.5941e-06,  3.2404e-09,  1.1116e-08,  2.1811e-04,
         3.7105e-04, -1.2241e-08,  7.6841e-09,  5.4344e-07,  6.4602e-10,
         7.8502e-08,  7.9407e-07,  1.9839e-09,  1.5985e-05,  3.0867e-12,
         3.1185e-04,  7.6009e-07,  3.5580e-05,  8.0355e-09,  1.6984e-09,
         3.4066e-12,  6.9226e-09,  2.7850e-11,  1.4570e-08,  1.5107e-08,
         6.7477e-06], device='cuda:0', grad_fn=<AddBackward0>)
That took 39.16690754890442 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-13/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

Sender: LSF System <lsfadmin@lt12>
Subject: Job 15330657: <active-supervised> in cluster <lila> Done

Job <active-supervised> was submitted from host <lilac> by user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:36 2020
Job was executed on host(s) <12*lt12>, in queue <gpuqueue>, as user <nguyenm5> in cluster <lila> at Mon Jul 13 21:31:37 2020
</home/nguyenm5> was used as the home directory.
</home/nguyenm5/coding/pinot> was used as the working directory.
Started at Mon Jul 13 21:31:37 2020
Terminated at Mon Jul 13 21:32:27 2020
Results reported at Mon Jul 13 21:32:27 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/home/nguyenm5/anaconda3/envs/pinot/bin/python scripts/active/plotting_active.py --net ExactGaussianProcessRegressor --num_rounds 4 --num_trials 1 --num_epoch 750 --data moonshot --q 96 --acquisition ExpectedImprovement --output_folder /home/nguyenm5/coding/pinot/jul-13/active-supervised --index 4
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   253.40 sec.
    Max Memory :                                 2 GB
    Average Memory :                             1.70 GB
    Total Requested Memory :                     192.00 GB
    Delta Memory :                               190.00 GB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                20
    Run time :                                   51 sec.
    Turnaround time :                            51 sec.

The output (if any) follows:

0
scores from acquisition: expected_improvement_analytical
tensor([0.2534, 0.1749, 0.2596, 0.1898, 0.2392, 0.2467, 0.2108, 0.1493, 0.2559,
        0.1642, 0.2600, 0.1782, 0.2494, 0.2600, 0.2165, 0.1989, 0.2359, 0.2434,
        0.2602, 0.2441, 0.2542, 0.2392, 0.2404, 0.1961, 0.2589, 0.2004, 0.1985,
        0.2602, 0.2593, 0.2595, 0.2595, 0.1334, 0.2600, 0.2036, 0.1644, 0.2594,
        0.2072, 0.2509, 0.2073, 0.2577, 0.2596, 0.2601, 0.2392, 0.2597, 0.2480,
        0.1752, 0.2585, 0.2528, 0.1794, 0.1751, 0.2422, 0.2573, 0.2227, 0.2567,
        0.2584, 0.2087, 0.1932, 0.2377, 0.2563, 0.2016, 0.1757, 0.2413, 0.1323,
        0.1772, 0.2596, 0.2596, 0.2026, 0.1759, 0.2356, 0.1573, 0.2504, 0.1318,
        0.2489, 0.2078, 0.2503, 0.1276, 0.2544, 0.1996, 0.0996, 0.1901, 0.2529,
        0.2426, 0.2144, 0.1989, 0.2027, 0.2051, 0.2603, 0.2596, 0.2570, 0.2483,
        0.2582, 0.2598, 0.2599, 0.2510, 0.2164, 0.2536, 0.2576, 0.2535, 0.1488,
        0.2418, 0.2597, 0.1326, 0.2585, 0.2585, 0.2134, 0.2587, 0.1521, 0.2600,
        0.1820, 0.1901, 0.1700, 0.1765, 0.1353, 0.2601, 0.2353, 0.2045, 0.2600,
        0.2496, 0.2407, 0.2596, 0.1494, 0.2579, 0.2598, 0.2025, 0.2597, 0.2596,
        0.2552, 0.1700, 0.2412, 0.2509, 0.1825, 0.2562, 0.2597, 0.2410, 0.1801,
        0.1925, 0.1321, 0.2360, 0.2576, 0.1340, 0.1806, 0.2458, 0.2426, 0.2047,
        0.1817, 0.2593, 0.2356, 0.2552, 0.1456, 0.2256, 0.2538, 0.2277, 0.2046,
        0.1901, 0.2516, 0.1654, 0.2537, 0.2176, 0.2120, 0.2474, 0.2550, 0.2408,
        0.2541, 0.1836, 0.2522, 0.2603, 0.1328, 0.2532, 0.2368, 0.2343, 0.1960,
        0.2166, 0.1556, 0.1749, 0.1900, 0.2479, 0.1800, 0.2100, 0.2315, 0.1313,
        0.2584, 0.2531, 0.2596, 0.1902, 0.2547, 0.2163, 0.1876, 0.1891, 0.2588,
        0.2582, 0.1322, 0.2600, 0.2163, 0.1274, 0.2174, 0.2547, 0.2038, 0.2459,
        0.1733, 0.2376, 0.2601, 0.1504, 0.0848, 0.2575, 0.1918, 0.2594, 0.2587,
        0.1849, 0.2268, 0.1606, 0.2024, 0.2393, 0.2396, 0.1495, 0.2372, 0.2554,
        0.2510, 0.1682, 0.2059, 0.2587, 0.1612, 0.2470, 0.2529, 0.2500, 0.1821,
        0.2534, 0.1733, 0.1853, 0.2034, 0.2600, 0.1483, 0.1887, 0.2595, 0.2315,
        0.2313, 0.2028, 0.2533, 0.2595, 0.2064, 0.2423, 0.1396, 0.2446, 0.2595,
        0.1982, 0.2417, 0.2595, 0.1322, 0.2470, 0.2014, 0.2211, 0.1757, 0.1983,
        0.1796, 0.2351, 0.2600, 0.2588, 0.1581, 0.1775, 0.1592, 0.1703, 0.2387,
        0.2600, 0.2462, 0.2166, 0.2587, 0.2083, 0.1982, 0.1621, 0.2037, 0.2418,
        0.2498, 0.1322, 0.1471, 0.2417, 0.2559, 0.1322, 0.2573, 0.2349, 0.2113,
        0.2587, 0.2595, 0.1624, 0.1890, 0.2542, 0.2596, 0.1770, 0.2452, 0.2368,
        0.2235, 0.1366, 0.1921, 0.2469, 0.2399, 0.1812, 0.1621, 0.2507, 0.1755,
        0.1998, 0.2000, 0.2507, 0.2300, 0.2371, 0.2504, 0.2470, 0.2600, 0.1720,
        0.2566, 0.2586, 0.2179, 0.1459, 0.2440, 0.2575, 0.2453, 0.2532, 0.2603,
        0.1961, 0.1782, 0.2596, 0.1781, 0.1346, 0.2428, 0.1978, 0.2534, 0.1999,
        0.2510, 0.1768, 0.1895, 0.2335, 0.2418, 0.2582, 0.2012, 0.2512, 0.1963,
        0.1328, 0.2266, 0.2350, 0.2298, 0.2264, 0.2527, 0.1549, 0.2568, 0.2101,
        0.2595, 0.2152, 0.2003, 0.2352, 0.1988, 0.2393, 0.2246, 0.2597, 0.2500,
        0.2571, 0.1699, 0.1909, 0.2594, 0.2509, 0.2551, 0.2229, 0.2028, 0.1559,
        0.1325, 0.2562, 0.1746, 0.1554, 0.1572, 0.2227, 0.2148, 0.2566, 0.2461,
        0.2354, 0.1932, 0.2596, 0.2457], device='cuda:0',
       grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 1.9258e-05,  3.5621e-02,  5.9553e-03,  2.3316e-02,  1.1065e-06,
         1.1044e-02,  1.0867e-02,  3.4758e-02,  3.4341e-02,  3.5618e-12,
         9.2753e-03,  2.5588e-02,  2.3599e-03,  4.1416e-03,  4.6570e-05,
         2.4087e-02,  5.9275e-04,  4.8085e-03,  7.8674e-06,  7.4906e-04,
        -7.6701e-09,  4.6739e-05,  1.3430e-02,  4.9604e-03,  2.5709e-07,
         2.4933e-02,  6.1957e-05,  1.1583e-07,  2.0286e-02, -6.0044e-10,
         2.6801e-03,  3.1874e-02,  2.4052e-03,  2.7843e-03,  7.1373e-04,
         1.4145e-03,  3.4887e-08,  1.5987e-02,  1.8299e-02,  8.7787e-07,
         1.4603e-02,  1.4961e-02,  1.9359e-02,  3.0427e-02,  4.2079e-02,
         2.4744e-02,  1.1574e-07, -8.4971e-09,  2.6066e-04,  3.1302e-03,
         2.4058e-10,  1.1427e-02,  6.5836e-03,  3.9158e-08,  2.0513e-02,
         4.9782e-11,  1.7778e-02,  3.5514e-03,  2.4821e-02,  1.5009e-02,
         4.5878e-03,  4.8796e-08,  7.8656e-08,  4.2718e-03,  7.1205e-03,
         2.5299e-09,  2.6644e-02,  1.1998e-04,  1.1180e-02,  8.2454e-03,
         1.8268e-02,  2.9632e-02,  1.4501e-02,  5.3769e-04,  2.0052e-02,
         4.7386e-07,  1.6479e-02,  2.6942e-02,  9.3611e-07,  1.7935e-04,
         1.2877e-02,  1.4591e-02,  2.9965e-02,  5.6520e-04,  1.1063e-03,
         2.4469e-02,  9.4876e-05,  9.7186e-03,  2.8780e-02,  1.8513e-02,
         7.6355e-04, -1.0688e-08,  2.9673e-02,  1.9792e-03,  2.0733e-03,
         9.9916e-03,  1.2214e-06,  5.3038e-04,  2.0948e-03,  1.6020e-03,
        -3.4022e-09,  1.9851e-02,  6.1394e-03,  4.7391e-03, -5.6371e-09,
         1.3925e-07,  5.9407e-03,  1.6821e-04,  5.0333e-03,  1.8699e-04,
         1.8892e-04,  1.6954e-05,  2.7138e-02,  2.6655e-07,  2.0419e-02,
         2.2950e-08,  5.8760e-06,  8.9127e-05,  1.5481e-02,  3.2353e-03,
         1.6041e-02,  2.0971e-02,  3.1000e-03,  1.2266e-03,  1.9725e-02,
         1.8177e-02,  6.5669e-03,  1.8840e-02,  1.1142e-06,  3.9901e-03,
         3.3360e-04,  1.1386e-02,  5.6792e-04,  1.8529e-02,  7.2814e-03,
         3.0809e-02,  1.4551e-02,  2.5430e-02,  2.7685e-04,  1.3348e-03,
         1.0391e-06,  1.7638e-02,  9.3127e-06,  1.4392e-02,  1.7762e-02,
         2.7025e-04,  3.0207e-02,  9.6010e-03,  3.9992e-03,  2.1822e-05,
         7.2944e-03,  1.9710e-07,  5.3912e-02,  6.7929e-03,  2.7729e-02,
         2.5262e-02,  1.6575e-03, -8.0875e-09,  1.7363e-10,  3.2695e-02,
         3.2671e-10,  5.4850e-03,  2.6372e-02,  1.5752e-02,  5.0860e-08,
         2.4237e-02,  2.0795e-02,  3.5644e-05,  1.4552e-05,  1.1609e-10,
         1.7129e-02,  2.4575e-03,  1.0653e-02,  2.6205e-03,  2.9806e-02,
         8.8693e-04,  2.5211e-07,  1.5941e-03,  1.2254e-02,  1.7586e-03,
         3.4650e-02,  3.5275e-02,  1.7281e-02,  1.5486e-02,  6.9941e-03,
         1.3317e-02,  2.1364e-02,  2.0873e-02,  4.3442e-03,  3.0321e-04,
         2.0186e-02,  4.0620e-03,  2.7326e-02,  3.2443e-02,  2.6084e-02,
         1.9485e-04,  3.9471e-10,  2.6245e-07,  1.9069e-02,  3.3174e-04,
         1.8294e-02,  1.5096e-02,  1.0799e-02,  8.7641e-07,  2.0039e-02,
         1.2372e-02,  1.8451e-06,  8.5148e-05,  5.6509e-04,  6.2266e-03,
         1.3280e-03,  1.4431e-05,  1.1628e-02,  1.6184e-02,  2.5261e-02,
         7.3121e-08,  2.1747e-07,  1.6089e-03,  2.5689e-02,  1.7325e-09,
         2.4494e-03,  2.8686e-03,  2.0579e-07,  1.5664e-03,  2.3471e-02,
         1.7385e-03,  1.1042e-02,  1.4256e-07,  8.6589e-06,  4.2714e-04,
         4.2110e-02,  2.6398e-02,  1.3388e-02,  1.2009e-02,  1.5598e-03,
         4.0645e-03,  6.5981e-06,  9.3176e-03,  6.0008e-06,  1.3594e-02,
         1.9022e-02,  4.0244e-04,  7.4068e-03,  4.6536e-03,  1.8653e-05,
         3.6136e-02,  7.4564e-03,  3.5654e-05,  4.1839e-02,  8.8695e-04,
         1.7146e-02,  9.0948e-12,  1.2801e-02,  2.1979e-02,  4.4975e-02,
         7.6433e-06,  4.1614e-02,  8.5309e-03,  2.4908e-04,  5.3165e-07,
         4.3791e-07,  2.8487e-02,  3.5052e-03,  1.1334e-08,  5.7728e-03,
         8.9452e-03,  1.6710e-02,  1.8767e-02,  2.0184e-02,  2.4834e-02,
         2.2989e-02,  1.4202e-02,  1.8694e-02,  2.5787e-03,  2.3355e-03,
         1.3166e-02,  4.9393e-06], device='cuda:0', grad_fn=<AddBackward0>)
scores from acquisition: expected_improvement_analytical
tensor([ 2.5525e-12,  4.8107e-04,  7.6910e-14,  1.7785e-08,  2.8428e-12,
         2.3976e-08,  1.0665e-07,  3.8108e-11,  3.4046e-10,  4.5270e-09,
         2.4625e-12, -6.3712e-09,  1.3500e-08,  4.4130e-07,  2.4050e-07,
         8.9595e-08,  3.0775e-07,  2.4808e-11,  9.8673e-06, -9.1631e-09,
         1.0774e-05,  2.7721e-16, -1.8544e-09,  5.2003e-09,  9.5955e-07,
         2.8532e-08, -6.8634e-09,  3.7038e-04,  3.7204e-06,  4.3852e-09,
         3.4734e-08,  8.6802e-06,  1.6461e-05,  8.1437e-10,  1.6272e-11,
         1.3857e-15,  1.9650e-08,  7.9485e-10,  2.0425e-11,  7.2527e-05,
         1.6381e-12,  2.1129e-06,  2.1194e-02,  5.2075e-06,  2.1567e-10,
         1.9360e-08,  6.1956e-08,  4.1293e-10,  1.3261e-03,  1.2381e-05,
         9.3244e-15,  9.3450e-07,  1.4654e-06,  8.3090e-06,  5.1685e-05,
         1.2328e-04,  9.2742e-10,  1.1029e-10,  1.0193e-07,  2.8083e-09,
         2.8935e-10,  4.9965e-14,  1.2919e-08,  8.6239e-08,  1.2784e-04,
         6.7043e-09,  1.8553e-05,  5.9237e-03,  3.3238e-05,  1.9335e-08,
         1.3890e-05,  1.2334e-05,  1.1482e-10,  2.7434e-07,  1.9073e-04,
         7.6087e-06,  2.5108e-05,  8.8697e-07,  1.7930e-12,  5.4610e-03,
         4.7403e-10,  6.2068e-10,  7.6559e-11,  2.4563e-09, -5.2850e-09,
         4.1442e-11,  1.4209e-08,  4.8498e-09,  3.4619e-14,  1.5855e-05,
        -3.2828e-09,  3.6677e-13,  3.7598e-06,  9.0436e-03,  8.4780e-06,
         4.4285e-07,  1.0381e-08,  9.1553e-08,  7.0205e-05,  4.5780e-05,
         6.7404e-08,  2.8673e-12,  1.5652e-08,  2.1855e-13,  6.6599e-08,
         3.9547e-10,  1.1496e-08,  2.1996e-05,  1.5494e-03,  4.3504e-04,
         8.0444e-08,  1.3489e-08,  4.2083e-04, -1.2448e-08, -8.2843e-09,
         2.8464e-06, -1.1150e-09,  1.2412e-04,  6.8308e-04,  5.3545e-03,
         9.9646e-09,  5.5938e-09, -4.7069e-09,  2.5122e-05,  1.9988e-08,
         3.5804e-09,  2.8366e-06,  6.8573e-14,  1.0859e-07,  1.5097e-04,
         1.6120e-03,  2.5466e-05,  7.0816e-10,  6.4971e-03,  4.6214e-06,
        -9.4942e-09,  3.7845e-10,  1.0741e-04,  9.3544e-10,  1.9313e-04,
         3.5009e-05,  2.5155e-05, -3.7901e-09,  1.6920e-06,  1.1512e-12,
         1.4248e-08,  1.4532e-09,  2.3664e-04,  4.8348e-08,  1.9394e-10,
         2.8714e-04,  7.4444e-04,  7.2641e-08,  4.2375e-09,  3.0731e-05,
         1.1631e-13,  1.3086e-09,  3.2788e-09,  6.9067e-05,  1.2610e-03,
         1.1419e-04,  1.4353e-09,  4.7643e-06,  2.8642e-07,  1.2156e-08,
        -4.8439e-10,  5.3715e-12,  1.4450e-04, -2.1089e-09,  7.2602e-05,
         1.1544e-08,  2.4685e-04,  1.0306e-09,  1.7169e-10,  2.3155e-10,
         1.3429e-10,  1.2542e-08,  1.3489e-08, -3.4930e-09,  2.2161e-08,
         1.5630e-08], device='cuda:0', grad_fn=<AddBackward0>)
That took 42.469266176223755 seconds


PS:

Read file </home/nguyenm5/coding/pinot/jul-13/active-supervised/ExpectedImprovement.stderr> for stderr output of this job.

