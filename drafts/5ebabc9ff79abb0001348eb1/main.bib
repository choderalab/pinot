@article{wu2018moleculenet,
  title={MoleculeNet: a benchmark for molecular machine learning},
  author={Wu, Zhenqin and Ramsundar, Bharath and Feinberg, Evan N and Gomes, Joseph and Geniesse, Caleb and Pappu, Aneesh S and Leswing, Karl and Pande, Vijay},
  journal={Chemical science},
  volume={9},
  number={2},
  pages={513--530},
  year={2018},
  publisher={Royal Society of Chemistry}
}


@article{doi:10.1080/15472450.2017.1291351,
author = {Dimitris Milakis and Bart van Arem and Bert van Wee},
title = {Policy and society related implications of automated driving: A review of literature and directions for future research},
journal = {Journal of Intelligent Transportation Systems},
volume = {21},
number = {4},
pages = {324-348},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/15472450.2017.1291351},

URL = { 
        https://doi.org/10.1080/15472450.2017.1291351
    
},
eprint = { 
        https://doi.org/10.1080/15472450.2017.1291351
    
}

}

@article{DBLP:journals/corr/abs-1710-03748,
  author    = {Trapit Bansal and
               Jakub Pachocki and
               Szymon Sidor and
               Ilya Sutskever and
               Igor Mordatch},
  title     = {Emergent Complexity via Multi-Agent Competition},
  journal   = {CoRR},
  volume    = {abs/1710.03748},
  year      = {2017},
  url       = {http://arxiv.org/abs/1710.03748},
  archivePrefix = {arXiv},
  eprint    = {1710.03748},
  timestamp = {Mon, 13 Aug 2018 16:47:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1710-03748},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{battaglia2018relational,
  title={Relational inductive biases, deep learning, and graph networks},
  author={Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
  journal={arXiv preprint arXiv:1806.01261},
  year={2018}
}

@article{DBLP:journals/corr/HasseltGS15,
  author    = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  archivePrefix = {arXiv},
  eprint    = {1509.06461},
  timestamp = {Mon, 13 Aug 2018 16:47:32 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HasseltGS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article {Mobley286542,
	author = {Mobley, David L. and Bannan, Caitlin C. and Rizzi, Andrea and Bayly, Christopher I. and Chodera, John D. and Lim, Victoria T. and Lim, Nathan M. and Beauchamp, Kyle A. and Shirts, Michael R. and Gilson, Michael K. and Eastman, Peter K.},
	title = {Open Force Field Consortium: Escaping atom types using direct chemical perception with SMIRNOFF v0.1},
	elocation-id = {286542},
	year = {2018},
	doi = {10.1101/286542},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Here, we focus on testing and improving force fields for molecular modeling, which see widespread use in diverse areas of computational chemistry and biomolecular simulation. A key issue affecting the accuracy and transferrability of these force fields is the use of atom typing. Traditional approaches to defining molecular mechanics force fields must encode, within a discrete set of atom types, all information which will ever be needed about the chemical environment; parameters are then assigned by looking up combinations of these atom types in tables. This atom typing approach leads to a wide variety of problems such as inextensible atom-typing machinery, enormous difficulty in expanding parameters encoded by atom types, and unnecessarily proliferation of encoded parameters. Here, we describe a new approach to assigning parameters for molecular mechanics force fields based on the industry standard SMARTS chemical perception language (with extensions to identify specific atoms available in SMIRKS). In this approach, each force field term (bonds, angles, and torsions, and nonbonded interactions) features separate definitions assigned in a hierarchical manner without using atom types. We accomplish this using direct chemical perception, where parameters are assigned directly based on substructure queries operating on the molecule(s) being parameterized, thereby avoiding the intermediate step of assigning atom types {\textemdash} a step which can be considered indirect chemical perception. Direct chemical perception allows for substantial simplification of force fields, as well as additional generality in the substructure queries. This approach is applicable to a wide variety of (bio)molecular systems, and can greatly reduce the number of parameters needed to create a complete force field. Further flexibility can also be gained by allowing force field terms to be interpolated based on the assignment of fractional bond orders via the same procedure used to assign partial charges. As an example of the utility of this approach, we provide a minimalist small molecule force field derived from Merck{\textquoteright}s parm@Frosst (an Amber parm99 descendant), in which a parameter definition file only {\guillemotleft}300 lines long can parameterize a large and diverse spectrum of pharmaceutically relevant small molecule chemical space. We benchmark this minimalist force field on the FreeSolv small molecule hydration free energy set and calculations of densities and dielectric constants from the ThermoML Archive, demonstrating that it achieves comparable accuracy to the Generalized Amber Force Field (GAFF) that consists of many thousands of parameters.},
	URL = {https://www.biorxiv.org/content/early/2018/07/13/286542},
	eprint = {https://www.biorxiv.org/content/early/2018/07/13/286542.full.pdf},
	journal = {bioRxiv}
}









@article{doi:10.1021/acs.jctc.8b00640,
author = {Mobley, David L. and Bannan, Caitlin C. and Rizzi, Andrea and Bayly, Christopher I. and Chodera, John D. and Lim, Victoria T. and Lim, Nathan M. and Beauchamp, Kyle A. and Slochower, David R. and Shirts, Michael R. and Gilson, Michael K. and Eastman, Peter
K.},
title = {Escaping Atom Types in Force Fields Using Direct Chemical Perception},
journal = {Journal of Chemical Theory and Computation},
volume = {14},
number = {11},
pages = {6076-6092},
year = {2018},
doi = {10.1021/acs.jctc.8b00640},
    note ={PMID: 30351006},

URL = { 
        https://doi.org/10.1021/acs.jctc.8b00640
    
},
eprint = { 
        https://doi.org/10.1021/acs.jctc.8b00640
    
}

}

@article{havel1998distance,
  title={Distance geometry: Theory, algorithms, and chemical applications},
  author={Havel, Timothy F}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@inproceedings{dietterich2000ensemble,
  title={Ensemble methods in machine learning},
  author={Dietterich, Thomas G},
  booktitle={International workshop on multiple classifier systems},
  pages={1--15},
  year={2000},
  organization={Springer}
}

@Article{C6SC05720A,
author ="Smith, J. S. and Isayev, O. and Roitberg, A. E.",
title  ="ANI-1: an extensible neural network potential with DFT accuracy at force field computational cost",
journal  ="Chem. Sci.",
year  ="2017",
volume  ="8",
issue  ="4",
pages  ="3192-3203",
publisher  ="The Royal Society of Chemistry",
doi  ="10.1039/C6SC05720A",
url  ="http://dx.doi.org/10.1039/C6SC05720A",
abstract  ="Deep learning is revolutionizing many areas of science and technology{,} especially image{,} text{,} and speech recognition. In this paper{,} we demonstrate how a deep neural network (NN) trained on quantum mechanical (QM) DFT calculations can learn an accurate and transferable potential for organic molecules. We introduce ANAKIN-ME (Accurate NeurAl networK engINe for Molecular Energies) or ANI for short. ANI is a new method designed with the intent of developing transferable neural network potentials that utilize a highly-modified version of the Behler and Parrinello symmetry functions to build single-atom atomic environment vectors (AEV) as a molecular representation. AEVs provide the ability to train neural networks to data that spans both configurational and conformational space{,} a feat not previously accomplished on this scale. We utilized ANI to build a potential called ANI-1{,} which was trained on a subset of the GDB databases with up to 8 heavy atoms in order to predict total energies for organic molecules containing four atom types: H{,} C{,} N{,} and O. To obtain an accelerated but physically relevant sampling of molecular potential surfaces{,} we also proposed a Normal Mode Sampling (NMS) method for generating molecular conformations. Through a series of case studies{,} we show that ANI-1 is chemically accurate compared to reference DFT calculations on much larger molecular systems (up to 54 atoms) than those included in the training data set."}

@article{DBLP:journals/corr/abs-1806-01261,
  author    = {Peter W. Battaglia and
               Jessica B. Hamrick and
               Victor Bapst and
               Alvaro Sanchez{-}Gonzalez and
               Vin{\'{\i}}cius Flores Zambaldi and
               Mateusz Malinowski and
               Andrea Tacchetti and
               David Raposo and
               Adam Santoro and
               Ryan Faulkner and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               H. Francis Song and
               Andrew J. Ballard and
               Justin Gilmer and
               George E. Dahl and
               Ashish Vaswani and
               Kelsey R. Allen and
               Charles Nash and
               Victoria Langston and
               Chris Dyer and
               Nicolas Heess and
               Daan Wierstra and
               Pushmeet Kohli and
               Matthew Botvinick and
               Oriol Vinyals and
               Yujia Li and
               Razvan Pascanu},
  title     = {Relational inductive biases, deep learning, and graph networks},
  journal   = {CoRR},
  volume    = {abs/1806.01261},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.01261},
  archivePrefix = {arXiv},
  eprint    = {1806.01261},
  timestamp = {Wed, 24 Jul 2019 18:56:21 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1806-01261},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{2019arXiv190907903W,
       author = {{Wang}, Yuanqing and {Fass}, Josh and {Stern}, Chaya D. and {Luo}, Kun and
         {Chodera}, John},
        title = "{Graph Nets for Partial Charge Prediction}",
      journal = {arXiv e-prints},
     keywords = {Physics - Computational Physics, Computer Science - Machine Learning, Physics - Chemical Physics},
         year = "2019",
        month = "Sep",
          eid = {arXiv:1909.07903},
        pages = {arXiv:1909.07903},
archivePrefix = {arXiv},
       eprint = {1909.07903},
 primaryClass = {physics.comp-ph},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190907903W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{doi:10.1021/ci034148o,
author = {Gilson, Michael K. and Gilson, Hillary S. R. and Potter, Michael J.},
title = {Fast Assignment of Accurate Partial Atomic Charges:  An Electronegativity Equalization Method that Accounts for Alternate Resonance Forms},
journal = {Journal of Chemical Information and Computer Sciences},
volume = {43},
number = {6},
pages = {1982-1997},
year = {2003},
doi = {10.1021/ci034148o},
    note ={PMID: 14632449},

URL = { 
        https://doi.org/10.1021/ci034148o
    
},
eprint = { 
        https://doi.org/10.1021/ci034148o
    
}

}

@article{doi:10.1021/acs.jcim.7b00663,
author = {Bleiziffer, Patrick and Schaller, Kay and Riniker, Sereina},
title = {Machine Learning of Partial Charges Derived from High-Quality Quantum-Mechanical Calculations},
journal = {Journal of Chemical Information and Modeling},
volume = {58},
number = {3},
pages = {579-590},
year = {2018},
doi = {10.1021/acs.jcim.7b00663},
    note ={PMID: 29461814},

URL = { 
        https://doi.org/10.1021/acs.jcim.7b00663
    
},
eprint = { 
        https://doi.org/10.1021/acs.jcim.7b00663
    
}

}

@misc{blundell2015weight,
    title={Weight Uncertainty in Neural Networks},
    author={Charles Blundell and Julien Cornebise and Koray Kavukcuoglu and Daan Wierstra},
    year={2015},
    eprint={1505.05424},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{leimkuhler2019partitioned,
    title={Partitioned integrators for thermodynamic parameterization of neural networks},
    author={Benedict Leimkuhler and Charles Matthews and Tiffany Vlaar},
    year={2019},
    eprint={1908.11843},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Vehtari_2016,
   title={Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
   volume={27},
   ISSN={1573-1375},
   url={http://dx.doi.org/10.1007/s11222-016-9696-4},
   DOI={10.1007/s11222-016-9696-4},
   number={5},
   journal={Statistics and Computing},
   publisher={Springer Science and Business Media LLC},
   author={Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
   year={2016},
   month={Aug},
   pages={1413–1432}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}
        

@article{halperin2002principles,
  title={Principles of docking: An overview of search algorithms and a guide to scoring functions},
  author={Halperin, Inbal and Ma, Buyong and Wolfson, Haim and Nussinov, Ruth},
  journal={Proteins: Structure, Function, and Bioinformatics},
  volume={47},
  number={4},
  pages={409--443},
  year={2002},
  publisher={Wiley Online Library}
}

@misc{wmt19, url={http://www.statmt.org/wmt19/}, journal={2019 Fourth Conference on Machine Translation (WMT19)}}

















@article{doi:10.1002/andp.18812480110,
author = {Lorentz, H. A.},
title = {Ueber die Anwendung des Satzes vom Virial in der kinetischen Theorie der Gase},
journal = {Annalen der Physik},

volume = {248},
number = {1},
pages = {127-136},
doi = {10.1002/andp.18812480110},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/andp.18812480110},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/andp.18812480110},
year = {1881}
}

@Article{Paul2010,
author={Paul, Steven M.
and Mytelka, Daniel S.
and Dunwiddie, Christopher T.
and Persinger, Charles C.
and Munos, Bernard H.
and Lindborg, Stacy R.
and Schacht, Aaron L.},
title={How to improve R\&D productivity: the pharmaceutical industry's grand challenge},
journal={Nature Reviews Drug Discovery},
year={2010},
volume={9},
number={3},
pages={203-214},
abstract={The biopharmaceutical industry is facing unprecedented challenges to its fundamental business model and currently cannot sustain sufficient innovation to replace its products and revenues lost due to patent expirations.The number of truly innovative new medicines approved by regulatory agencies such as the US Food and Drug Administration has declined substantially despite continued increases in R\&D spending, raising the current cost of each new molecular entity (NME) to approximately US\$1.8 billionDeclining R\&D productivity is arguably the most important challenge the industry faces and thus improving R\&D productivity is its most important priority.A detailed analysis of the key elements that determine overall R\&D productivity and the cost to successfully develop an NME reveals exactly where (and to what degree) R\&D productivity can (and must) be improved.Reducing late-stage (Phase II and III) attrition rates and cycle times during drug development are among the key requirements for improving R\&D productivity.To achieve the necessary increase in R\&D productivity, R\&D investments, both financial and intellectual, must be focused on the 'sweet spot' of drug discovery and early clinical development, from target selection to clinical proof-of-concept.The transformation from a traditional biopharmaceutical FIPCo (fully integrated pharmaceutical company) to a FIPNet (fully integrated pharmaceutical network) should allow a given R\&D organization to 'play bigger than its size' and to more affordably fund the necessary number and quality of pipeline assets.},
issn={1474-1784},
doi={10.1038/nrd3078},
url={https://doi.org/10.1038/nrd3078}
}

@article{ramakrishnan2014quantum,
  title={Quantum chemistry structures and properties of 134 kilo molecules},
  author={Ramakrishnan, Raghunathan and Dral, Pavlo O and Rupp, Matthias and von Lilienfeld, O Anatole},
  journal={Scientific Data},
  volume={1},
  year={2014},
  publisher={Nature Publishing Group}
}

@article{DBLP:journals/corr/ChungGCB14,
  author    = {Junyoung Chung and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               KyungHyun Cho and
               Yoshua Bengio},
  title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1412.3555},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.3555},
  archivePrefix = {arXiv},
  eprint    = {1412.3555},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChungGCB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hochreiter:1997:LSM:1246443.1246450,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@article{DBLP:journals/corr/Altae-TranRPP16,
  author    = {Han Altae{-}Tran and
               Bharath Ramsundar and
               Aneesh S. Pappu and
               Vijay S. Pande},
  title     = {Low Data Drug Discovery with One-shot Learning},
  journal   = {CoRR},
  volume    = {abs/1611.03199},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.03199},
  archivePrefix = {arXiv},
  eprint    = {1611.03199},
  timestamp = {Mon, 13 Aug 2018 16:45:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Altae-TranRPP16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{neal2012bayesian,
  title={Bayesian learning for neural networks},
  author={Neal, Radford M},
  volume={118},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{slivkins2014contextual,
  title={Contextual bandits with similarity information},
  author={Slivkins, Aleksandrs},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={2533--2568},
  year={2014},
  publisher={JMLR. org}
}

@article{garnett2012bayesian,
  title={Bayesian optimal active search and surveying},
  author={Garnett, Roman and Krishnamurthy, Yamuna and Xiong, Xuehan and Schneider, Jeff and Mann, Richard},
  journal={arXiv preprint arXiv:1206.6406},
  year={2012}
}

@article{schobel1999stochastic,
  title={Stochastic volatility with an Ornstein--Uhlenbeck process: an extension},
  author={Sch{\"o}bel, Rainer and Zhu, Jianwei},
  journal={Review of Finance},
  volume={3},
  number={1},
  pages={23--46},
  year={1999},
  publisher={European Finance Association}
}

@Article{pmid28430432,
   Author="Xie, B.  and Nguyen, T. H.  and Minh, D. D. L. ",
   Title="{{A}bsolute {B}inding {F}ree {E}nergies between {T}4 {L}ysozyme and 141 {S}mall {M}olecules: {C}alculations {B}ased on {M}ultiple {R}igid {R}eceptor {C}onfigurations}",
   Journal="J Chem Theory Comput",
   Year="2017",
   Volume="13",
   Number="6",
   Pages="2930--2944",
   Month="Jun"
}

@article{PhysRevLett.98.146401,
  title = {Generalized Neural-Network Representation of High-Dimensional Potential-Energy Surfaces},
  author = {Behler, J\"org and Parrinello, Michele},
  journal = {Phys. Rev. Lett.},
  volume = {98},
  issue = {14},
  pages = {146401},
  numpages = {4},
  year = {2007},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.98.146401},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.98.146401}
}

@misc{douglas2011weisfeilerlehman,
    title={The Weisfeiler-Lehman Method and Graph Isomorphism Testing},
    author={B. L. Douglas},
    year={2011},
    eprint={1101.5211},
    archivePrefix={arXiv},
    primaryClass={math.CO}
}

@misc{xu2018powerful,
    title={How Powerful are Graph Neural Networks?},
    author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
    year={2018},
    eprint={1810.00826},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}



















@article{doi:10.1002/jcc.540150207,
author = {Maple, J. R. and Hwang, M.-J. and Stockfisch, T. P. and Dinur, U. and Waldman, M. and Ewig, C. S. and Hagler, A. T.},
title = {Derivation of class II force fields. I. Methodology and quantum force field for the alkyl functional group and alkane molecules},
journal = {Journal of Computational Chemistry},

volume = {15},
number = {2},
pages = {162-182},
doi = {10.1002/jcc.540150207},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.540150207},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcc.540150207},
abstract = {Abstract A new method for deriving force fields for molecular simulations has been developed. It is based on the derivation and parameterization of analytic representations of the ab initio potential energy surfaces. The general method is presented here and used to derive a quantum mechanical force field (QMFF) for alkanes. It is based on sampling the energy surfaces of 16 representative alkane species. For hydrocarbons, this force field contains 66 force constants and reference values. These were fit to 128,376 quantum mechanical energies and energy derivatives describing the energy surface. The detailed form of the analytic force field expression and the values of all resulting parameters are given. A series of computations is then performed to test the ability of this force field to reproduce the features of the ab initio energy surface in terms of energies as well as the first and second derivatives of the energies with respect to molecular deformations. The fit is shown to be good, with rms energy deviations of less than 7\% for all molecules. Also, although only two atom types are employed, the force field accounts for the properties of both highly strained species, such as cyclopropane and methylcyclopropanes, as well as unstrained systems. The information contained in the quantum energy surface indicates that it is significantly anharmonic and that important intramolecular coupling interactions exist between internals. The representation of the nature of these interactions, not present in diagonal, quadratic force fields (Class I force fields), is shown to be important in accounting accurately for molecular energy surfaces. The Class II force field derived from the quantum energy surface is characterized by accounting for these important intramolecular forces. The importance of each 4.2 to 18.2\%. This fourfold increase in the second derivative error dramatically demonstrates the importance of bond anharmonicity in the ab initio potential energy surface. The Class II force field derived from the quantum energy surface is characterized by accounting for these important intramolecular forces. The importance of each of the interaction terms of the potential energy function has also been assessed. Bond anharmonicity, angle anharmonicity, and bond/angle, bond/torsion, and angle/angle/ torsion cross-term interactions result in the most significant overall improvement in distorted structure energies and energy derivatives. The implications of each energy term for the development of advanced force fields is discussed. Finally, it is shown that the techniques introduced here for exploring the quantum energy surface can be used to determine the extent of transferability and range of validity of the force field. The latter is of crucial importance in meeting the objective of deriving a force field for use in molecular mechanics and dynamics calculations of a wide range of molecules often containing functional groups in novel environments. © 1994 by John Wiley \& Sons, Inc.},
year = {1994}
}


@Article{pmid26201396,
   Author="Papadatos, G.  and Gaulton, A.  and Hersey, A.  and Overington, J. P. ",
   Title="{{A}ctivity, assay and target data curation and quality in the {C}h{E}{M}{B}{L} database}",
   Journal="J. Comput. Aided Mol. Des.",
   Year="2015",
   Volume="29",
   Number="9",
   Pages="885--896",
   Month="Sep"
}

@Article{pmid4655909,
   Author="Peck, A. H. ",
   Title="{{A}n interim program for emergency psychiatric evaluation in {B}altimore city}",
   Journal="Md State Med J",
   Year="1972",
   Volume="21",
   Number="12",
   Pages="43--47",
   Month="Dec"
}

@misc{molssi, title={The MolSSIQuantum Chemistry Archive}, url={https://qcarchive.molssi.org/}, journal={The MolSSI QCArchive}, author={Molecular Sciences Software Institute}}

@article{WANG2006247,
title = "Automatic atom type and bond type perception in molecular mechanical calculations",
journal = "Journal of Molecular Graphics and Modelling",
volume = "25",
number = "2",
pages = "247 - 260",
year = "2006",
issn = "1093-3263",
doi = "https://doi.org/10.1016/j.jmgm.2005.12.005",
url = "http://www.sciencedirect.com/science/article/pii/S1093326305001737",
author = "Junmei Wang and Wei Wang and Peter A. Kollman and David A. Case",
keywords = "Atom type perception, Bond type perception, Antechamber, Residue topology, Force field parameters, General AMBER force field (GAFF)",
abstract = "In molecular mechanics (MM) studies, atom types and/or bond types of molecules are needed to determine prior to energy calculations. We present here an automatic algorithm of perceiving atom types that are defined in a description table, and an automatic algorithm of assigning bond types just based on atomic connectivity. The algorithms have been implemented in a new module of the AMBER packages. This auxiliary module, antechamber (roughly meaning “before AMBER”), can be applied to generate necessary inputs of leap—the AMBER program to generate topologies for minimization, molecular dynamics, etc., for most organic molecules. The algorithms behind the manipulations may be useful for other molecular mechanical packages as well as applications that need to designate atom types and bond types."
}


@book{liu2008monte,
  title={Monte Carlo strategies in scientific computing},
  author={Liu, Jun S},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article {Noeeaaw1147,
	author = {No{\'e}, Frank and Olsson, Simon and K{\"o}hler, Jonas and Wu, Hao},
	title = {Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning},
	volume = {365},
	number = {6457},
	elocation-id = {eaaw1147},
	year = {2019},
	doi = {10.1126/science.aaw1147},
	publisher = {American Association for the Advancement of Science},
	abstract = {Molecular dynamics or Monte Carlo methods can be used to sample equilibrium states, but these methods become computationally expensive for complex systems, where the transition from one equilibrium state to another may only occur through rare events. No{\'e} et al. used neural networks and deep learning to generate distributions of independent soft condensed-matter samples at equilibrium (see the Perspective by Tuckerman). Supervised training is used to construct invertible transformations between the coordinates of the complex system of interest and simple Gaussian coordinates of the same dimensionality. Thus, configurations can be sampled in this simpler coordinate system and then transformed back into the complex one using the correct statistical weighting.Science, this issue p. eaaw1147; see also p. 982INTRODUCTIONStatistical mechanics aims to compute the average behavior of physical systems on the basis of their microscopic constituents. For example, what is the probability that a protein will be folded at a given temperature? If we could answer such questions efficiently, then we could not only comprehend the workings of molecules and materials, but we could also design drug molecules and materials with new properties in a principled way.To this end, we need to compute statistics of the equilibrium states of many-body systems. In the protein-folding example, this means to consider each of the astronomically many ways to place all protein atoms in space, to compute the probability of each such {\textquotedblleft}configuration{\textquotedblright} in the equilibrium ensemble, and then to compare the total probability of unfolded and folded configurations.As enumeration of all configurations is infeasible, one instead must attempt to sample them from their equilibrium distribution. However, we currently have no way to generate equilibrium samples of many-body systems in {\textquotedblleft}one shot.{\textquotedblright} The main approach is thus to start with one configuration, e.g., the folded protein state, and make tiny changes to it over time, e.g., by using Markov-chain Monte Carlo or molecular dynamics (MD). However, these simulations get trapped in metastable (long-lived) states: For example, sampling a single folding or unfolding event with atomistic MD may take a year on a supercomputer.RATIONALEHere, we combine deep machine learning and statistical mechanics to develop Boltzmann generators. Boltzmann generators are trained on the energy function of a many-body system and learn to provide unbiased, one-shot samples from its equilibrium state. This is achieved by training an invertible neural network to learn a coordinate transformation from a system{\textquoteright}s configurations to a so-called latent space representation, in which the low-energy configurations of different states are close to each other and can be easily sampled. Because of the invertibility, every latent space sample can be back-transformed to a system configuration with high Boltzmann probability (Fig. 1). We then employ statistical mechanics, which offers a rich set of tools for reweighting the distribution generated by the neural network to the Boltzmann distribution.RESULTSBoltzmann generators can be trained to directly generate independent samples of low-energy structures of condensed-matter systems and protein molecules. When initialized with a few structures from different metastable states, Boltzmann generators can generate statistically independent samples from these states and efficiently compute the free-energy differences between them. This capability could be used to compute relative stabilities between different experimental structures of protein or other organic molecules, which is currently a very challenging problem. Boltzmann generators can also learn a notion of {\textquotedblleft}reaction coordinates{\textquotedblright}: Simple linear interpolations between points in latent space have a high probability of corresponding to physically realistic, low-energy transition pathways. Finally, by using established sampling methods such as Metropolis Monte Carlo in the latent space variables, Boltzmann generators can discover new states and gradually explore state space.CONCLUSIONBoltzmann generators can overcome rare event{\textendash}sampling problems in many-body systems by learning to generate unbiased equilibrium samples from different metastable states in one shot. They differ conceptually from established enhanced sampling methods, as no reaction coordinates are needed to drive them between metastable states. However, by applying existing sampling methods in the latent spaces learned by Boltzmann generators, a plethora of new opportunities opens up to design efficient sampling methods for many-body systems.Boltzmann generators overcome sampling problems between long-lived states.The Boltzmann generator works as follows: 1. We sample from a simple (e.g., Gaussian) distribution. 2. An invertible deep neural network is trained to transform this simple distribution to a distribution pX(x) that is similar to the desired Boltzmann distribution of the system of interest. 3. To compute thermodynamics quantities, the samples are reweighted to the Boltzmann distribution using statistical mechanics methods.Computing equilibrium states in condensed-matter many-body systems, such as solvated proteins, is a long-standing challenge. Lacking methods for generating statistically independent equilibrium samples in {\textquotedblleft}one shot,{\textquotedblright} vast computational effort is invested for simulating these systems in small steps, e.g., using molecular dynamics. Combining deep learning and statistical mechanics, we developed Boltzmann generators, which are shown to generate unbiased one-shot equilibrium samples of representative condensed-matter systems and proteins. Boltzmann generators use neural networks to learn a coordinate transformation of the complex configurational equilibrium distribution to a distribution that can be easily sampled. Accurate computation of free-energy differences and discovery of new configurations are demonstrated, providing a statistical mechanics tool that can avoid rare events during sampling without prior knowledge of reaction coordinates.},
	issn = {0036-8075},
	URL = {https://science.sciencemag.org/content/365/6457/eaaw1147},
	eprint = {https://science.sciencemag.org/content/365/6457/eaaw1147.full.pdf},
	journal = {Science}
}


@misc{kingma2018glow,
    title={Glow: Generative Flow with Invertible 1x1 Convolutions},
    author={Diederik P. Kingma and Prafulla Dhariwal},
    year={2018},
    eprint={1807.03039},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}


@misc{papamakarios2019normalizing,
    title={Normalizing Flows for Probabilistic Modeling and Inference},
    author={George Papamakarios and Eric Nalisnick and Danilo Jimenez Rezende and Shakir Mohamed and Balaji Lakshminarayanan},
    year={2019},
    eprint={1912.02762},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{chen2019residual,
    title={Residual Flows for Invertible Generative Modeling},
    author={Ricky T. Q. Chen and Jens Behrmann and David Duvenaud and Jörn-Henrik Jacobsen},
    year={2019},
    eprint={1906.02735},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}


@misc{dinh2014nice,
    title={NICE: Non-linear Independent Components Estimation},
    author={Laurent Dinh and David Krueger and Yoshua Bengio},
    year={2014},
    eprint={1410.8516},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{DBLP:journals/corr/DinhSB16,
  author    = {Laurent Dinh and
               Jascha Sohl{-}Dickstein and
               Samy Bengio},
  title     = {Density estimation using Real {NVP}},
  journal   = {CoRR},
  volume    = {abs/1605.08803},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.08803},
  archivePrefix = {arXiv},
  eprint    = {1605.08803},
  timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/DinhSB16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{trudeau1993introduction,
  title={Introduction to Graph Theory},
  author={Trudeau, R.J.},
  isbn={9780486678702},
  lccn={lc93032996},
  series={Dover Books on Mathematics Series},
  url={https://books.google.com/books?id=NunuAAAAMAAJ},
  year={1993},
  publisher={Dover Pub.}
}

@misc{cpr,
url={http://brooksandrew.github.io/simpleblog/articles/intro-to-graph-optimization-solving-cpp/#solving-the-chinese-postman-problem}}

@article{DBLP:journals/corr/KipfW16,
  author    = {Thomas N. Kipf and
               Max Welling},
  title     = {Semi-Supervised Classification with Graph Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1609.02907},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.02907},
  archivePrefix = {arXiv},
  eprint    = {1609.02907},
  timestamp = {Mon, 13 Aug 2018 16:48:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KipfW16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{doi:10.1002/jcc.540150207,
author = {Maple, J. R. and Hwang, M.-J. and Stockfisch, T. P. and Dinur, U. and Waldman, M. and Ewig, C. S. and Hagler, A. T.},
title = {Derivation of class II force fields. I. Methodology and quantum force field for the alkyl functional group and alkane molecules},
journal = {Journal of Computational Chemistry},
volume = {15},
number = {2},
pages = {162-182},
doi = {10.1002/jcc.540150207},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.540150207},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcc.540150207},
abstract = {Abstract A new method for deriving force fields for molecular simulations has been developed. It is based on the derivation and parameterization of analytic representations of the ab initio potential energy surfaces. The general method is presented here and used to derive a quantum mechanical force field (QMFF) for alkanes. It is based on sampling the energy surfaces of 16 representative alkane species. For hydrocarbons, this force field contains 66 force constants and reference values. These were fit to 128,376 quantum mechanical energies and energy derivatives describing the energy surface. The detailed form of the analytic force field expression and the values of all resulting parameters are given. A series of computations is then performed to test the ability of this force field to reproduce the features of the ab initio energy surface in terms of energies as well as the first and second derivatives of the energies with respect to molecular deformations. The fit is shown to be good, with rms energy deviations of less than 7\% for all molecules. Also, although only two atom types are employed, the force field accounts for the properties of both highly strained species, such as cyclopropane and methylcyclopropanes, as well as unstrained systems. The information contained in the quantum energy surface indicates that it is significantly anharmonic and that important intramolecular coupling interactions exist between internals. The representation of the nature of these interactions, not present in diagonal, quadratic force fields (Class I force fields), is shown to be important in accounting accurately for molecular energy surfaces. The Class II force field derived from the quantum energy surface is characterized by accounting for these important intramolecular forces. The importance of each 4.2 to 18.2\%. This fourfold increase in the second derivative error dramatically demonstrates the importance of bond anharmonicity in the ab initio potential energy surface. The Class II force field derived from the quantum energy surface is characterized by accounting for these important intramolecular forces. The importance of each of the interaction terms of the potential energy function has also been assessed. Bond anharmonicity, angle anharmonicity, and bond/angle, bond/torsion, and angle/angle/ torsion cross-term interactions result in the most significant overall improvement in distorted structure energies and energy derivatives. The implications of each energy term for the development of advanced force fields is discussed. Finally, it is shown that the techniques introduced here for exploring the quantum energy surface can be used to determine the extent of transferability and range of validity of the force field. The latter is of crucial importance in meeting the objective of deriving a force field for use in molecular mechanics and dynamics calculations of a wide range of molecules often containing functional groups in novel environments. © 1994 by John Wiley \& Sons, Inc.},
year = {1994}
}
